{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"My Dev Notes","text":"<p>Welcome to My Dev Notes \ud83d\udc4b</p> <p>This site contains my personal development notes, cheatsheets, and useful commands.</p>"},{"location":"cloud/aws/athena/","title":"AWS Athena","text":""},{"location":"cloud/aws/athena/#introduction","title":"Introduction","text":"<p>Amazon Athena is an interactive query service that lets you analyze data directly in Amazon S3 using standard SQL. It is serverless, so there is no infrastructure to manage, and you only pay for the queries you run.</p>"},{"location":"cloud/aws/athena/#adding-missing-partitions-automatically","title":"Adding Missing Partitions Automatically","text":"<p>When working with partitioned tables in Athena (for example, daily partitions in <code>year/month/day</code> format), you may need to update the metadata so Athena recognizes newly added data.</p> <pre><code>MSCK REPAIR TABLE my_database.my_table;\n</code></pre> <p>This will scan the table\u2019s S3 location and add any missing partitions automatically.</p>"},{"location":"cloud/aws/athena/#aws-glue-crawler","title":"AWS Glue Crawler","text":"<ul> <li>AWS Glue Crawler Console: https://console.aws.amazon.com/glue/home?region=eu-west-1#catalog:tab=crawlers</li> <li>After adding data to S3, run the Glue Crawler to update the Athena table schema.</li> </ul> <p>A typical workflow for keeping your Athena tables up to date:</p> <ol> <li>Run AWS Glue Crawler    Update the table schema with new data structure changes.</li> <li> <p>Repair Partitions in Athena</p> <pre><code>MSCK REPAIR TABLE my_database.my_table;\n</code></pre> </li> <li> <p>Re-run the AWS Glue Crawler    If new columns were introduced after the first run, run the crawler again so the new schema is reflected in Athena.</p> </li> </ol>"},{"location":"cloud/aws/athena/#adding-a-specific-partition-manually","title":"Adding a Specific Partition Manually","text":"<p>If you want to add a single partition without scanning the whole dataset:</p> <pre><code>ALTER TABLE audit_logs ADD IF NOT EXISTS\nPARTITION (year='2025', month='08', day='19', hour='15')\nLOCATION 's3://example-bucket/audit_logs/2025/08/19/15/';\n</code></pre>"},{"location":"cloud/aws/athena/#example-athena-queries","title":"Example Athena Queries","text":"<p>Audit Log Search by Object ID</p> <pre><code>SELECT object_id, user_id, log_timestamp, message\nFROM my_database.audit_logs\nWHERE year = '2025' AND month = '06'\n  AND environment = 'test'\n  AND object_id = 'UPDATE_USER_STATUS'\n  AND message LIKE '%123456789%'\nORDER BY log_timestamp DESC;\n</code></pre> <p>Recent Updates</p> <pre><code>SELECT * FROM company_trace_db.store_product\nWHERE DATE(last_updated_at) &gt; '2025-08-14'\n  AND store_code = '1001'\n  AND product_code = 'P12345'\nORDER BY last_updated_at DESC\nLIMIT 1000;\n</code></pre> <p>Top Search Keywords</p> <pre><code>SELECT LOWER(x.name) AS keyword, COUNT(*) AS count  \nFROM company_trace_db.user_action, UNNEST(context_value) AS x  \nWHERE DATE(created_at) BETWEEN '2025-08-10' AND '2025-08-12'  \n  AND context IN ('QUICK_SEARCH', 'SEARCH')  \nGROUP BY LOWER(x.name)  \nORDER BY count DESC  \nLIMIT 100;\n</code></pre>"},{"location":"cloud/aws/athena/#creating-athena-tables-from-csv-in-s3","title":"Creating Athena Tables from CSV in S3","text":"<p>If you have raw CSV files in S3 and want to query them directly:</p> <pre><code>CREATE EXTERNAL TABLE IF NOT EXISTS default.audit_csv (\n  `timestamp` bigint,\n  `serverhost` string,\n  `username` string,\n  `host` string,\n  `connectionid` string,\n  `queryid` int,\n  `operation` string,\n  `database` string,\n  `object` string,\n  `return_code` int\n)\nPARTITIONED BY (year int, month int, day int)\nROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'\nWITH SERDEPROPERTIES (\n  'serialization.format' = ',',\n  'field.delim' = ','\n)\nLOCATION 's3://example-audit-logs/sub-directory'\nTBLPROPERTIES ('has_encrypted_data'='false');\n\nALTER TABLE default.audit_csv\nADD PARTITION (year='2025', month='01', day='31')\nLOCATION 's3://example-audit-logs/sub-directory/2025/01/31/';\n</code></pre>"},{"location":"cloud/aws/athena/#querying-athena-from-intellijdatagrip","title":"Querying Athena from IntelliJ/DataGrip","text":"<p>You can query AWS Athena directly from IntelliJ-based IDEs like DataGrip. Official guide: Using AWS Athena from IntelliJ-based IDE</p> <p>How to Use:</p> <ol> <li>Open DataGrip or another IntelliJ-based IDE.</li> <li>Add a new Data Source \u2192 Amazon Athena.</li> <li>Enter your AWS credentials and select the correct region.</li> <li>Choose the catalog and database you want to query.</li> <li>Write your SQL queries in the editor and run them just like any other database.</li> </ol> <p>This allows you to work with Athena queries directly inside your IDE without switching to the AWS web console.</p>"},{"location":"cloud/aws/athena/#best-practices","title":"Best Practices","text":"<ul> <li>Use Glue Crawlers to keep schemas up to date automatically.</li> <li>Always filter partitions in your queries to reduce costs.</li> <li>Use compressed columnar formats like Parquet for faster queries.</li> <li>Maintain a clear S3 folder structure for easier partition management.</li> <li>Enable S3 Lifecycle Policies to manage storage costs.</li> </ul>"},{"location":"cloud/aws/athena/#references","title":"References","text":"<ul> <li>Official AWS Athena Documentation</li> <li>AWS Glue Crawlers</li> <li>Amazon S3 Documentation</li> <li>Partition Projection in Athena</li> </ul>"},{"location":"database/mysql/mysql-cheatsheet/","title":"MySQL Cheatsheet","text":"<p>This document contains useful commands, configurations, and troubleshooting tips for MySQL.</p>"},{"location":"database/mysql/mysql-cheatsheet/#1-installation","title":"1. Installation","text":"<p>Install MySQL via Homebrew:</p> Click to expand <pre><code>brew install mysql@8.0\necho 'export PATH=\"/usr/local/opt/mysql@8.0/bin:$PATH\"' &gt;&gt; ~/.bash_profile\nexport PATH=\"/usr/local/opt/mysql@8.0/bin:$PATH\"\nsource ~/.bash_profile\n</code></pre> <p>Check version:</p> <pre><code>$ mysql --version\nmysql  Ver 8.0.43 for macos14.7 on x86_64 (Homebrew)\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#2-uninstallation","title":"2. Uninstallation","text":"<p>Uninstall MySQL Completely:</p> Click to expand <pre><code>brew uninstall mysql\nbrew uninstall mysql-client\nbrew uninstall --ignore-dependencies mysql-client\nbrew cleanup\n\nsudo rm -rf /usr/local/var/mysql\nsudo rm -rf /usr/local/mysql*\nsudo rm -rf /usr/local/mysql-client*\nsudo rm -rf /Library/StartupItems/MySQLCOM\nsudo rm -rf /Library/PreferencePanes/My*\nsudo rm -rf /Library/Receipts/mysql*\nsudo rm -rf /Library/Receipts/MySQL*\n</code></pre> <p>Reference: Remove MySQL completely</p>"},{"location":"database/mysql/mysql-cheatsheet/#3-common-mysql-commands","title":"3. Common MySQL Commands","text":""},{"location":"database/mysql/mysql-cheatsheet/#start-stop-server","title":"Start / Stop Server","text":"<pre><code>mysql.server start\nmysql.server stop\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#login","title":"Login","text":"<pre><code>mysql -u root -p\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#show-mysql-version","title":"Show MySQL Version","text":"<pre><code>SHOW VARIABLES LIKE \"%version%\";\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#4-process-management","title":"4. Process Management","text":""},{"location":"database/mysql/mysql-cheatsheet/#show-process-list","title":"Show Process List","text":"<pre><code>SHOW PROCESSLIST;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#show-only-queries","title":"Show Only Queries","text":"<pre><code>SELECT *\nFROM INFORMATION_SCHEMA.PROCESSLIST\nWHERE COMMAND = 'Query'\nORDER BY TIME DESC;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#kill-a-query-rds-example","title":"Kill a Query (RDS Example)","text":"<pre><code>CALL mysql.rds_kill(query_id);\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#show-innodb-transactions","title":"Show InnoDB Transactions","text":"<pre><code>SELECT *\nFROM INFORMATION_SCHEMA.INNODB_TRX;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#show-active-processes-excluding-sleep","title":"Show Active Processes (excluding sleep)","text":"<pre><code>SELECT *\nFROM information_schema.processlist\nWHERE command &lt;&gt; 'Sleep' AND (db IN ('example_db') OR db IS NULL);\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#5-deadlock-info","title":"5. Deadlock Info","text":"<pre><code>SHOW ENGINE INNODB STATUS;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#6-index-management","title":"6. Index Management","text":""},{"location":"database/mysql/mysql-cheatsheet/#show-indexes","title":"Show Indexes","text":"<pre><code>SHOW INDEX FROM example_db.example_table;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#index-usage-statistics","title":"Index Usage Statistics","text":"<pre><code>SELECT INDEX_NAME, COUNT_STAR, COUNT_READ, COUNT_WRITE\nFROM performance_schema.table_io_waits_summary_by_index_usage\nWHERE OBJECT_SCHEMA = 'example_db' AND OBJECT_NAME = 'example_table'\nORDER BY COUNT_STAR;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#cardinality-size","title":"Cardinality &amp; Size","text":"<pre><code>SELECT TABLE_NAME, INDEX_NAME, CARDINALITY, INDEX_TYPE\nFROM information_schema.STATISTICS\nWHERE TABLE_SCHEMA = 'example_db' AND TABLE_NAME = 'example_table';\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#find-unused-indexes","title":"Find Unused Indexes","text":"<pre><code>SELECT *\nFROM sys.schema_unused_indexes\nWHERE object_schema = 'example_db' AND object_name = 'example_table';\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#find-redundant-indexes","title":"Find Redundant Indexes","text":"<pre><code>SELECT *\nFROM sys.schema_redundant_indexes\nWHERE table_schema = 'example_db' AND table_name = 'example_table';\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#check-index-statistics","title":"Check Index Statistics","text":"<pre><code>SELECT *\nFROM sys.schema_index_statistics\nWHERE table_schema = 'example_db' AND table_name = 'example_table';\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#7-slow-query-log","title":"7. Slow Query Log","text":""},{"location":"database/mysql/mysql-cheatsheet/#enable-configure-slow-query-log","title":"Enable &amp; Configure Slow Query Log","text":"<p><code>my.cnf</code> sample:</p> <pre><code># Log queries not using indexes\nlog_queries_not_using_indexes = 0\n\n# Enable slow query log\nslow_query_log = 1\n\n# Threshold for slow queries (seconds)\nlong_query_time = 3\n\n# File to store slow queries\nslow-query-log-file = /var/lib/mysql/logs/slow.log\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#view-slow-queries","title":"View Slow Queries","text":"<pre><code>-- Show slow log entries for a specific DB\nSELECT *\nFROM mysql.slow_log\nWHERE db = 'example_db'\nORDER BY start_time DESC;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#8-file-upload","title":"8. File Upload","text":"<pre><code>LOAD DATA LOCAL INFILE '/path/to/file.csv'\n    INTO TABLE example_schema.example_table\n    FIELDS TERMINATED BY ';'\n    OPTIONALLY ENCLOSED BY '\"'\n    LINES TERMINATED BY '\\n'\n    IGNORE 1 LINES;\n\nSHOW WARNINGS;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#9-time-zone","title":"9. Time Zone","text":""},{"location":"database/mysql/mysql-cheatsheet/#check-current-time-zone","title":"Check Current Time Zone","text":"<pre><code>SELECT @@time_zone;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#example-connection-string-with-time-zone","title":"Example Connection String with Time Zone","text":"<pre><code># Asia/Baghdad\njdbc:mysql://example_host:3306/example_db?useSSL=false&amp;serverTimezone=Asia/Baghdad\n\n# GMT+3\njdbc:mysql://example_host:3306/example_db?useSSL=false&amp;serverTimezone=GMT%2B3\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#10-password-management","title":"10. Password Management","text":""},{"location":"database/mysql/mysql-cheatsheet/#change-user-password","title":"Change User Password","text":"<pre><code>mysql -u root\n\nALTER USER 'example_user'@'localhost' IDENTIFIED BY 'new_password';\nALTER USER 'root'@'localhost' IDENTIFIED BY '';\n\nFLUSH PRIVILEGES;\n\nmysql -u root -h localhost -p\nmysql.server restart\n</code></pre> <p>Reference: Change MySQL Password</p>"},{"location":"database/mysql/mysql-cheatsheet/#reset-root-password","title":"Reset Root Password","text":"<pre><code>UPDATE mysql.user\nSET authentication_string=NULL\nWHERE User = 'root';\nFLUSH PRIVILEGES;\n\nALTER USER 'root'@'localhost' IDENTIFIED WITH caching_sha2_password BY 'new_password';\nALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'new_password';\n</code></pre> <p>Reference: Password Reset Gist</p>"},{"location":"database/mysql/mysql-cheatsheet/#11-table-operations","title":"11. Table Operations","text":""},{"location":"database/mysql/mysql-cheatsheet/#atomic-rename","title":"Atomic Rename","text":"<pre><code>RENAME TABLE old_table TO old_table_backup, new_table TO old_table;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#partitioning-example","title":"Partitioning Example","text":"<pre><code>ALTER TABLE example_table\nREORGANIZE PARTITION p_max INTO (\n    PARTITION p_20201023 VALUES LESS THAN ('2020-10-24'),\n    PARTITION p_20201024 VALUES LESS THAN ('2020-10-25'),\n    PARTITION p_max VALUES LESS THAN (MAXVALUE)\n    );\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#12-random-row","title":"12. Random Row","text":"<pre><code>SELECT *\nFROM example_table\nORDER BY RAND()\nLIMIT 1;\n</code></pre>"},{"location":"database/mysql/mysql-cheatsheet/#13-reset-auto-increment","title":"13. Reset Auto Increment","text":"<pre><code>ALTER TABLE example_table\nAUTO_INCREMENT = 1;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/","title":"PostgreSQL Cheatsheet","text":"<p>This guide is designed to provide a clear, concise overview of common PostgreSQL tasks and commands, suitable for developers and DBAs transitioning from MySQL or other database systems.</p>"},{"location":"database/postgresql/postgresql-cheatsheet/#1-installation","title":"1. Installation","text":"<pre><code>brew install postgresql\n\n# Restart PostgreSQL service after upgrade\nbrew services restart postgresql\n\n# Start PostgreSQL manually without background service\n/usr/local/opt/postgresql/bin/postgres -D /usr/local/var/postgres\n\n# If PostgreSQL fails to start, remove stale PID file\nrm /usr/local/var/postgres/postmaster.pid\n\n# Stop PostgreSQL service\nbrew services stop postgresql\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#2-basic-postgresql-user-database-management","title":"2. Basic PostgreSQL User &amp; Database Management","text":"<p>Connect to the default <code>postgres</code> database:</p> <pre><code>psql postgres\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#21-user-management","title":"2.1 User Management","text":"<pre><code>-- Create a new user with encrypted password\nCREATE USER username WITH ENCRYPTED PASSWORD 'password';\n\n-- Alter user to have superuser privileges\nALTER USER username WITH SUPERUSER;\n\n-- Allow user to create databases\nALTER USER username CREATEDB;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#22-database-management","title":"2.2 Database Management","text":"<pre><code>-- Create a new database owned by a specific user\nCREATE DATABASE dbname WITH OWNER username;\n\n-- Change the owner of a database\nALTER DATABASE dbname OWNER TO username;\n\n-- Grant all privileges on a database to a user\nGRANT ALL PRIVILEGES ON DATABASE dbname TO username;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#3-running-sql-scripts","title":"3. Running SQL Scripts","text":"<p>Execute a SQL file from command line:</p> <pre><code>psql -U username -d dbname -f path/to/script.sql\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#4-managing-sequences-auto-increment-ids","title":"4. Managing Sequences (Auto-Increment IDs)","text":"<pre><code>-- Set sequence value manually\nSELECT setval('sequence_name', 100000);\n\n-- Get next sequence value\nSELECT nextval(pg_get_serial_sequence('table_name', 'column_name')) AS next_id;\n\n-- Get current sequence value\nSELECT currval(pg_get_serial_sequence('table_name', 'column_name')) AS current_id;\n\n-- Check last value from a sequence\nSELECT last_value\nFROM sequence_name;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#5-monitoring-managing-connections","title":"5. Monitoring &amp; Managing Connections","text":"<pre><code>-- View active connections to a specific database\nSELECT *\nFROM pg_stat_activity\nWHERE datname = 'your_database';\n\n-- Cancel a running query by PID\nSELECT pg_cancel_backend(pid);\n\n-- Terminate a connection forcefully by PID\nSELECT pg_terminate_backend(pid);\n</code></pre> <p>Use system commands to find PostgreSQL processes:</p> <pre><code>ps -ef | grep postgres\nsudo kill -9 &lt;PID&gt;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#6-postgresql-system-catalog-and-information-queries","title":"6. PostgreSQL System Catalog and Information Queries","text":""},{"location":"database/postgresql/postgresql-cheatsheet/#viewing-roles-and-users","title":"Viewing Roles and Users","text":"<pre><code>SELECT *\nFROM pg_catalog.pg_user;\n\nSELECT *\nFROM pg_catalog.pg_roles;\n\nSELECT DISTINCT rolname\nFROM pg_catalog.pg_roles;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#viewing-databases-tables-and-groups","title":"Viewing Databases, Tables, and Groups","text":"<pre><code>SELECT *\nFROM pg_catalog.pg_database;\n\nSELECT *\nFROM pg_catalog.pg_tables;\n\nSELECT *\nFROM pg_catalog.pg_group;\n\nSELECT *\nFROM pg_catalog.pg_namespace;\n\nSELECT *\nFROM pg_catalog.pg_default_acl;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#using-information_schema-for-privileges","title":"Using information_schema for Privileges","text":"<pre><code>SELECT *\nFROM information_schema.role_table_grants;\n\nSELECT *\nFROM information_schema.role_table_grants\nWHERE grantee LIKE '%psqladmin%';\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#showing-server-settings-and-extensions","title":"Showing Server Settings and Extensions","text":"<pre><code>SHOW wal_level; -- Should be 'logical' for logical replication\nSHOW max_worker_processes; -- Typically 16\nSHOW azure.extensions;\nSHOW session_replication_role;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#7-role-privilege-management","title":"7. Role &amp; Privilege Management","text":"<pre><code>-- Grant default privileges on new tables in a schema to a role\nALTER DEFAULT PRIVILEGES IN SCHEMA public\n    GRANT SELECT ON TABLES TO role_name;\n\n-- Revoke default privileges on new tables\nALTER DEFAULT PRIVILEGES IN SCHEMA public\n    REVOKE SELECT ON TABLES FROM role_name;\n\n-- Example granting multiple privileges\nALTER DEFAULT PRIVILEGES IN SCHEMA public\n    GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO role_name;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#8-performance-maintenance","title":"8. Performance &amp; Maintenance","text":"<pre><code>-- Analyze query plan and execution time\nEXPLAIN ANALYZE\nSELECT *\nFROM your_table;\n\n-- Perform vacuum full to reclaim storage\nVACUUM FULL your_table;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#9-useful-sql-snippets","title":"9. Useful SQL Snippets","text":"<pre><code>-- Generate a random number within a range\nSELECT floor(random() * (max_value - min_value + 1) + min_value);\n\n-- Select random rows from a table\nSELECT *\nFROM your_table\nORDER BY random()\nLIMIT 100;\n\n-- Use SET LOCAL within a transaction\nBEGIN;\nSET LOCAL some.custom_variable = 'value';\n-- your SQL commands here\nCOMMIT;\n</code></pre>"},{"location":"database/postgresql/postgresql-cheatsheet/#helpful-resources","title":"Helpful Resources","text":"<ul> <li>PostgreSQL Official Documentation</li> <li>StackOverflow: Run PostgreSQL SQL file via CLI</li> <li>Managing Roles &amp; Permissions</li> <li>PostgreSQL ALTER DEFAULT PRIVILEGES</li> </ul>"},{"location":"database/postgresql/postgresql-jsonb-operations/","title":"PostgreSQL JSONB Operations","text":"<p>This document covers common PostgreSQL JSONB operations with practical examples. It serves as a reference for querying, modifying, and manipulating JSONB data.</p>"},{"location":"database/postgresql/postgresql-jsonb-operations/#introduction-to-jsonb","title":"Introduction to JSONB","text":"<p>JSONB is a binary JSON data type introduced in PostgreSQL 9.4 that stores JSON data in a decomposed binary format, enabling efficient access and manipulation.</p> <p>Advantages of JSONB over JSON:</p> <ul> <li>Faster access and querying.</li> <li>Supports indexing.</li> <li>Allows modification of parts of JSON data.</li> </ul>"},{"location":"database/postgresql/postgresql-jsonb-operations/#basic-jsonb-queries","title":"Basic JSONB Queries","text":"<p>Assuming a table <code>documents</code> with a JSONB column <code>data</code>.</p> <pre><code>-- Select all rows\nSELECT *\nFROM documents;\n\n-- Select JSONB column\nSELECT data\nFROM documents;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#accessing-jsonb-elements","title":"Accessing JSONB Elements","text":""},{"location":"database/postgresql/postgresql-jsonb-operations/#access-with-and-operators","title":"Access with <code>-&gt;</code> and <code>-&gt;&gt;</code> operators","text":"<ul> <li><code>-&gt;</code> returns JSON object/array</li> <li><code>-&gt;&gt;</code> returns text</li> </ul> <pre><code>-- Get JSON object field\nSELECT data -&gt; 'name'\nFROM documents;\n\n-- Get JSON object field as text\nSELECT data -&gt;&gt; 'name'\nFROM documents;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#access-nested-json-objects","title":"Access nested JSON objects","text":"<pre><code>SELECT data -&gt; 'address' -&gt;&gt; 'city' AS city\nFROM documents;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#access-json-array-elements-by-index","title":"Access JSON array elements by index","text":"<pre><code>SELECT data -&gt; 'items' -&gt;&gt; 0 AS first_item\nFROM documents;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#jsonb-operators","title":"JSONB Operators","text":"Operator Description Example <code>?</code> Does key exist? <code>data ? 'name'</code> <code>?|</code> Do any of these keys exist? <code>data ?| array['name','age']</code> <code>?&amp;</code> Do all of these keys exist? <code>data ?&amp; array['name','age']</code> <code>@&gt;</code> Contains JSONB <code>data @&gt; '{\"name\":\"John\"}'</code> <code>&lt;@</code> Contained by JSONB <code>'{\"name\":\"John\"}'::jsonb &lt;@ data</code>"},{"location":"database/postgresql/postgresql-jsonb-operations/#jsonb-functions","title":"JSONB Functions","text":""},{"location":"database/postgresql/postgresql-jsonb-operations/#expand-json-array-elements-jsonb_array_elements","title":"Expand JSON array elements: <code>jsonb_array_elements</code>","text":"<p>Expands a JSONB array to a set of JSONB values.</p> <pre><code>SELECT jsonb_array_elements(data -&gt; 'items') AS item\nFROM documents;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#expand-json-object-into-keyvalue-pairs-jsonb_each","title":"Expand JSON object into key/value pairs: <code>jsonb_each</code>","text":"<p>Expands the outermost JSONB object into set of key/value pairs.</p> <pre><code>SELECT key, value\nFROM jsonb_each(data);\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#get-json-object-keys-jsonb_object_keys","title":"Get JSON object keys: <code>jsonb_object_keys</code>","text":"<p>Returns set of keys in JSONB object.</p> <pre><code>SELECT jsonb_object_keys(data)\nFROM documents;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#updating-jsonb-data","title":"Updating JSONB Data","text":""},{"location":"database/postgresql/postgresql-jsonb-operations/#set-or-update-keyvalue-with-jsonb_set","title":"Set or update key/value with <code>jsonb_set</code>","text":"<pre><code>UPDATE documents\nSET data = jsonb_set(data, '{name}', '\"Jane\"')\nWHERE id = 1;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#remove-key-with-operator","title":"Remove key with - operator","text":"<pre><code>UPDATE documents\nSET data = data - 'age'\nWHERE id = 1;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#concatenate-two-jsonb-objects-with-merge-jsonb-objects","title":"Concatenate two JSONB objects with <code>||</code> (Merge JSONB objects)","text":"<pre><code>UPDATE documents\nSET data = data || '{\"new_key\": \"new_value\"}'\nWHERE id = 1;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#indexing-jsonb","title":"Indexing JSONB","text":"<p>To speed up queries, create indexes on JSONB columns.</p>"},{"location":"database/postgresql/postgresql-jsonb-operations/#gin-index-for-containment-queries","title":"GIN index for containment queries","text":"<pre><code>CREATE INDEX idx_data_gin ON documents USING gin(data);\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#advanced-jsonb-examples","title":"Advanced JSONB Examples","text":"<p>Example: Filter rows where JSONB contains a key with specific value:</p> <pre><code>SELECT *\nFROM documents\nWHERE data @&gt; '{\"status\": \"active\"}';\n</code></pre> <p>Example: Extract all keys and values from JSONB object:</p> <pre><code>SELECT key, value\nFROM documents, jsonb_each(data);\n</code></pre> <p>Example: Get all elements of a JSONB array:</p> <pre><code>SELECT jsonb_array_elements(data -&gt; 'tags') AS tag\nFROM documents;\n</code></pre> <p>Example: Update nested JSON key:</p> <pre><code>UPDATE documents\nSET data = jsonb_set(data, '{address,city}', '\"New York\"')\nWHERE id = 2;\n</code></pre>"},{"location":"database/postgresql/postgresql-jsonb-operations/#helpful-resources","title":"Helpful Resources","text":"<p>This concludes the essential JSONB operations reference in PostgreSQL. For further details, refer to the official PostgreSQL documentation on JSONB:</p> <p>https://www.postgresql.org/docs/current/functions-json.html https://www.postgresql.org/docs/current/datatype-json.html</p>"},{"location":"docker/docker-cheatsheet/","title":"Docker Cheatsheet","text":""},{"location":"docker/docker-cheatsheet/#image-commands","title":"Image Commands","text":"<ul> <li><code>docker build</code> \u2014 Build an image from a Dockerfile</li> <li><code>docker images</code> \u2014 List images</li> <li><code>docker rmi</code> \u2014 Remove one or more images</li> <li><code>docker tag</code> \u2014 Tag an image for a repository</li> </ul>"},{"location":"docker/docker-cheatsheet/#container-commands","title":"Container Commands","text":"<ul> <li><code>docker run</code> \u2014 Run a container</li> <li><code>docker ps</code> \u2014 List running containers</li> <li><code>docker stop</code> \u2014 Stop one or more running containers</li> <li><code>docker start</code> \u2014 Start one or more stopped containers</li> <li><code>docker restart</code> \u2014 Restart containers</li> <li><code>docker rm</code> \u2014 Remove one or more containers</li> <li><code>docker exec</code> \u2014 Run a command inside a running container</li> <li><code>docker logs</code> \u2014 Fetch logs from a container</li> </ul>"},{"location":"docker/docker-cheatsheet/#volume-commands","title":"Volume Commands","text":"<ul> <li><code>docker volume create</code> \u2014 Create a volume</li> <li><code>docker volume ls</code> \u2014 List volumes</li> <li><code>docker volume rm</code> \u2014 Remove a volume</li> </ul>"},{"location":"docker/docker-cheatsheet/#network-commands","title":"Network Commands","text":"<ul> <li><code>docker network create</code> \u2014 Create a network</li> <li><code>docker network ls</code> \u2014 List networks</li> <li><code>docker network rm</code> \u2014 Remove a network</li> </ul>"},{"location":"docker/docker-cheatsheet/#system-commands","title":"System Commands","text":"<ul> <li><code>docker system prune</code> \u2014 Remove unused data</li> <li><code>docker system prune -a --volumes</code> \u2014 Remove all unused containers, images, networks, and volumes</li> <li><code>docker info</code> \u2014 Display system-wide information</li> <li><code>docker version</code> \u2014 Show Docker version info</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/","title":"Docker Compose Cheatsheet","text":"<p>Docker Compose is a tool for defining and running multi-container Docker applications. Below are some common Docker Compose commands with explanations using the new <code>docker compose</code> syntax.</p>"},{"location":"docker/docker-compose-cheatsheet/#starting-services","title":"Starting Services","text":"<pre><code>docker compose up\n</code></pre> <ul> <li>Builds, (re)creates, starts, and attaches to containers for a service defined in <code>docker-compose.yml</code>.</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#starting-services-in-detached-mode","title":"Starting Services in Detached Mode","text":"<pre><code>docker compose up -d\n</code></pre> <ul> <li>Starts the containers in the background (detached mode).</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#stopping-services","title":"Stopping Services","text":"<pre><code>docker compose down\n</code></pre> <ul> <li>Stops and removes containers, networks, volumes, and images created by <code>docker compose up</code>.</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#viewing-running-containers","title":"Viewing Running Containers","text":"<pre><code>docker compose ps\n</code></pre> <ul> <li>Lists containers started by <code>docker compose</code>.</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#viewing-logs","title":"Viewing Logs","text":"<pre><code>docker compose logs\n</code></pre> <ul> <li>Shows output logs from containers.</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#rebuilding-services","title":"Rebuilding Services","text":"<pre><code>docker compose build\n</code></pre> <ul> <li>Builds or rebuilds services.</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#restarting-services","title":"Restarting Services","text":"<pre><code>docker compose restart\n</code></pre> <ul> <li>Restarts running containers.</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#stopping-services-without-removing-containers","title":"Stopping Services Without Removing Containers","text":"<pre><code>docker compose stop\n</code></pre> <ul> <li>Stops running containers but does not remove them.</li> </ul>"},{"location":"docker/docker-compose-cheatsheet/#summary","title":"Summary","text":"Command Description <code>docker compose up</code> Start and attach to containers <code>docker compose up -d</code> Start containers in detached mode <code>docker compose down</code> Stop and remove containers and networks <code>docker compose ps</code> List containers <code>docker compose logs</code> Show container logs <code>docker compose build</code> Build or rebuild services <code>docker compose restart</code> Restart running containers <code>docker compose stop</code> Stop containers without removing them <p>For more info, visit the official docs: https://docs.docker.com/compose/</p>"},{"location":"docker/docker-examples/","title":"Docker Examples","text":""},{"location":"docker/docker-examples/#container","title":"Container","text":"<p>Running a container:</p> <p><code>docker container run image:tag</code></p> <p>Example: <code>docker container run nginx:latest</code></p> <p>Running a container in detached mode (-d):</p> <p><code>docker container run -d image:tag</code></p> <p>Example: <code>docker container run -d nginx:latest</code></p> <p>Starting a container with a different command instead of the default:</p> <p><code>docker container run image:tag command</code></p> <p>Example: <code>docker container run ubuntu:latest ping 127.0.0.1</code></p> <p>Running a container with a given name:</p> <p><code>docker container run --name name image:tag</code></p> <p>Example: <code>docker container run --name container1 -d nginx:latest</code></p> <p>Running another command inside a running container:</p> <p><code>docker container exec container_id|or|container_name command</code></p> <p>Example: <code>docker container exec 12a793b3fec0 ping 127.0.0.1</code></p> <p>Opening a shell inside a running container:</p> <p><code>docker container exec -it container_id|or|container_name sh</code></p> <p>Example: <code>docker container exec -it 12a793b3fec0 sh</code></p> <p>Creating a container with detached mode and shell connection (dit):</p> <p><code>docker container run -dit image:tag sh</code></p> <p>Example: <code>docker container run -dit nginx:latest sh</code></p> <p>Attaching to a container created with detached mode and shell:</p> <p><code>docker attach container_id|or|container_name</code></p> <p>Example: <code>docker attach 12a793b3fec0</code></p> <p>Stopping a container:</p> <p><code>docker container stop container_id|or|container_name</code></p> <p>Example: <code>docker container stop 12a793b3fec0</code></p> <p>Removing a container:</p> <p><code>docker container rm container_id|or|container_name</code></p> <p>Example: <code>docker container rm 12a793b3fec0</code></p> <p>Removing a running container (-f):</p> <p><code>docker container rm -f container_id|or|container_name</code></p> <p>Example: <code>docker container rm -f 12a793b3fec0</code></p> <p>Automatically remove container on exit (-rm):</p> <p><code>docker container run -rm image:tag</code></p> <p>Example: <code>docker container run -rm nginx:latest</code> (with -rm the container is automatically removed after stopping)</p> <p>Inspecting container details:</p> <p><code>docker container inspect container_id|or|container_name</code></p> <p>Example: <code>docker container inspect 12a793b3fec0</code></p> <p>Removing all containers (running and stopped) in the system:</p> <p><code>docker container rm -f $(docker ps -aq)</code></p> <p>Listing running containers:</p> <p><code>docker container ls</code> or</p> <p><code>docker container ps</code></p> <p>Listing all containers:</p> <p><code>docker container ls -a</code> or</p> <p><code>docker container ps -a</code></p> <p>Listing processes inside a running container:</p> <p><code>docker top container_id|or|container_name</code></p> <p>Example: <code>docker top 12a793b3fec0</code></p> <p>Viewing CPU, RAM, I/O usage of a running container:</p> <p><code>docker stats container_id|or|container_name</code></p> <p>Example: <code>docker stats 12a793b3fec0</code></p> <p>Limiting container memory usage (--memory, --memory-swap):</p> <p><code>docker container run --memory=value(b,k,m,g) --memory-swap=value(b,k,m,g) image:tag</code></p> <p>Example: <code>docker container run --memory=1g --memory-swap=2g nginx:latest</code> (With memory-swap you can also define swap space. b=byte, k=kilobyte, m=megabyte, g=gigabyte)</p> <p>Limiting container CPU usage (--cpus, --cpuset-cpus):</p> <p><code>docker container run --cpus=\"number_of_cores\" image:tag</code></p> <p>Example: <code>docker container run --cpus=\"3\" nginx:latest</code> (This limits the number of CPU cores the container can use)</p> <p><code>docker container run --cpuset-cpus=\"core_numbers\" image:tag</code></p> <p>Example: <code>docker container run --cpuset-cpus=\"0,4\" nginx:latest</code> (This sets which CPU cores the container can access)</p> <p>Setting environment variables for a container:</p> <p><code>docker container run --env environment_variable=value image:tag</code></p> <p>Example: <code>docker container run --env VAR1=test1 --env VAR2=test2 nginx:latest</code></p> <p>Copying files between container and host (both directions):</p> <p><code>docker cp container_id|or|container_name:path host_path</code></p> <p>Example: <code>docker cp 12a793b3fec0:/usr/src/app/ .</code></p>"},{"location":"docker/docker-examples/#image","title":"Image","text":"<p>Logging into a registry via Docker CLI:</p> <p><code>docker login registry_url</code></p> <p>Example: <code>docker login localhost:8080</code></p> <p>Pulling an image to the system:</p> <p><code>docker image pull image:tag</code></p> <p>Example: <code>docker image pull nginx:latest</code></p> <p>Pushing an image to Docker Hub (or another repository):</p> <p><code>docker image push repository/image:tag</code></p> <p>Example: <code>docker image push ozgurozturknet/adanzyedocker:latest</code></p> <p>Tagging an existing image with a new tag:</p> <p><code>docker image tag image:tag newimage:tag</code></p> <p>Example: <code>docker image tag nginx:latest ozgurozturknet/nginx:v1</code></p> <p>Inspecting image details:</p> <p><code>docker image inspect image:tag</code></p> <p>Example: <code>docker image inspect nginx:latest</code></p> <p>Listing image layers:</p> <p><code>docker image history image:tag</code></p> <p>Example: <code>docker image history nginx:latest</code></p> <p>Building a new image using Dockerfile:</p> <p><code>docker image build -t image:tag .</code></p> <p>Example: <code>docker image build -t ozgurozturknet/hello-world:latest .</code> (Dockerfile must be in the folder where this command is run)</p> <p>Using build args when building image:</p> <p><code>docker image build --build-arg arg=value -t image:tag .</code></p> <p>Example: <code>docker image build --build-arg VERSION=3.7.1 -t nginx:latest .</code></p> <p>Listing all images in the system:</p> <p><code>docker image ls</code></p> <p>Removing an image from the system:</p> <p><code>docker image rm image:tag</code></p> <p>Example: <code>docker image rm nginx:latest</code></p> <p>Creating an image from a container:</p> <p><code>docker commit container_id|or|container_name image:tag</code></p> <p>Example: <code>docker commit 12a793b3fec0 ozgurozturknet/img:latest</code></p> <p>Saving an image to a file and loading an image from a saved file:</p> <p><code>docker save image:tag -o filename.tar</code></p> <p>Example: <code>docker save ozgurozturknet/img:latest -o image.tar</code></p> <p><code>docker load -i filename.tar</code></p> <p>Example: <code>docker load -i imagecon1.tar</code></p>"},{"location":"docker/docker-examples/#volume","title":"Volume","text":"<p>Creating a volume:</p> <p><code>docker volume create volume_name</code></p> <p>Example: <code>docker volume create firstvolume</code></p> <p>Inspecting volume details:</p> <p><code>docker volume inspect volume_id|or|volume_name</code></p> <p>Example: <code>docker volume inspect firstvolume</code></p> <p>Listing all volumes in the system:</p> <p><code>docker volume ls</code></p> <p>Mounting a volume to a container (-v):</p> <p><code>docker container run -v volume_name:container_path image:tag</code></p> <p>Example: <code>docker container run -v firstvolume:/var/www/html image:tag</code></p> <p>Mounting a volume as read-only (:ro):</p> <p><code>docker container run -v volume_name:container_path:ro image:tag</code></p> <p>Example: <code>docker container run -v firstvolume:/var/www/html:ro image:tag</code></p> <p>Binding a host folder or file as a mount:</p> <p><code>docker container run -v host_folder_path:container_path image:tag</code></p> <p>Example: <code>docker container run -v c:\\websites:/usr/share/nginx/html nginx:latest</code></p> <p>Removing a volume:</p> <p><code>docker volume rm volume_name</code></p> <p>Example: <code>docker volume rm firstvolume</code></p>"},{"location":"docker/docker-examples/#network","title":"Network","text":"<p>Creating a user-defined bridge network (bridge):</p> <p><code>docker network create --driver=bridge network_name</code></p> <p>Example: <code>docker network create --driver=bridge bridge-net</code></p> <p>Creating a user-defined bridge network with IP settings:</p> <p><code>docker network create --driver=bridge --subnet=cidr --ip-range=cidr --gateway=ip_address network_name</code></p> <p>Example: <code>docker network create --driver=bridge --subnet=10.10.0.0/16 --ip-range=10.10.10.0/24 --gateway=10.10.10.10 bridge-net</code></p> <p>Listing all networks in the system:</p> <p><code>docker network ls</code></p> <p>Inspecting network details:</p> <p><code>docker network inspect network_name</code></p> <p>Example: <code>docker network inspect bridge-net</code></p> <p>Running a container connected to a non-default network:</p> <p><code>docker container run --network network_name image:tag</code></p> <p>Example: <code>docker container run --network bridge-net nginx:latest</code></p> <p>Connecting a running container to another network:</p> <p><code>docker network connect network_name container_id|or|container_name</code></p> <p>Example: <code>docker network connect bridge-net 12a793b3fec0</code></p> <p>Disconnecting a running container from a network:</p> <p><code>docker network disconnect network_name container_id|or|container_name</code></p> <p>Example: <code>docker network disconnect bridge-net 12a793b3fec0</code></p> <p>Running a container with published ports (-p):</p> <p><code>docker container run -p host_port:container_port/tcp_or_udp image:tag</code></p> <p>Example: <code>docker container run -p 8080:80 -p 53:53/udp nginx:latest</code></p>"},{"location":"docker/docker-examples/#logging","title":"Logging","text":"<p>Viewing logs created by a container:</p> <p><code>docker logs container_id|or|container_name</code></p> <p>Example: <code>docker logs 12a793b3fec0</code></p> <p>Viewing detailed logs in long format:</p> <p><code>docker logs --details container_id|or|container_name</code></p> <p>Example: <code>docker logs --details 12a793b3fec0</code></p> <p>Viewing logs within a specific date range:</p> <p><code>docker logs --since date_time --until date_time container_id|or|container_name</code></p> <p>Example: <code>docker logs --since 2020-01-13T11:34:43.154304300Z 12a793b3fec0</code> (since shows logs from the given time, until shows logs up to the given time)</p> <p>Viewing last N log entries:</p> <p><code>docker logs --tail number container_id|or|container_name</code></p> <p>Example: <code>docker logs --tail 10 12a793b3fec0</code> (lists the last 10 log entries)</p> <p>Following logs live:</p> <p><code>docker logs -f container_id|or|container_name</code></p> <p>Example: <code>docker logs -f 12a793b3fec0</code> (logs will show live as they occur; use Ctrl-C to exit)</p>"},{"location":"docker/docker-examples/#image-copy","title":"Image Copy","text":"<p>You can copy an image from one Docker Hub account to another using the following script.</p> <p>You need to change the <code>OLD_IMAGE</code> and <code>NEW_IMAGE</code> variables accordingly.</p> copy_image.sh <pre><code>#!/bin/bash\n\n# Old image (source)\nOLD_IMAGE=\"olduser/oldrepo:version\"\n\n# New image (destination)\nNEW_IMAGE=\"newuser/newrepo:version\"\n\n# 1. Pull the old image\ndocker pull $OLD_IMAGE\n\n# 2. Tag it with the new name\ndocker tag $OLD_IMAGE $NEW_IMAGE\n\n# 3. Log in to Docker Hub (will ask for password unless already logged in)\n#echo \"Please log in to your Docker account:\"\n#docker login -u newuser\n\n# 4. Push the new image\ndocker push $NEW_IMAGE\n\necho \"\u2705 Done! $NEW_IMAGE is now available under your new account.\"\n\n</code></pre> <p>Usage:</p> <pre><code>chmod +x copy_image.sh\n./copy_image.sh\n</code></pre>"},{"location":"docker/docker-examples/#references","title":"References","text":"<p>For more details, check the website.</p>"},{"location":"docker/docker-installation/","title":"Docker Installation","text":"<p>This guide helps you install Docker on Mac, Linux, and Windows, and also provides a link to try Docker online via Play with Docker.</p>"},{"location":"docker/docker-installation/#docker-on-mac","title":"Docker on Mac","text":"<p>Docker Desktop is the easiest way to install Docker on macOS. It includes both a GUI and CLI tools.</p> <p>Installation Steps:</p> <ol> <li>Download Docker Desktop from the official    site: Docker Desktop for Mac</li> <li>Open the downloaded <code>.dmg</code> file and drag Docker to the Applications folder.</li> <li>Launch Docker from Applications.</li> <li>Follow the onboarding instructions to finish the setup.</li> <li>Verify installation by opening Terminal and running:</li> </ol> <pre><code>docker --version\ndocker compose version\ndocker run hello-world\n</code></pre> <p>Optional: Install via Homebrew CLI (Not Recommended):</p> <p>If you prefer a CLI-only installation:</p> <pre><code>brew install docker docker-compose\n</code></pre>"},{"location":"docker/docker-installation/#docker-on-linux","title":"Docker on Linux","text":"<p>For Linux, it is recommended to follow the official installation instructions for your distribution to ensure you get the latest version.</p>"},{"location":"docker/docker-installation/#ubuntu-debian","title":"Ubuntu / Debian","text":"<p>Visit the official Docker guide: Docker Desktop for Ubuntu</p>"},{"location":"docker/docker-installation/#fedora-centos","title":"Fedora / CentOS","text":"<p>Visit the official Docker guide: Docker Desktop for Fedora</p>"},{"location":"docker/docker-installation/#after-installation","title":"After Installation","text":"<p>After installation, you may want to run Docker without <code>sudo</code>:</p> <pre><code>sudo usermod -aG docker $USER\nnewgrp docker\n</code></pre> <p>Verify installation by opening Terminal and running:</p> <pre><code>docker --version\ndocker compose version\ndocker run hello-world\n</code></pre>"},{"location":"docker/docker-installation/#docker-on-windows","title":"Docker on Windows","text":"<p>Docker Desktop is available for Windows 10/11 and includes both GUI and CLI tools.</p> <ol> <li>Download Docker Desktop    from: Docker Desktop for Windows</li> <li>Run the installer and follow the setup instructions.</li> <li>Verify installation in PowerShell or CMD:</li> </ol> <pre><code>docker --version\ndocker compose version\ndocker run hello-world\n</code></pre>"},{"location":"docker/docker-installation/#play-with-docker","title":"Play with Docker","text":"<p>If you want to try Docker without installing it locally:</p> <ul> <li>Go to https://labs.play-with-docker.com/</li> <li>Create a free account or login with Docker Hub.</li> <li>Launch a playground and start experimenting with Docker commands instantly.</li> </ul>"},{"location":"docker/docker-installation/#references","title":"References","text":"<ul> <li>Official Docker Documentation</li> <li>Docker announcement on Wikipedia</li> <li>The Future of Linux Containers - YouTube Video</li> <li>Linux Kernel Overview</li> <li>What is an Operating System? - Techopedia</li> <li>Everything You Need to Know About Linux Containers - Linux Journal</li> <li>Cgroups - Wikipedia</li> <li>Linux Namespaces - Wikipedia</li> <li>Docker Engine Overview</li> <li>Linux Kernel - Wikipedia</li> <li>LXC Containers - Wikipedia</li> <li>Docker Container Runtime</li> <li>History of Docker - TechTarget</li> <li>Docker Images - TechTarget</li> <li>Building Minimal Docker Containers for Go Applications</li> </ul>"},{"location":"git/git-cheatsheet/","title":"Git Cheatsheet","text":""},{"location":"git/git-cheatsheet/#setup-and-configuration","title":"Setup and Configuration","text":"<p>Set user name:</p> <p><code>git config --global user.name \"yourusername\"</code></p> <p>Set user email:</p> <p><code>git config --global user.email \"youremail@mail.com\"</code></p> <p>Manage Personal Access Token info: GitHub PAT Docs</p>"},{"location":"git/git-cheatsheet/#repository-initialization","title":"Repository Initialization","text":"<p>Initialize Git repository:</p> <p><code>git init</code></p> <p>Clone repository:</p> <ul> <li> <p>Via https: <code>git clone https://github.com/yourusername/yourrepo.git your-new-directory</code></p> </li> <li> <p>Via ssh: <code>git clone git@github.com:yourusername/yourrepo.git your-new-directory</code></p> </li> </ul>"},{"location":"git/git-cheatsheet/#staging-and-committing","title":"Staging and Committing","text":"<p>Check the status of changes:</p> <p><code>git status</code></p> <p>Stage a file:</p> <p><code>git add README.md</code></p> <p>Stage multiple files:</p> <p><code>git add README.md index.html</code></p> <p>Stage all changes (excluding ignored):</p> <p><code>git add *</code></p> <p>or</p> <p><code>git add .</code></p> <p>Unstage a file:</p> <p><code>git rm --cached .vscode</code></p> <p>Unstage multiple files:</p> <p><code>git rm --cached -r .vscode/ bin/</code></p> <p>Unstage all files:</p> <p><code>git rm -r --cached .</code></p> <p>Commit with the message:</p> <p><code>git commit -m \"initial commit\"</code></p> <p>Amend last commit with staged changes:</p> <p><code>git commit --amend --all</code></p> <p>Change commit message:</p> <p><code>git commit -am \"updated commit\" --amend</code></p>"},{"location":"git/git-cheatsheet/#branching-and-merging","title":"Branching and Merging","text":"<p>List branches:</p> <p><code>git branch</code></p> <p>Create new branch:</p> <p><code>git branch feature-restructure</code></p> <p>Create the new branch and switch to it:</p> <p><code>git checkout -b feature-restructure</code></p> <p>Delete branch:</p> <p><code>git branch -D feature-restructure</code></p> <p>Rename branch:</p> <p><code>git branch -m feature-new-name</code></p> <p>Switch branch:</p> <p><code>git checkout $branch_name</code></p> <p>Merge branch into current branch:</p> <p><code>git merge feature-restructure</code></p>"},{"location":"git/git-cheatsheet/#working-with-commits","title":"Working with Commits","text":"<p>View commit history:</p> <p><code>git log</code></p> <p>Checkout specific commit:</p> <p><code>git checkout $commit_id</code></p> <p>Hard reset to commit (WARNING: discards changes):</p> <p><code>git reset --hard $commit_id</code></p> <p>Soft reset to commit:</p> <p><code>git reset --soft HEAD~</code></p> <p>Unstage file with restore:</p> <p><code>git restore --staged index.html</code></p> <p>Discard changes in working directory:</p> <p><code>git restore index.html</code></p>"},{"location":"git/git-cheatsheet/#remote-repositories","title":"Remote Repositories","text":"<p>Add remote URL:</p> <p><code>git remote add origin https://github.com/yourusername/yourrepo.git</code></p> <p>Remove remote URL:</p> <p><code>git remote remove origin</code></p> <p>Change remote URL:</p> <p><code>git remote set-url origin https://github.com/yourusername/yourrepo.git</code></p> <p>Show remote URL:</p> <p><code>git remote get-url origin</code></p>"},{"location":"git/git-cheatsheet/#pushing-and-pulling","title":"Pushing and Pulling","text":"<p>Push to remote branch:</p> <p><code>git push origin master</code></p> <p>Push and set upstream:</p> <p><code>git push --set-upstream origin main</code></p> <p>Push after the upstream set:</p> <p><code>git push</code></p> <p>Pull with rebase:</p> <p><code>git pull --rebase origin master</code></p> <p>Set upstream branch for current branch:</p> <p><code>git branch --set-upstream-to=origin/master</code></p> <p>Pull after the upstream set:</p> <p><code>git pull</code></p>"},{"location":"git/git-cheatsheet/#miscellaneous","title":"Miscellaneous","text":"<ul> <li>Skip CI workflow by adding <code>[skip ci]</code> in the commit message</li> </ul> <p>Add <code>[skip ci]</code> anywhere in your git commit message to skip CI workflows.</p>"},{"location":"git/github-actions/","title":"GitHub Actions","text":""},{"location":"git/github-actions/#useful-links","title":"Useful Links","text":"<ul> <li>GitHub Actions Runners</li> <li>GitHub Actions Events</li> <li>GitHub Actions Events Filters</li> <li>GitHub Actions Workflow Skip</li> <li>GitHub Actions Contexts</li> <li>GitHub Actions Expressions</li> <li>GitHub Actions Workflow Syntax</li> <li>GitHub Actions Default Environment Variables</li> <li>GitHub Actions Reuse Workflows</li> </ul>"},{"location":"git/github-actions/#storing-actions-in-repositories-sharing-actions-with-others","title":"Storing Actions in Repositories &amp; Sharing Actions with Others","text":"<p>In this section, we explain how to create and share custom Actions stored in separate repositories, instead of keeping them inside the same repository as your workflows.</p>"},{"location":"git/github-actions/#how-to-create-and-share-a-custom-action-in-its-own-repository","title":"How to create and share a custom Action in its own repository:","text":"<ol> <li> <p>Create a new local project folder    This folder should contain your action.yml file and all the code needed for your Action. Important: Do not put your action.yml or code inside a .github/actions folder or similar. Keep everything at the    root level of your new project folder.</p> </li> <li> <p>Initialize a Git repository    Run the following command inside your project folder:</p> </li> </ol> <p><code>git init</code></p> <ol> <li>Add and commit your files</li> </ol> <p><code>git add .</code></p> <p><code>git commit -m \"Initial commit for my custom Action\"</code></p> <ol> <li> <p>Create a GitHub repository    Create a new repository on GitHub to host your Action.</p> </li> <li> <p>Connect your local repo to GitHub remote</p> </li> </ol> <p><code>git remote add origin https://github.com/my-account/my-action.git</code></p> <ol> <li>Tag a release version    It's a good practice to tag your Action versions for reuse:</li> </ol> <p><code>git tag -a -m \"My action release\" v1</code></p> <ol> <li>Push your code and tags to GitHub</li> </ol> <p><code>git push --follow-tags origin main</code></p> <ol> <li>Use your custom Action in workflows    Reference your custom Action in any other workflow by specifying the repository and tag, like this:</li> </ol> <p><code>uses: my-account/my-action@v1</code></p>"},{"location":"git/list-github-actions/","title":"List GitHub Actions","text":"<p>This script scans a given GitHub Actions workflow file or an entire folder containing multiple workflow files, and lists all jobs and their steps.</p>"},{"location":"git/list-github-actions/#requirements","title":"Requirements","text":"<p>Install dependencies before running the script:</p> <pre><code>   python3 -m venv .venv\n   source .venv/bin/activate\n   pip install pyyaml\n</code></pre>"},{"location":"git/list-github-actions/#1-single-file-usage","title":"1. Single File Usage","text":"<p>If you want to list jobs and steps from a single GitHub Actions workflow file:</p>"},{"location":"git/list-github-actions/#script","title":"Script","text":"list_github_actions.py <pre><code>import argparse\nimport yaml\n\n\ndef main(filepath):\n    with open(filepath, 'r') as file:\n        workflow = yaml.safe_load(file)\n\n    # List jobs and steps\n    for job_name, job in workflow['jobs'].items():\n        print(f\"Job: {job_name}\")\n        for step in job['steps']:\n            print(f\"  Step: {step['name']}\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='List GitHub Actions jobs and steps')\n    parser.add_argument('filepath', type=str, help='Path to the GitHub Actions workflow file')\n    args = parser.parse_args()\n    main(args.filepath)\n</code></pre>"},{"location":"git/list-github-actions/#run","title":"Run","text":"<pre><code>python3 list_github_actions.py .github/workflows/test-workflow.yaml\n</code></pre>"},{"location":"git/list-github-actions/#2-folder-usage","title":"2. Folder Usage","text":"<p>If you want to scan all workflow files inside a folder:</p>"},{"location":"git/list-github-actions/#script_1","title":"Script","text":"list_github_actions.py <pre><code>import argparse\nimport os\nimport yaml\n\n\ndef list_jobs_and_steps(filepath):\n    with open(filepath, 'r') as file:\n        workflow = yaml.safe_load(file)\n\n    # List jobs and steps\n    for job_name, job in workflow['jobs'].items():\n        print(f\"Job: {job_name}\")\n        for step in job['steps']:\n            print(f\"  Step: {step['name']}\")\n\n\ndef main(folder_path):\n    for filename in os.listdir(folder_path):\n        if filename.endswith('.yml') or filename.endswith('.yaml'):\n            filepath = os.path.join(folder_path, filename)\n            print(f\"\\nProcessing file: {filepath}\")\n            list_jobs_and_steps(filepath)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='List GitHub Actions jobs and steps from a folder')\n    parser.add_argument('folderpath', type=str, help='Path to the folder containing GitHub Actions workflow files')\n    args = parser.parse_args()\n    main(args.folderpath)\n</code></pre>"},{"location":"git/list-github-actions/#run_1","title":"Run","text":"<pre><code>python3 list_github_actions.py .github/workflows/\n</code></pre>"},{"location":"git/list-github-actions/#example-output","title":"Example Output","text":"<pre><code>Processing file: .github/workflows/test-workflow.yaml\nJob: build\n  Step: Checkout code\n  Step: Set up Python\n  Step: Install dependencies\n  Step: Run tests\n</code></pre>"},{"location":"git/list-github-actions/#notes","title":"Notes","text":"<ul> <li>Works with both .yml and .yaml files.</li> <li>Ignores files without jobs in the workflow.</li> <li>Helpful for quickly auditing workflow configurations.</li> </ul>"},{"location":"git/tmate/","title":"Tmate","text":"<p>tmate is a tool that lets you connect to a running GitHub Actions runner via SSH, allowing real-time interactive debugging.</p>"},{"location":"git/tmate/#what-is-tmate","title":"What is tmate?","text":"<ul> <li>Remote Terminal Access: Opens a secure SSH session into the CI environment.</li> <li>Runs in GitHub Actions: No local installation required.</li> <li>Interactive Debugging: Lets you explore the runner\u2019s file system, run commands, and investigate issues live.</li> </ul>"},{"location":"git/tmate/#why-use-tmate","title":"Why use tmate?","text":"<ul> <li>Inspect the actual environment where your workflow runs.</li> <li>Reproduce issues interactively instead of guessing.</li> <li>Check environment variables, installed tools, or file contents.</li> <li>Debug complex CI problems more efficiently.</li> </ul>"},{"location":"git/tmate/#how-to-enable-tmate-in-github-actions","title":"How to Enable tmate in GitHub Actions","text":"<p>Add this step anywhere in your workflow where you want to pause and debug:</p> <pre><code>- name: Setup tmate session\n  uses: mxschmitt/action-tmate@v3\n</code></pre>"},{"location":"git/tmate/#connecting-to-the-runner","title":"Connecting to the Runner","text":"<ol> <li>Run the workflow.</li> <li>When it reaches the <code>Setup tmate session</code> step, GitHub Actions logs will display:<ul> <li>An SSH command to connect from your terminal.</li> <li>A Web URL to connect via browser terminal.</li> </ul> </li> <li>Use the SSH command in your terminal:    <code>bash    ssh &lt;connection_string&gt; # ssh AVmfLLaAuYmMAhg3JX6YUWkBE@nyc1.tmate.io</code></li> <li>Once connected, you have full terminal access to the runner.</li> </ol>"},{"location":"git/tmate/#ending-the-session","title":"Ending the Session","text":"<ul> <li>Type <code>exit</code> in the SSH terminal to close the session.</li> <li>The workflow will then continue to the next step.</li> </ul>"},{"location":"git/tmate/#notes","title":"Notes","text":"<ul> <li>The SSH session is temporary and only exists while the workflow is paused at the tmate step.</li> <li>Make sure sensitive data is handled carefully \u2014 anyone with the SSH link can access the runner.</li> </ul>"},{"location":"git/tmate/#references","title":"References","text":"<ul> <li>tmate GitHub Action</li> <li>tmate Official Website</li> <li>Debugging with tmate - GitHub Docs</li> </ul>"},{"location":"java/jenv/","title":"jEnv - Java Version Manager","text":"<p>jEnv is a command-line tool that helps you manage multiple Java versions easily. jEnv is a command line tool to help you forget how to set the JAVA_HOME environment variable</p>"},{"location":"java/jenv/#1-install-jenv","title":"1. Install jEnv","text":"<pre><code>brew install jenv\n</code></pre>"},{"location":"java/jenv/#2-configure-your-shell","title":"2. Configure your shell","text":"<p>Add jEnv to your shell environment:</p>"},{"location":"java/jenv/#bash","title":"Bash","text":"<pre><code>echo 'export PATH=\"$HOME/.jenv/bin:$PATH\"' &gt;&gt; ~/.bash_profile\necho 'eval \"$(jenv init -)\"' &gt;&gt; ~/.bash_profile\nsource ~/.bash_profile # Reload the shell\n</code></pre>"},{"location":"java/jenv/#zsh","title":"Zsh","text":"<pre><code>echo 'export PATH=\"$HOME/.jenv/bin:$PATH\"' &gt;&gt; ~/.zshrc\necho 'eval \"$(jenv init -)\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc # Reload the shell\n</code></pre>"},{"location":"java/jenv/#3-enable-the-export-plugin","title":"3. Enable the export plugin","text":"<p>Enable plugins to automatically set <code>JAVA_HOME</code> and integrate with Maven:</p> <pre><code>eval \"$(jenv init -)\"\njenv enable-plugin export\njenv enable-plugin maven\n</code></pre> <p>Restart your shell:</p> <pre><code>exec $SHELL -l\n</code></pre>"},{"location":"java/jenv/#4-add-jdksjres","title":"4. Add JDKs/JREs","text":"<p>Make sure the paths match the JDKs you have installed.</p> <pre><code>jenv add /System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home\njenv add /Library/Java/JavaVirtualMachines/jdk17011.jdk/Contents/Home\njenv add /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home \njenv add /Library/Java/JavaVirtualMachines/jdk-21.jdk/Contents/Home\n</code></pre>"},{"location":"java/jenv/#5-list-managed-jdks","title":"5. List managed JDKs","text":"<pre><code>$ jenv versions\n  system\n  oracle64-1.6.0.39\n* oracle64-1.7.0.11 (set by /Users/hikage/.jenv/version)\n</code></pre>"},{"location":"java/jenv/#6-configure-global-version","title":"6. Configure global version","text":"<pre><code>jenv global oracle64-1.6.0.39\n</code></pre>"},{"location":"java/jenv/#7-configure-local-version-per-directory","title":"7. Configure local version (per directory)","text":"<pre><code>jenv local oracle64-1.6.0.39\n</code></pre>"},{"location":"java/jenv/#8-configure-shell-instance-version","title":"8. Configure shell instance version","text":"<pre><code>jenv shell oracle64-1.6.0.39\n</code></pre>"},{"location":"java/jenv/#9-verify","title":"9. Verify","text":"<p>Verify the current jenv version:</p> <pre><code>jenv version\n</code></pre> <p>Example output:</p> <pre><code>21.0 (set by /Users/youruser/.jenv/version)\n</code></pre> <p>Verify the current Java version:</p> <pre><code>java -version\n</code></pre> <p>Example output:</p> <pre><code>java version \"21.0.4\" 2024-07-16 LTS\nJava(TM) SE Runtime Environment (build 21.0.4+8-LTS-274)\nJava HotSpot(TM) 64-Bit Server VM (build 21.0.4+8-LTS-274, mixed mode, sharing)\n</code></pre> <p>Verify the java version on maven:</p> <pre><code>mvn -version\n</code></pre> <p>Example output:</p> <pre><code>Apache Maven 3.9.6\nJava version: 21.0.4, vendor: Oracle Corporation\n</code></pre>"},{"location":"java/jenv/#troubleshooting","title":"Troubleshooting","text":"<p>Problem:</p> <pre><code>/Users/username/.jenv/shims/java: line 21: /usr/local/Cellar/jenv/0.5.6/libexec/libexec/jenv: No such file or directory\n</code></pre> <p>Solution: Refer to the GitHub issue #394:</p> <pre><code>jenv --version\njenv rehash\n</code></pre> <p>If <code>.jenv-shim</code> exists and causes errors, rename it, then run:</p> <pre><code>jenv rehash\n</code></pre>"},{"location":"java/jenv/#references","title":"References","text":"<p>For more details, check the official website: https://www.jenv.be</p>"},{"location":"java/sdkman/","title":"SDKMAN! - Java Version Manager","text":"<p>SDKMAN! is a tool for managing parallel versions of multiple Software Development Kits on most Unix-based systems. It provides a convenient way to install, switch, and manage SDKs such as Java, Groovy, Kotlin, Scala, and more.</p>"},{"location":"java/sdkman/#installing-sdkman","title":"Installing SDKMAN!","text":"<p>To install SDKMAN!, open your terminal and run:</p> <pre><code>brew install sdkman-cli\n</code></pre>"},{"location":"java/sdkman/#configuring-your-shell","title":"Configuring Your Shell","text":"<p>To ensure SDKMAN! works correctly, you need to add initialization to your shell profile. For Bash or Zsh, append the following lines at the end of your profile file (<code>~/.bash_profile</code>, <code>~/.bashrc</code>, or <code>~/.zshrc</code>):</p> <pre><code>#THIS MUST BE AT THE END OF THE FILE FOR SDKMAN TO WORK!!!\nexport SDKMAN_DIR=\"$HOME/.sdkman\"\n[[ -s \"$HOME/.sdkman/bin/sdkman-init.sh\" ]] &amp;&amp; source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n</code></pre> <p>After adding these lines, apply the changes with:</p> <pre><code>source ~/.bash_profile (or 'source ~/.bashrc' or 'source ~/.zshrc' depending on your shell)\n</code></pre> <p>You can verify that SDKMAN! is installed correctly by executing:</p> <pre><code>sdk version\n</code></pre>"},{"location":"java/sdkman/#listing-available-sdks","title":"Listing Available SDKs","text":"<p>To see all SDKs available for installation, use:</p> <pre><code>sdk list\n</code></pre> <p>This will display a list of candidates, versions, and whether they are installed on your system.</p>"},{"location":"java/sdkman/#listing-available-versions-for-a-specific-sdk","title":"Listing Available Versions for a Specific SDK","text":"<p>To see all available versions of a specific SDK, such as Java, run:</p> <pre><code>sdk list java\n</code></pre> <p>This will display all Java versions you can install, along with the currently installed and default versions.</p>"},{"location":"java/sdkman/#installing-a-specific-sdk","title":"Installing a Specific SDK","text":"<p>To install a specific version of an SDK, use:</p> <pre><code>sdk install &lt;candidate&gt; &lt;version&gt;\n</code></pre> <p>Example:</p> <pre><code>sdk install java 21.0.4-tem\n</code></pre>"},{"location":"java/sdkman/#installing-latest-sdk","title":"Installing Latest SDK","text":"<p>To install the latest version of an SDK, use:</p> <pre><code>sdk install &lt;candidate&gt;\n</code></pre> <p>Example:</p> <pre><code>sdk install java\n</code></pre>"},{"location":"java/sdkman/#switching-between-versions","title":"Switching Between Versions","text":"<p>You can switch to a different installed version with:</p> <pre><code>sdk use &lt;candidate&gt; &lt;version&gt;\n</code></pre> <p>Example:</p> <pre><code>sdk use java 21.0.4-tem\n</code></pre> <p>Or set it as the default version:</p> <pre><code>sdk default &lt;candidate&gt; &lt;version&gt;\n</code></pre> <p>Example:</p> <pre><code>sdk default java 21.0.4-tem\n</code></pre>"},{"location":"java/sdkman/#updating-sdkman","title":"Updating SDKMAN!","text":"<p>Keep your SDKMAN! installation up-to-date by running:</p> <pre><code>sdk update\n</code></pre>"},{"location":"java/sdkman/#uninstalling-sdks","title":"Uninstalling SDKs","text":"<p>To remove an installed SDK, use:</p> <pre><code>sdk uninstall &lt;candidate&gt; &lt;version&gt;\n</code></pre> <p>Example:</p> <pre><code>sdk uninstall java 21.0.4-tem\n</code></pre>"},{"location":"java/sdkman/#conclusion","title":"Conclusion","text":"<p>SDKMAN! simplifies the management of multiple SDKs on your system, allowing you to install, switch, and maintain different versions effortlessly. By mastering these commands and correctly configuring your shell, you can ensure that your development environment is flexible and up-to-date.</p> <p>For more detailed usage instructions, please refer to the official SDKMAN! usage guide: https://sdkman.io/usage</p>"},{"location":"kubernetes/kubernetes-installation/","title":"Kubernetes Installation","text":"<p>All commands are given through kube-apiserver. These commands can be given in 3 ways:</p> <ol> <li>Through REST Api (as curl from terminal, etc.),</li> <li>Through Kubernetes GUI (Dashboard, Lens, Octant),</li> <li>Through Kubectl (CLI).</li> </ol>"},{"location":"kubernetes/kubernetes-installation/#kubectl-installation","title":"Kubectl Installation","text":"<p>For installation details, you can check the kubectl documentation.</p>"},{"location":"kubernetes/kubernetes-installation/#kubernetes-installation_1","title":"Kubernetes Installation","text":""},{"location":"kubernetes/kubernetes-installation/#which-version-will-we-install","title":"Which version will we install?","text":"<ul> <li>For the most light-weight version -&gt; minikube, Docker Desktop (Single Node K8s Cluster)</li> <li>Other options -&gt; kubeadm, kubespray</li> <li>Cloud solutions -&gt; Azure Kubernetes Service (AKS), Google Kubernetes Engine, Amazon EKS</li> </ul>"},{"location":"kubernetes/kubernetes-installation/#docker-desktop","title":"Docker Desktop","text":"<ul> <li>Docker Desktop allows you to set up a Single Node Kubernetes Cluster. This situation gives you the ability to   perform operations on Kubernetes without needing another tool. But the recommendation is to use minikube!</li> <li>For K8s installation within Docker Desktop, you need to go to <code>Settings &gt; Kubernetes</code> and enable it.</li> </ul>"},{"location":"kubernetes/kubernetes-installation/#minikube","title":"Minikube","text":"<p>For installation details, you can check the minikube documentation.</p>"},{"location":"kubernetes/kubernetes-installation/#kubeadm-installation","title":"kubeadm Installation","text":"<p>It's another platform that allows us to create a Kubernetes cluster. It's more advanced than minikube.</p> <p>For installation details, you can check the kubeadm documentation.</p>"},{"location":"kubernetes/kubernetes-installation/#installation-on-aws","title":"Installation on AWS","text":"<ul> <li>Amazon EKS is the service that allows you to create a Kubernetes cluster on AWS.</li> </ul>"},{"location":"kubernetes/kubernetes-installation/#installation-on-azure","title":"Installation on Azure","text":"<ul> <li>Azure Kubernetes Service (AKS) is the service that allows you to create a Kubernetes cluster on Azure.</li> </ul>"},{"location":"kubernetes/kubernetes-installation/#installation-on-google-cloud-platform","title":"Installation on Google Cloud Platform","text":"<ul> <li>Google Kubernetes Engine (GKE) is the service that allows you to create a Kubernetes cluster on Google Cloud   Platform.</li> </ul>"},{"location":"kubernetes/kubernetes-installation/#play-with-kubernetes-installation","title":"Play-with-kubernetes Installation","text":"<ul> <li>If you don't want to give your credit card for cloud or want to quickly do some experiments,   play-with-kubernetes is perfect for you.</li> <li>There's a 4-hour usage limit. After 4 hours, the system resets, settings are lost.</li> <li>It works browser-based.</li> <li>You can create a total max of 5 nodes.</li> </ul>"},{"location":"kubernetes/kubernetes-installation/#tools","title":"Tools","text":"<ul> <li>Lens --&gt; A very well-prepared management tool for Kubernetes. For other dashboard tools, you can check   the Dashboards documentation.</li> <li>kubectx --&gt; For quick config/context switching.</li> <li>Krew --&gt; Plugin-sets for kubectl</li> </ul>"},{"location":"kubernetes/kubernetes-installation/#references","title":"References","text":"<ul> <li>Kubernetes Official Installation Tools</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-introduction/","title":"Kubernetes Introduction","text":""},{"location":"kubernetes/kubernetes-introduction/#why-is-it-necessary","title":"Why is it Necessary?","text":"<p>Let's go through an example:</p> <p>Let's think of a docker environment where multiple microservices are running. Let's assume that each microservice runs in a docker container and we expose our application to users. Our application is currently running on a single server, and when we make updates on the server, interruptions will start to occur in the system.</p> <p>To solve this problem, we rented a new server, set up the same docker environment (cloned it), and installed a load balancer to transition to a distributed architecture. Despite this, docker containers shut down on their own and we need to manually intervene in this situation. Since we received more traffic, we rented 2 more servers. 2 more servers, 2 more servers..</p> <p>We continue to manage all these servers manually. Over time, we started spending too much time on DevOps processes due to manual intervention, and there was no time left for other tasks.</p> <p>So what will solve this situation? Answer -&gt; Container Orchestration!</p> <p>We can set up all system configurations and entrust this decision mechanism to an orchestra conductor. This conductor is Kubernetes!</p> <p>Other alternatives -&gt; Docker Swarm, Apache H2o</p>"},{"location":"kubernetes/kubernetes-introduction/#k8s-history","title":"K8s History","text":"<ul> <li>Orchestration system developed by Google.</li> <li>Google has been using Linux containers for many years. To manage all these containers, they developed a platform   called Borg. However, errors emerged over time and a need for a new platform arose, and the Omega platform was   developed.</li> <li>In 2013, 3 Google engineers opened the Kubernetes repo on GitHub as open-source. Kubernetes: Sea helmsman (k8s)</li> <li>In 2014, the project was donated by Google to CNCF. (Cloud Native Computing Foundation)</li> </ul>"},{"location":"kubernetes/kubernetes-introduction/#what-is-kubernetes","title":"What is Kubernetes?","text":"<ul> <li>Declarative (declarative configuration), Container orchestration platform.</li> <li>The project is not tied to any company, it is managed by a foundation.</li> <li>It's free. Competitor companies are also open-source.</li> <li>The reason it's so popular is the platform's design and solution approach.</li> <li>It follows semantic versioning (x.y.z. -&gt; x: major, y: minor, z: patch) and releases a minor version every 4 months.</li> <li>It releases a patch version every month.</li> <li>A kubernetes platform can be used for a maximum of 1 year, after 1 year it needs to be updated.</li> </ul>"},{"location":"kubernetes/kubernetes-introduction/#kubernetes-design-and-approach","title":"Kubernetes Design and Approach","text":"<p>It consists of multiple developable modules. Each of these modules has a task and all modules focus on their own tasks. These modules or new modules can be developed when needed. (extendable)</p> <p>Instead of telling us step by step what we need to do like \"Do this, then do that\" (imperative method); K8s offers the approach of \"I want something like this\" (declarative method). It doesn't describe how to do it, we tell it what we want.</p> <ul> <li>The imperative method causes us to waste time, we have to design all the steps.</li> <li>In the declarative method, we just tell it what we want and look at the result.</li> </ul> <p>Kubernetes asks us what we want from it, we tell it, and it doesn't deviate from what we want. For example, let's say the Desired State (Declared State - Think of it as requests) is as follows:</p> <ul> <li>Create an image named Example/k8s:latest and run it with 10 containers. Open port 80 to the outside world and when I   make an update to this service, execute it on 2 tasks simultaneously and wait 10 seconds.</li> </ul> <p>If Kubernetes has 9 containers running, it immediately starts one more container and optimizes the platform according to our requests. This saves us from a very big job. (Remember, we were starting it manually in Docker.)</p>"},{"location":"kubernetes/kubernetes-introduction/#kubernetes-components","title":"Kubernetes Components","text":"<p>K8s was created considering microservice architecture.</p> <p></p> <p></p>"},{"location":"kubernetes/kubernetes-introduction/#control-plane-master-nodes","title":"Control Plane (Master Nodes)","text":"<p>The following 4 components make up the k8s management part and run on the master-node.</p> <ul> <li>Master-node -&gt; Where management modules run.</li> <li>Worker-node -&gt; Where the workload runs.</li> </ul> <p> </p> <ul> <li>kube-apiserver (api) \u2013&gt; The brain of K8s, the main communication center, entry point. We can call it a   kind of Gateway. All components and nodes communicate through kube-apiserver. Also, kube-apiserver   provides communication between the outside world and the platform. It is the only component that can communicate   with everyone to this extent. It handles Authentication and Authorization.</li> <li>etcd -&gt; All cluster data, metadata information, and information about components and objects created in the   Kubernetes platform are stored here. A kind of Archive room. etcd stores data in key-value format. Other   components cannot communicate directly with etcd. They do this communication through kube-apiserver.</li> <li>kube-scheduler (sched) -&gt; Where K8s work planning is done. It monitors newly created or unassigned Pods and   selects a node for them to run on. (Pod = container) When making this selection, it evaluates various parameters   such as CPU, Ram, etc. and decides which node is most suitable for the pod through a selection algorithm.</li> <li>kube-controller-manager (c-m) -&gt; The structure where K8s controls are performed. It checks whether there is a   difference between the current state and the desired state. For example; you requested 3 clusters and k8s   accomplished this. But a problem occurred and 2 containers remained. kube-controller comes into play here and   immediately starts one more cluster. Although it is compiled as a single binary, it contains many controllers:<ul> <li>Node Controller,</li> <li>Job Controller,</li> <li>Service Account &amp; Token Controller,</li> <li>Endpoints Controller.</li> </ul> </li> </ul>"},{"location":"kubernetes/kubernetes-introduction/#worker-nodes","title":"Worker Nodes","text":"<p>These are where our containers run. They run containers like Container or Docker. Each worker node has 3 basic components:</p> <ol> <li>Container runtime -&gt; Docker by default. But for various reasons, it has transitioned from Docker to Containerd    . The difference between Docker and containerd is minimal enough to say there's no difference. In fact, Docker also    uses containerd internally. Another supported container type is CRI-O.</li> <li>kubelet -&gt; It controls etcd through the API Server and creates pods that need to run on its node as determined by    the scheduler. It sends a message to Containerd and ensures that a container runs with the specified properties.</li> <li>kube-proxy -&gt; It manages network rules and traffic flow on nodes. It allows and monitors communication with Pods.</li> </ol> <p>In addition to all these, plugins that provide GUI services, etc. are also installed.</p>"},{"location":"kubernetes/kubernetes-introduction/#references","title":"References","text":"<ul> <li>Kubernetes Official Components Overview</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/","title":"Kubernetes Objects - Affinity, Taints, and Tolerations","text":""},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#overview","title":"Overview","text":"<p>Affinity, Taints, and Tolerations are mechanisms in Kubernetes that control how Pods are scheduled on nodes. They help ensure Pods run on appropriate nodes and prevent unwanted scheduling.</p>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#node-affinity","title":"Node Affinity","text":""},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#purpose","title":"Purpose","text":"<p>Node Affinity allows you to specify rules that determine which nodes a Pod can be scheduled on.</p>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#basic-example","title":"Basic Example","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: affinity-pod\nspec:\n  containers:\n  - name: app\n    image: nginx\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: kubernetes.io/os\n            operator: In\n            values:\n            - linux\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#pod-affinity","title":"Pod Affinity","text":""},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#purpose_1","title":"Purpose","text":"<p>Pod Affinity allows Pods to be scheduled near other Pods based on labels.</p>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#basic-example_1","title":"Basic Example","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod-affinity\n  labels:\n    app: web\nspec:\n  containers:\n  - name: app\n    image: nginx\n  affinity:\n    podAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - labelSelector:\n          matchExpressions:\n          - key: app\n            operator: In\n            values:\n            - database\n        topologyKey: kubernetes.io/hostname\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#pod-anti-affinity","title":"Pod Anti-Affinity","text":""},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#purpose_2","title":"Purpose","text":"<p>Pod Anti-Affinity prevents Pods from being scheduled on the same node.</p>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#basic-example_2","title":"Basic Example","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: anti-affinity-pod\n  labels:\n    app: web\nspec:\n  containers:\n  - name: app\n    image: nginx\n  affinity:\n    podAntiAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 100\n        podAffinityTerm:\n          labelSelector:\n            matchExpressions:\n            - key: app\n              operator: In\n              values:\n              - web\n          topologyKey: kubernetes.io/hostname\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#taints-and-tolerations","title":"Taints and Tolerations","text":""},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#purpose_3","title":"Purpose","text":"<p>Taints allow nodes to repel Pods that don't tolerate the taint. Tolerations allow Pods to be scheduled on tainted nodes.</p>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#node-taint","title":"Node Taint","text":"<pre><code># Add taint to node\nkubectl taint nodes &lt;node-name&gt; key=value:NoSchedule\n\n# Remove taint from node\nkubectl untaint nodes &lt;node-name&gt; key:NoSchedule-\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#pod-with-toleration","title":"Pod with Toleration","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: toleration-pod\nspec:\n  containers:\n  - name: app\n    image: nginx\n  tolerations:\n  - key: \"key\"\n    operator: \"Equal\"\n    value: \"value\"\n    effect: \"NoSchedule\"\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#database-pods-on-specific-nodes","title":"Database Pods on Specific Nodes","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: database\n  labels:\n    app: database\nspec:\n  containers:\n  - name: mysql\n    image: mysql\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: node-type\n            operator: In\n            values:\n            - database\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#web-pods-spread-across-nodes","title":"Web Pods Spread Across Nodes","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n  affinity:\n    podAntiAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n      - labelSelector:\n          matchExpressions:\n          - key: app\n            operator: In\n            values:\n            - web\n        topologyKey: kubernetes.io/hostname\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#basic-commands","title":"Basic Commands","text":"<pre><code># Add taint to node\nkubectl taint nodes &lt;node-name&gt; key=value:NoSchedule\n\n# Remove taint\nkubectl untaint nodes &lt;node-name&gt; key:NoSchedule-\n\n# Check node taints\nkubectl describe node &lt;node-name&gt;\n\n# Check pod affinity\nkubectl describe pod &lt;pod-name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/affinity-taint-toleration/#references","title":"References","text":"<ul> <li>Kubernetes Affinity and Anti-affinity</li> <li>Kubernetes Taints and Tolerations</li> <li>GitHub - Aytitech K8sFundamentals - Affinity</li> </ul>"},{"location":"kubernetes/kubernetes-objects/authentication/","title":"Kubernetes Objects - Authentication","text":""},{"location":"kubernetes/kubernetes-objects/authentication/#overview","title":"Overview","text":"<p>Authentication in Kubernetes determines who can access the cluster. It verifies the identity of users and service accounts before allowing access to cluster resources.</p>"},{"location":"kubernetes/kubernetes-objects/authentication/#authentication-methods","title":"Authentication Methods","text":""},{"location":"kubernetes/kubernetes-objects/authentication/#client-certificates","title":"Client Certificates","text":"<p>The most common authentication method using X.509 certificates.</p>"},{"location":"kubernetes/kubernetes-objects/authentication/#generate-private-key","title":"Generate Private Key","text":"<pre><code># Generate private key\nopenssl genrsa -out &lt;username&gt;.key 2048\n\n# Example:\nopenssl genrsa -out john.key 2048\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#generate-certificate-signing-request-csr","title":"Generate Certificate Signing Request (CSR)","text":"<pre><code># Generate CSR\nopenssl req -new -key &lt;username&gt;.key -out &lt;username&gt;.csr -subj \"/CN=&lt;username&gt;/O=&lt;group&gt;\"\n\n# Example:\nopenssl req -new -key john.key -out john.csr -subj \"/CN=john/O=developers\"\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#submit-csr-to-kubernetes","title":"Submit CSR to Kubernetes","text":"<pre><code># Submit CSR\ncat &lt;username&gt;.csr | base64 | tr -d '\\n' | kubectl apply -f -\n\n# Example:\ncat john.csr | base64 | tr -d '\\n' | kubectl apply -f -\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#approve-csr","title":"Approve CSR","text":"<pre><code># Approve CSR\nkubectl certificate approve &lt;username&gt;-&lt;hash&gt;\n\n# Example:\nkubectl certificate approve john-abc123\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#extract-certificate","title":"Extract Certificate","text":"<pre><code># Extract approved certificate\nkubectl get csr &lt;username&gt;-&lt;hash&gt; -o jsonpath='{.status.certificate}' | base64 -d &gt; &lt;username&gt;.crt\n\n# Example:\nkubectl get csr john-abc123 -o jsonpath='{.status.certificate}' | base64 -d &gt; john.crt\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#bearer-tokens","title":"Bearer Tokens","text":"<p>Simple token-based authentication for service accounts.</p>"},{"location":"kubernetes/kubernetes-objects/authentication/#create-service-account-token","title":"Create Service Account Token","text":"<pre><code># Create service account\nkubectl create serviceaccount &lt;serviceaccount-name&gt;\n\n# Create token\nkubectl create token &lt;serviceaccount-name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#configuration","title":"Configuration","text":""},{"location":"kubernetes/kubernetes-objects/authentication/#set-credentials","title":"Set Credentials","text":"<pre><code># Set credentials in kubeconfig\nkubectl config set-credentials &lt;username&gt; --client-certificate=&lt;username&gt;.crt --client-key=&lt;username&gt;.key\n\n# Example:\nkubectl config set-credentials john --client-certificate=john.crt --client-key=john.key\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#set-context","title":"Set Context","text":"<pre><code># Set context\nkubectl config set-context &lt;context-name&gt; --cluster=&lt;cluster-name&gt; --user=&lt;username&gt;\n\n# Example:\nkubectl config set-context john-context --cluster=minikube --user=john\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#use-context","title":"Use Context","text":"<pre><code># Switch to context\nkubectl config use-context &lt;context-name&gt;\n\n# Example:\nkubectl config use-context john-context\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#testing-authentication","title":"Testing Authentication","text":""},{"location":"kubernetes/kubernetes-objects/authentication/#check-permissions","title":"Check Permissions","text":"<pre><code># Test if user can perform action\nkubectl auth can-i create pods\nkubectl auth can-i delete pods --namespace=&lt;namespace&gt;\nkubectl auth can-i get secrets --as=&lt;user&gt; --as-group=&lt;group&gt;\n\n# Examples:\nkubectl auth can-i create pods\nkubectl auth can-i delete pods --namespace=default\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#check-specific-resources","title":"Check Specific Resources","text":"<pre><code># Test permissions for specific resource\nkubectl auth can-i get pods --subresource=log\nkubectl auth can-i create deployments --namespace=&lt;namespace&gt;\n\n# Examples:\nkubectl auth can-i get pods --subresource=log\nkubectl auth can-i create deployments --namespace=default\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/authentication/#developer-access","title":"Developer Access","text":"<pre><code># Create developer user\nopenssl genrsa -out developer.key 2048\nopenssl req -new -key developer.key -out developer.csr -subj \"/CN=developer/O=developers\"\n\n# Submit and approve\ncat developer.csr | base64 | tr -d '\\n' | kubectl apply -f -\nkubectl certificate approve developer-&lt;hash&gt;\n\n# Extract certificate\nkubectl get csr developer-&lt;hash&gt; -o jsonpath='{.status.certificate}' | base64 -d &gt; developer.crt\n\n# Configure access\nkubectl config set-credentials developer --client-certificate=developer.crt --client-key=developer.key\nkubectl config set-context developer-context --cluster=minikube --user=developer\nkubectl config use-context developer-context\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#service-account-access","title":"Service Account Access","text":"<pre><code># Create service account\nkubectl create serviceaccount app-service-account\n\n# Create token\nkubectl create token app-service-account\n\n# Use token in kubeconfig\nkubectl config set-credentials app-user --token=&lt;token&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#basic-commands","title":"Basic Commands","text":"<pre><code># Check current context\nkubectl config current-context\n\n# List contexts\nkubectl config get-contexts\n\n# Switch context\nkubectl config use-context &lt;context-name&gt;\n\n# Check permissions\nkubectl auth can-i &lt;verb&gt; &lt;resource&gt;\n\n# View kubeconfig\nkubectl config view\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/authentication/#references","title":"References","text":"<ul> <li>Kubernetes Authentication</li> <li>Kubernetes Certificates</li> <li>GitHub - Aytitech K8sFundamentals - Authentication</li> </ul>"},{"location":"kubernetes/kubernetes-objects/daemonset/","title":"Kubernetes Objects - DaemonSet","text":""},{"location":"kubernetes/kubernetes-objects/daemonset/#overview","title":"Overview","text":"<p>A DaemonSet ensures that all (or some) nodes run a copy of a Pod. As nodes are added to the cluster, Pods will be added to them. As nodes are removed from the cluster, those Pods are garbage collected.</p>"},{"location":"kubernetes/kubernetes-objects/daemonset/#purpose","title":"Purpose","text":"<p>DaemonSets are used for:</p> <ul> <li>Node-level Services: Logging, monitoring, storage</li> <li>System Services: Network plugins, security agents</li> <li>Cluster Maintenance: Backup tools, maintenance scripts</li> </ul>"},{"location":"kubernetes/kubernetes-objects/daemonset/#basic-daemonset","title":"Basic DaemonSet","text":"<pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd-elasticsearch\n  namespace: kube-system\n  labels:\n    k8s-app: fluentd-logging\nspec:\n  selector:\n    matchLabels:\n      name: fluentd-elasticsearch\n  template:\n    metadata:\n      labels:\n        name: fluentd-elasticsearch\n    spec:\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n      containers:\n      - name: fluentd-elasticsearch\n        image: k8s.gcr.io/fluentd-elasticsearch:1.20\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/daemonset/#daemonset-with-node-selector","title":"DaemonSet with Node Selector","text":"<pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ssd-monitor\nspec:\n  selector:\n    matchLabels:\n      name: ssd-monitor\n  template:\n    metadata:\n      labels:\n        name: ssd-monitor\n    spec:\n      nodeSelector:\n        disk: ssd\n      containers:\n      - name: ssd-monitor\n        image: nginx\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/daemonset/#daemonset-with-rolling-update","title":"DaemonSet with Rolling Update","text":"<pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-daemon\nspec:\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/daemonset/#basic-commands","title":"Basic Commands","text":"<pre><code># Create DaemonSet\nkubectl apply -f daemonset.yaml\n\n# List DaemonSets\nkubectl get daemonset\nkubectl get ds\n\n# Check DaemonSet status\nkubectl describe daemonset &lt;daemonset-name&gt;\n\n# Update DaemonSet image\nkubectl set image daemonset/&lt;daemonset-name&gt; &lt;container-name&gt;=&lt;new-image&gt;\n\n# Delete DaemonSet\nkubectl delete daemonset &lt;daemonset-name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/daemonset/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/daemonset/#logging-agent","title":"Logging Agent","text":"<pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: log-aggregator\nspec:\n  selector:\n    matchLabels:\n      app: log-aggregator\n  template:\n    metadata:\n      labels:\n        app: log-aggregator\n    spec:\n      containers:\n      - name: log-aggregator\n        image: fluentd:latest\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/daemonset/#monitoring-agent","title":"Monitoring Agent","text":"<pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-exporter\nspec:\n  selector:\n    matchLabels:\n      app: node-exporter\n  template:\n    metadata:\n      labels:\n        app: node-exporter\n    spec:\n      containers:\n      - name: node-exporter\n        image: prom/node-exporter:latest\n        ports:\n        - containerPort: 9100\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/daemonset/#references","title":"References","text":"<ul> <li>Kubernetes DaemonSet</li> <li>GitHub - Aytitech K8sFundamentals - DaemonSet</li> </ul>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/","title":"Kubernetes Objects - Deployment, ReplicaSet","text":""},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#overview","title":"Overview","text":"<p>In Kubernetes architecture, \"Singleton (Single) Pods\" are generally not created directly. Instead, higher-level controller objects manage Pods, providing enhanced functionality and operational efficiency. The Deployment represents the primary controller for managing Pod lifecycles.</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#why-use-deployments-instead-of-direct-pod-management","title":"Why Use Deployments Instead of Direct Pod Management?","text":""},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#operational-challenges","title":"Operational Challenges","text":"<p>Consider a scenario where a frontend application is deployed with a container in a Pod. If an error occurs in the container and the RestartPolicy is set to \"Always\" or \"OnFailure\", kube-scheduler can recover by restarting the container and continuing operation. However, if the problem occurs on the node itself, kube-scheduler doesn't automatically migrate the Pod to another worker node.</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#traditional-solutions-and-limitations","title":"Traditional Solutions and Limitations","text":"<p>As a solution, organizations could define multiple nodes and place a load balancer in front of them. If one node fails, others continue operating, solving the availability problem. However, this approach introduces significant operational complexity:</p> <ul> <li>Container image updates require manual refresh across all nodes</li> <li>Label management becomes cumbersome and error-prone</li> <li>Configuration changes require individual node updates</li> <li>This approach becomes increasingly complex and difficult to manage</li> </ul>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#deployment-controller","title":"Deployment Controller","text":""},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#core-functionality","title":"Core Functionality","text":"<p>The Deployment object continuously strives to bring the desired state defined for one or more Pods to the * current state. The deployment-controller* within Deployments takes the necessary actions to transition the current state to the desired state.</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#key-benefits","title":"Key Benefits","text":"<ul> <li>Simplified Operations: Easily perform operations like image updates across all managed Pods</li> <li>Rollout Control: Specify how Deployments should behave during operations using the Rollout parameter</li> <li>Rollback Capability: Revert to previous states with a single command if errors occur during operations</li> <li>Automatic Recovery: Kubernetes automatically maintains the specified replica count</li> </ul>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#critical-operational-behavior","title":"Critical Operational Behavior","text":"<p>\u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f Important: When defining a replica count during deployment creation, the Kubernetes cluster continuously attempts to maintain that many replicas running. Even if Pods are manually deleted, new Pods are automatically started in the background. This is why direct Pod creation is not recommended - Kubernetes handles this optimization automatically.</p> <p>Best Practice: Even for single Pod scenarios, create them using Deployments! (Official Kubernetes recommendation)</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#deployment-operations","title":"Deployment Operations","text":""},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#creation-via-command-line","title":"Creation via Command Line","text":"<pre><code>kubectl create deployment &lt;deploymentName&gt; --image=&lt;imageName&gt; --replicas=&lt;replicasNumber&gt;\n\nkubectl create deployment &lt;deploymentName&gt; --image=nginx:latest --replicas=2\n\nkubectl get deployment\n# Pay attention to the ready column for all deployments!\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#image-updates","title":"Image Updates","text":"<pre><code>kubectl set image deployment/&lt;deploymentName&gt; &lt;containerName&gt;=&lt;newImage&gt;\n\nkubectl set image deployment/firstdeployment nginx=httpd\n</code></pre> <p>Default Behavior: The strategy updates one Pod at a time. This behavior can be customized through deployment configuration.</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#scaling-operations","title":"Scaling Operations","text":"<pre><code>kubectl scale deployment &lt;deploymentName&gt; --replicas=&lt;newReplicaNumber&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#resource-management","title":"Resource Management","text":"<pre><code>kubectl delete deployments &lt;deploymentName&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#yaml-configuration","title":"YAML Configuration","text":""},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#conversion-process","title":"Conversion Process","text":"<ol> <li>Extract Pod Configuration: Copy the configuration under <code>metadata</code> from any YAML file that creates a Pod:</li> </ol> <pre><code># podexample.yaml\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: examplepod\n  labels:\n    app: frontend\nspec:\n  containers:\n    - name: nginx\n      image: nginx:latest\n      ports:\n        - containerPort: 80\n</code></pre> <ol> <li> <p>Template Integration: Paste the configuration under the <code>template</code> section in the deployment YAML file. (Pay    attention to indentation!)</p> </li> <li> <p>Template Modification: Remove the <code>name</code> field from the Pod template.</p> </li> </ol>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#deployment-configuration","title":"Deployment Configuration","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: firstdeployment\n  labels:\n    team: development\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend # Label to be used to match with the Pod in the template\n  template: # Area where we specify the properties of the Pods to be created\n    metadata:\n      labels:\n        app: frontend # Label of the Pod matching with the deployment\n    spec:\n      containers:\n        - name: nginx\n          image: nginx:latest\n          ports:\n            - containerPort: 80 # Port to be opened to the outside\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#configuration-requirements","title":"Configuration Requirements","text":"<ul> <li>Each deployment must have at least one <code>selector</code> definition</li> <li>For multiple deployments, use different labels to avoid conflicts and ensure proper Pod management</li> <li>Creating singleton Pods with the same labels as deployments is risky and not recommended</li> </ul>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#replicaset","title":"ReplicaSet","text":""},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#architecture","title":"Architecture","text":"<p>In Kubernetes, the object type that actually creates and manages a specific number of Pods is not Deployment - it's ReplicaSet. When defining a deployment and specifying the desired state, the Deployment object creates a ReplicaSet object, and ReplicaSet performs all Pod management tasks.</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#historical-context","title":"Historical Context","text":"<p>When Kubernetes was first introduced, the Replication-controller object provided this functionality. While it still exists, it is no longer used in modern Kubernetes deployments.</p> <pre><code>kubectl get replicaset # Lists active ReplicaSets\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#update-behavior","title":"Update Behavior","text":"<p>When modifying a deployment, the deployment creates a new ReplicaSet, and this ReplicaSet starts creating new Pods. Meanwhile, old Pods are deleted according to the specified strategy.</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#rollback-operations","title":"Rollback Operations","text":"<pre><code>kubectl rollout undo deployment &lt;deploymentName&gt;\n</code></pre> <p>In this scenario, the old deployment is recreated, and the old ReplicaSet starts creating the previous Pods. This is why, to avoid managing all these operations manually, ReplicaSets are not created directly; operations continue through Deployments.</p> <p>Hierarchy: Deployment &gt; ReplicaSet &gt; Pods</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#yaml-configuration_1","title":"YAML Configuration","text":"<p>When ReplicaSet is desired to be created as YAML, it is created exactly the same way as Deployment.</p>"},{"location":"kubernetes/kubernetes-objects/deployment-replicaset/#references","title":"References","text":"<ul> <li>Kubernetes Official Deployment Overview</li> <li>Kubernetes Official ReplicaSet Overview</li> <li>GitHub - Aytitech K8sFundamentals - Deployment</li> <li>GitHub - Aytitech K8sFundamentals - ReplicaSet</li> </ul>"},{"location":"kubernetes/kubernetes-objects/image-secret/","title":"Kubernetes Objects - Image Secret","text":""},{"location":"kubernetes/kubernetes-objects/image-secret/#overview","title":"Overview","text":"<p>Image Secrets in Kubernetes are used to authenticate with private Docker registries when pulling container images. These secrets store registry credentials and are referenced by Pods to enable access to private image repositories.</p>"},{"location":"kubernetes/kubernetes-objects/image-secret/#purpose","title":"Purpose","text":"<p>Image Secrets are used for:</p> <ul> <li>Private Registry Access: Authenticating with private Docker registries</li> <li>Enterprise Security: Securing access to internal image repositories</li> <li>CI/CD Pipelines: Enabling automated deployments from private registries</li> </ul>"},{"location":"kubernetes/kubernetes-objects/image-secret/#creating-image-secrets","title":"Creating Image Secrets","text":""},{"location":"kubernetes/kubernetes-objects/image-secret/#basic-command","title":"Basic Command","text":"<pre><code># Create Docker registry secret\nkubectl create secret docker-registry &lt;secret_name&gt; \\\n  --docker-server=&lt;registry_url&gt; \\\n  --docker-username=&lt;username&gt; \\\n  --docker-password=&lt;password&gt;\n\n# Example:\nkubectl create secret docker-registry regscrt \\\n  --docker-server=testregistry.azurecr.io \\\n  --docker-username=testregistry \\\n  --docker-password=wqRjEDdVhrM9Hj4D=gWwvV3YXyq9Y4ID\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#yaml-configuration","title":"YAML Configuration","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: regscrt\n  namespace: default\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: eyJhdXRocyI6eyJvemp1cm96dHVya3JlZ2lzdHJ5LmF6dXJlY3IuaW8iOnsidXNlcm5hbWUiOiJvemp1cm96dHVya3JlZ2lzdHJ5IiwicGFzc3dvcmQiOiJ3cVJqRUREdmhyTTlIajREPUdXd3ZWM1lYeXE5WTQ5SUQiLCJhdXRoIjoiWVdSdGFXNDZTR0Z5WW05eU1USXpORFU9In19fQ==\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#using-image-secrets","title":"Using Image Secrets","text":""},{"location":"kubernetes/kubernetes-objects/image-secret/#pod-with-image-secret","title":"Pod with Image Secret","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: imagesecrettest2\n  labels:\n    app: imagesecret\nspec:\n  containers:\n    - name: imagesecretcontainer\n      image: testregistry.azurecr.io/k8s:latest\n      imagePullPolicy: Always\n      ports:\n        - containerPort: 80\n  imagePullSecrets:\n    - name: regscrt\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#pod-without-image-secret","title":"Pod without Image Secret","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: imagesecrettest1\n  labels:\n    app: imagesecret\nspec:\n  containers:\n    - name: imagesecretcontainer\n      image: testregistry.azurecr.io/k8s:latest\n      ports:\n        - containerPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#deployment-with-image-secret","title":"Deployment with Image Secret","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      imagePullSecrets:\n        - name: production-registry-secret\n      containers:\n        - name: app\n          image: private-registry.com/my-app:latest\n          ports:\n            - containerPort: 8080\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#common-registry-configurations","title":"Common Registry Configurations","text":""},{"location":"kubernetes/kubernetes-objects/image-secret/#azure-container-registry-acr","title":"Azure Container Registry (ACR)","text":"<pre><code># Create ACR secret\nkubectl create secret docker-registry acr-secret \\\n  --docker-server=&lt;registry_name&gt;.azurecr.io \\\n  --docker-username=&lt;service_principal_id&gt; \\\n  --docker-password=&lt;service_principal_password&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#google-container-registry-gcr","title":"Google Container Registry (GCR)","text":"<pre><code># Create GCR secret with service account key\nkubectl create secret docker-registry gcr-secret \\\n  --docker-server=gcr.io \\\n  --docker-username=_json_key \\\n  --docker-password=\"$(cat service-account-key.json)\"\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#docker-hub","title":"Docker Hub","text":"<pre><code># Create Docker Hub secret\nkubectl create secret docker-registry dockerhub-secret \\\n  --docker-server=docker.io \\\n  --docker-username=&lt;username&gt; \\\n  --docker-password=&lt;password&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#service-account-integration","title":"Service Account Integration","text":"<pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: app-service-account\n  namespace: production\nimagePullSecrets:\n  - name: production-registry-secret\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-deployment\n  namespace: production\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      serviceAccountName: app-service-account\n      containers:\n        - name: app\n          image: private-registry.com/my-app:latest\n          ports:\n            - containerPort: 8080\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#basic-commands","title":"Basic Commands","text":"<pre><code># Create image secret\nkubectl create secret docker-registry &lt;secret_name&gt; \\\n  --docker-server=&lt;registry_url&gt; \\\n  --docker-username=&lt;username&gt; \\\n  --docker-password=&lt;password&gt;\n\n# List secrets\nkubectl get secrets\n\n# Delete secret\nkubectl delete secret &lt;secret_name&gt;\n\n# Check secret details\nkubectl describe secret &lt;secret_name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/image-secret/#references","title":"References","text":"<ul> <li>Kubernetes Secrets</li> <li>Kubernetes Docker Registry Secret</li> <li>GitHub - Aytitech K8sFundamentals - ImageSecret</li> </ul>"},{"location":"kubernetes/kubernetes-objects/ingress/","title":"Kubernetes Objects - Ingress","text":""},{"location":"kubernetes/kubernetes-objects/ingress/#overview","title":"Overview","text":"<p>Ingress provides the infrastructure for applications to access external resources and be accessible from external sources. It serves as the primary mechanism for managing external access to services within a Kubernetes cluster.</p>"},{"location":"kubernetes/kubernetes-objects/ingress/#use-cases","title":"Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/ingress/#scenario-1-load-balancer-management","title":"Scenario 1: Load Balancer Management","text":"<p>In cloud environments like Azure, organizations define LoadBalancer services within clusters. Cloud providers assign IP addresses to these LoadBalancer services, and all requests directed to these IPs are handled by the LoadBalancer. Domain names are matched with IP addresses through DNS, enabling user access.</p> <p>Challenge: When multiple applications are deployed in the same Kubernetes cluster, organizations need to pay additional costs to cloud providers and perform manual configurations for each LoadBalancer.</p>"},{"location":"kubernetes/kubernetes-objects/ingress/#scenario-2-path-based-routing","title":"Scenario 2: Path-Based Routing","text":"<p>In this scenario: when users visit example.com, application A runs; when they visit example.com/contact, application B runs. LoadBalancer services cannot handle this setup because /contact paths cannot be defined in DNS. However, a load balancer that functions like a gateway is required to welcome users in all scenarios.</p> <p>Solution: Both scenarios are resolved using Ingress Controller and Ingress Objects.</p>"},{"location":"kubernetes/kubernetes-objects/ingress/#architecture","title":"Architecture","text":""},{"location":"kubernetes/kubernetes-objects/ingress/#ingress-controller","title":"Ingress Controller","text":"<p>Ingress Controller refers to load balancer applications like Nginx, Traefik, or KrakenD that can be deployed. Organizations select one of these applications, deploy it to the Kubernetes cluster, and expose it externally by setting up a LoadBalancer service. This provides the application with a public IP, enabling complete user communication through this IP address.</p>"},{"location":"kubernetes/kubernetes-objects/ingress/#ingress-objects","title":"Ingress Objects","text":"<p>How are incoming requests directed? This is where Ingress Objects come into play. (Structures defined in YAML files) Organizations determine how Ingress Objects and Ingress Controllers should behave against incoming requests through configurations made in Ingress Controllers.</p> <p>Features: Ingress provides load balancing, SSL termination, and path-based routing.</p>"},{"location":"kubernetes/kubernetes-objects/ingress/#implementation","title":"Implementation","text":""},{"location":"kubernetes/kubernetes-objects/ingress/#environment-setup","title":"Environment Setup","text":""},{"location":"kubernetes/kubernetes-objects/ingress/#1-minikube-configuration","title":"1. Minikube Configuration","text":"<p>To run Ingress, the minikube driver must be changed:</p> <ul> <li>Windows: Choose Hyper-V</li> <li>macOS/Linux: Choose VirtualBox</li> </ul> <p>Install the appropriate driver before making the selection.</p> <pre><code>minikube start --driver=hyperv\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/ingress/#2-ingress-controller-installation","title":"2. Ingress Controller Installation","text":"<p>Nginx Controller: Each ingress controller has different installation procedures. Installation details can be found on the application's official website.</p> <p>Installation Reference: https://kubernetes.github.io/ingress-nginx/deploy/</p> <p>Minikube Add-ons: minikube offers some ingress controllers like Nginx that are heavily used as add-ons for faster activation.</p> <pre><code>minikube addons enable ingress # Activates the ingress add-on\nminikube addons list # Lists all available add-ons\n</code></pre> <p>Namespace Creation: When Nginx is installed, it creates a namespace named <code>ingress-nginx</code> for itself.</p> <pre><code># To list all objects belonging to the ingress-nginx namespace:\nkubectl get all -n ingress-nginx \n</code></pre>"},{"location":"kubernetes/kubernetes-objects/ingress/#3-application-deployment","title":"3. Application Deployment","text":"<p>Deploy the YAML file that creates both Pods and Services for blueapp, greenapp, todoapp.</p> <p>Important: All services must be ClusterIP type services.</p> ingress.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: blueapp\n  labels:\n    app: blue\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: blue\n  template:\n    metadata:\n      labels:\n        app: blue\n    spec:\n      containers:\n        - name: blueapp\n          image: ozlmulg/k8s:blue\n          ports:\n            - containerPort: 80\n          livenessProbe:\n            httpGet:\n              path: /healthcheck\n              port: 80\n            initialDelaySeconds: 5\n            periodSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /ready\n              port: 80\n            initialDelaySeconds: 5\n            periodSeconds: 3\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: bluesvc\nspec:\n  selector:\n    app: blue\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: greenapp\n  labels:\n    app: green\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: green\n  template:\n    metadata:\n      labels:\n        app: green\n    spec:\n      containers:\n        - name: greenapp\n          image: ozlmulg/k8s:green\n          ports:\n            - containerPort: 80\n          livenessProbe:\n            httpGet:\n              path: /healthcheck\n              port: 80\n            initialDelaySeconds: 5\n            periodSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /ready\n              port: 80\n            initialDelaySeconds: 5\n            periodSeconds: 3\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: greensvc\nspec:\n  selector:\n    app: green\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: todoapp\n  labels:\n    app: todo\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: todo\n  template:\n    metadata:\n      labels:\n        app: todo\n    spec:\n      containers:\n        - name: todoapp\n          image: ozlmulg/samplewebapp:latest\n          ports:\n            - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: todosvc\nspec:\n  selector:\n    app: todo\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/ingress/#4-ingress-object-configuration","title":"4. Ingress Object Configuration","text":"<p>After selecting and installing the Ingress Controller (Nginx) and installing the ClusterIP type services for each app, deploy the Ingress objects necessary for users to access service A when they write example.com/a.</p> <p>Ingress Object definition for blue and green apps:</p> <p>The <code>pathType</code> section can be set in two ways: <code>exact</code> or <code>Prefix</code>. For detailed information, refer to the Kubernetes Official Documentation</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: appingress\n  annotations:\n    # Nginx settings are configured through annotations\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\nspec:\n  rules:\n    - host: example.com\n      http:\n        paths:\n          - path: /blue\n            pathType: Prefix\n            backend:\n              service:\n                name: bluesvc\n                port:\n                  number: 80\n          - path: /green\n            pathType: Prefix\n            backend:\n              service:\n                name: greensvc\n                port:\n                  number: 80\n</code></pre> <p>Ingress Object prepared using a different <code>path</code>:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: todoingress\nspec:\n  rules:\n    - host: todoapp.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: todosvc\n                port:\n                  number: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/ingress/#5-verification","title":"5. Verification","text":"<pre><code>kubectl get ingress\n</code></pre> <p>Note: To simulate with URLs, edit the hosts file.</p>"},{"location":"kubernetes/kubernetes-objects/ingress/#references","title":"References","text":"<ul> <li>Kubernetes Official Ingress Overview</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/","title":"Kubernetes Objects - Job &amp; CronJob","text":""},{"location":"kubernetes/kubernetes-objects/job-cronjob/#overview","title":"Overview","text":"<p>Jobs and CronJobs in Kubernetes are used for running batch processes and scheduled tasks. Jobs run to completion, while CronJobs run on a schedule.</p>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#job","title":"Job","text":""},{"location":"kubernetes/kubernetes-objects/job-cronjob/#purpose","title":"Purpose","text":"<p>Jobs are used for:</p> <ul> <li>Batch Processing: One-time tasks that need to complete</li> <li>Data Processing: ETL jobs, data analysis</li> <li>Backup Operations: Database backups, file backups</li> <li>Testing: Running tests, validation scripts</li> </ul>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#basic-job","title":"Basic Job","text":"<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    spec:\n      containers:\n      - name: pi\n        image: perl\n        command:\n        - perl\n        - -Mbignum=bpi\n        - -wle\n        - print bpi(2000)\n      restartPolicy: Never\n  backoffLimit: 4\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#job-with-parallelism","title":"Job with Parallelism","text":"<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: parallel-job\nspec:\n  parallelism: 3\n  completions: 6\n  template:\n    spec:\n      containers:\n      - name: worker\n        image: busybox\n        command: [\"sh\", \"-c\", \"echo 'Hello from job'; sleep 10\"]\n      restartPolicy: Never\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#cronjob","title":"CronJob","text":""},{"location":"kubernetes/kubernetes-objects/job-cronjob/#purpose_1","title":"Purpose","text":"<p>CronJobs are used for:</p> <ul> <li>Scheduled Tasks: Regular maintenance, backups</li> <li>Periodic Jobs: Data synchronization, cleanup</li> <li>Automated Operations: System maintenance, monitoring</li> </ul>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#basic-cronjob","title":"Basic CronJob","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: \"*/1 * * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: busybox\n            command:\n            - /bin/sh\n            - -c\n            - date; echo Hello from the Kubernetes cluster\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#cronjob-with-concurrency-policy","title":"CronJob with Concurrency Policy","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: backup-job\nspec:\n  schedule: \"0 2 * * *\"\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: backup\n            image: backup-tool:latest\n            command: [\"/backup.sh\"]\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#cron-schedule-format","title":"Cron Schedule Format","text":"<pre><code># Format: minute hour day month day-of-week\n# Examples:\n\"0 0 * * *\"      # Daily at midnight\n\"0 2 * * *\"      # Daily at 2 AM\n\"0 */6 * * *\"    # Every 6 hours\n\"0 9 * * 1\"      # Every Monday at 9 AM\n\"*/15 * * * *\"   # Every 15 minutes\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#basic-commands","title":"Basic Commands","text":"<pre><code># Create Job\nkubectl apply -f job.yaml\n\n# Create CronJob\nkubectl apply -f cronjob.yaml\n\n# List Jobs\nkubectl get jobs\n\n# List CronJobs\nkubectl get cronjobs\n\n# Check Job status\nkubectl describe job &lt;job-name&gt;\n\n# Check CronJob status\nkubectl describe cronjob &lt;cronjob-name&gt;\n\n# Delete Job\nkubectl delete job &lt;job-name&gt;\n\n# Delete CronJob\nkubectl delete cronjob &lt;cronjob-name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/job-cronjob/#database-backup-job","title":"Database Backup Job","text":"<pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: db-backup\nspec:\n  template:\n    spec:\n      containers:\n      - name: backup\n        image: postgres:13\n        command:\n        - /bin/sh\n        - -c\n        - pg_dump -h db-service -U postgres &gt; /backup/backup.sql\n        env:\n        - name: PGPASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: password\n        volumeMounts:\n        - name: backup-volume\n          mountPath: /backup\n      volumes:\n      - name: backup-volume\n        persistentVolumeClaim:\n          claimName: backup-pvc\n      restartPolicy: Never\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#log-cleanup-cronjob","title":"Log Cleanup CronJob","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: log-cleanup\nspec:\n  schedule: \"0 3 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: cleanup\n            image: busybox\n            command:\n            - /bin/sh\n            - -c\n            - find /logs -name \"*.log\" -mtime +7 -delete\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/job-cronjob/#references","title":"References","text":"<ul> <li>Kubernetes Jobs</li> <li>Kubernetes CronJobs</li> <li>GitHub - Aytitech K8sFundamentals - Job/CronJob</li> </ul>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/","title":"Kubernetes Objects - Label, Selector, Annotation","text":""},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#overview","title":"Overview","text":"<p>Labels and Selectors provide the fundamental mechanism for organizing and identifying Kubernetes objects. Labels act as key-value pairs that tag Kubernetes objects, while Selectors enable object selection based on these labels.</p>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#labels","title":"Labels","text":""},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#definition","title":"Definition","text":"<p>Labels are key-value pairs that act as tags for Kubernetes objects. Selectors are mechanisms for selecting objects based on their labels.</p> <p>Format: <code>example.com/tier:front-end</code> where:</p> <ul> <li><code>example.com/</code> = Prefix (optional)</li> <li><code>tier</code> = key</li> <li><code>front-end</code> = value</li> </ul>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#constraints","title":"Constraints","text":"<ul> <li>Reserved prefixes: <code>kubernetes.io/</code> and <code>k8s.io/</code> are reserved for Kubernetes core components and cannot be used</li> <li>Valid characters: Labels can contain dashes, underscores, and dots</li> <li>Language restrictions: Turkish characters cannot be used</li> <li>Purpose: Labels are used to establish connections between objects like Services, Deployments, and Pods</li> </ul>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#implementation","title":"Implementation","text":""},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#label-definition","title":"Label Definition","text":"<p>Label definitions are made in the metadata section. Multiple labels can be added to the same object. Labels provide grouping and identification capabilities, making CLI operations easier.</p>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#selectors-object-filtering","title":"Selectors - Object Filtering","text":"<p>To list objects that have a specific \"app\" key:</p> <pre><code>---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod8\n  labels:\n    app: web # app key with value \"web\"\n    tier: backend # tier key with value \"backend\"\n...\n---\n</code></pre> <pre><code>kubectl get pods -l &lt;keyword&gt; --show-labels\n\n## Equality-based Syntax\n\nkubectl get pods -l \"app\" --show-labels\n\nkubectl get pods -l \"app=firstapp\" --show-labels\n\nkubectl get pods -l \"app=firstapp, tier=front-end\" --show-labels\n\n# Objects with app key as \"firstapp\" and tier not \"front-end\":\nkubectl get pods -l \"app=firstapp, tier!=front-end\" --show-labels\n\n# Objects with app key and tier as \"front-end\":\nkubectl get pods -l \"app, tier=front-end\" --show-labels\n\n## Set-based Syntax\n\n# Objects with app as \"firstapp\":\nkubectl get pods -l \"app in (firstapp)\" --show-labels\n\n# Query app and get those that don't contain \"firstapp\":\nkubectl get pods -l \"app, app notin (firstapp)\" --show-labels\n\nkubectl get pods -l \"app in (firstapp, secondapp)\" --show-labels\n\n# List those that don't have app key:\nkubectl get pods -l \"!app\" --show-labels\n\n# Get those assigned as \"firstapp\" for app, not assigned \"frontend\" value to tier key:\nkubectl get pods -l \"app in (firstapp), tier notin (frontend)\" --show-labels\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#syntax-differences","title":"Syntax Differences","text":"<p>Important distinction: While no results are found with the first syntax (equality-based), results appear with the second syntax (set-based selector):</p> <pre><code>kubectl get pods -l \"app=firstapp, app=secondapp\" --show-labels # No results!\nkubectl get pods -l \"app in (firstapp, secondapp)\" --show-labels # Results exist!\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#label-management","title":"Label Management","text":""},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#adding-labels","title":"Adding Labels","text":"<pre><code>kubectl label pods &lt;podName&gt; &lt;label&gt;\n\nkubectl label pods pod1 app=front-end\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#removing-labels","title":"Removing Labels","text":"<p>Append a dash (-) at the end to indicate deletion.</p> <pre><code>kubectl label pods pod1 app-\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#updating-labels","title":"Updating Labels","text":"<pre><code>kubectl label --overwrite pods &lt;podName&gt; &lt;label&gt;\n\nkubectl label --overwrite pods pod9 team=team3\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#bulk-operations","title":"Bulk Operations","text":"<p>This label is added to all objects.</p> <pre><code>kubectl label pods --all foo=bar\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#object-relationships","title":"Object Relationships","text":""},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#node-selection","title":"Node Selection","text":"<p>In normal operation, kube-scheduler makes node selections according to its own algorithm. To make this selection manual, specify that it should select a node with the <code>hddtype: ssd</code> label as shown in the example below. This establishes a relationship between the Pod and node through labels.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: pod11\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\n    ports:\n    - containerPort: 80\n  nodeSelector:\n    hddtype: ssd\n</code></pre> <p>Implementation: Add the <code>hddtype: ssd</code> label to the single node in the minikube cluster. After adding this label, the Pod above will transition from \"Pending\" state to \"Running\" state. (Because it found the node it was looking for \ud83d\ude0a)</p> <pre><code>kubectl label nodes minikube hddtype=ssd\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#annotations","title":"Annotations","text":""},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#purpose","title":"Purpose","text":"<p>Annotations behave similarly to labels and are written under the metadata section. Since labels are used to establish relationships between objects, they fall into the sensitive information category. For this reason, important information that cannot be used as labels can be recorded through Annotations.</p>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#format","title":"Format","text":"<p>Example: <code>example.com/notification-email:admin@k8s.com</code></p> <ul> <li><code>example.com</code> \u2192 Prefix (optional)</li> <li><code>notification-email</code> \u2192 Key</li> <li><code>admin@k8s.com</code> \u2192 Value</li> </ul>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#configuration","title":"Configuration","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: annotationpod\n  annotations:\n    owner: \"Name Surname\"\n    notification-email: \"admin@example.com\"\n    releasedate: \"01.01.2021\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\nspec:\n  containers:\n  - name: annotationcontainer\n    image: nginx\n    ports:\n    - containerPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#management-operations","title":"Management Operations","text":"<p>Adding Annotations:</p> <pre><code>kubectl annotate pods annotationpod foo=bar\n\nkubectl annotate pods annotationpod foo- # Deletes the annotation\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/label-selector-annotation/#references","title":"References","text":"<ul> <li>Kubernetes Official Labels/Selectors Overview</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-objects/namespace/","title":"Kubernetes Objects - Namespace","text":""},{"location":"kubernetes/kubernetes-objects/namespace/#overview","title":"Overview","text":"<p>Namespaces provide logical isolation within Kubernetes clusters, enabling organizations to organize resources and manage access control effectively. They serve as virtual clusters within physical clusters, allowing multiple teams or projects to share infrastructure while maintaining separation.</p>"},{"location":"kubernetes/kubernetes-objects/namespace/#purpose","title":"Purpose","text":""},{"location":"kubernetes/kubernetes-objects/namespace/#resource-organization","title":"Resource Organization","text":"<p>Consider a scenario where 10 different teams share a single file server:</p> <ul> <li>Files created by one person could be overwritten by another, causing name conflicts</li> <li>Separating files that only Team 1 should access becomes challenging, requiring constant permission adjustments</li> <li>To resolve this, dedicated folders can be created for each team with permissions configured according to team   membership</li> </ul> <p>In the example above, the file server represents the Kubernetes cluster, and namespaces represent the * dedicated folders* created for each team.</p>"},{"location":"kubernetes/kubernetes-objects/namespace/#technical-implementation","title":"Technical Implementation","text":"<p>Namespaces are Kubernetes objects that require proper definition when creating them (especially in YAML files). Namespaces must be independent and unique from each other. Namespaces cannot be nested within each other.</p> <p>When Kubernetes is initially created, four default namespaces are automatically established: <code>default</code>, <code>kube-node-lease</code>, <code>kube-public</code>, and <code>kube-system</code>.</p>"},{"location":"kubernetes/kubernetes-objects/namespace/#operations","title":"Operations","text":""},{"location":"kubernetes/kubernetes-objects/namespace/#listing-namespaces","title":"Listing Namespaces","text":"<p>By default, all operations and objects are processed under the default namespace. When executing <code>kubectl get pods</code> without specifying a namespace, the command retrieves Pods from the <code>default namespace</code>.</p> <pre><code>kubectl get pods --namespace &lt;namespaceName&gt;\nkubectl get pods -n &lt;namespaceName&gt;\n\n# To list Pods across all namespaces:\nkubectl get pods --all-namespaces\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/namespace/#creation","title":"Creation","text":"<pre><code>kubectl create namespace &lt;namespaceName&gt;\n\nkubectl get namespaces\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/namespace/#yaml-configuration","title":"YAML Configuration","text":"<pre><code>apiVersion: v1\nkind: Namespace # A namespace named development is created\nmetadata:\n  name: development # Namespace identifier\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  namespace: development # Pod defined under the created namespace\n  name: namespacepod\nspec:\n  containers:\n    - name: namespacecontainer\n      image: nginx:latest\n      ports:\n        - containerPort: 80\n</code></pre> <p>Important Note: When creating Pods that run in a specific namespace and connecting to these Pods (or performing any operations on them), the namespace must be specified. If not specified, Kubernetes will search for the relevant Pod under the default namespace.</p>"},{"location":"kubernetes/kubernetes-objects/namespace/#default-namespace-configuration","title":"Default Namespace Configuration","text":"<pre><code>kubectl config set-context --current --namespace=&lt;namespaceName&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/namespace/#deletion","title":"Deletion","text":"<p>\u26a0\ufe0f CRITICAL WARNING! No confirmation will be requested when deleting a namespace. All objects within the namespace will be permanently deleted!</p> <pre><code>kubectl delete namespaces &lt;namespaceName&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/namespace/#references","title":"References","text":"<ul> <li>Kubernetes Official Namespace Overview</li> </ul>"},{"location":"kubernetes/kubernetes-objects/network-policy/","title":"Kubernetes Objects - Network Policy","text":""},{"location":"kubernetes/kubernetes-objects/network-policy/#overview","title":"Overview","text":"<p>Network Policies in Kubernetes control how Pods communicate with each other and other network endpoints. They provide fine-grained control over network traffic within the cluster.</p>"},{"location":"kubernetes/kubernetes-objects/network-policy/#purpose","title":"Purpose","text":"<p>Network Policies are used for:</p> <ul> <li>Traffic Control: Allow or deny specific network traffic</li> <li>Security: Isolate Pods and restrict communication</li> <li>Compliance: Meet security requirements and regulations</li> <li>Multi-tenancy: Separate network traffic between different teams</li> </ul>"},{"location":"kubernetes/kubernetes-objects/network-policy/#basic-network-policy","title":"Basic Network Policy","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny\n  namespace: default\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#allow-specific-traffic","title":"Allow Specific Traffic","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-web\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: web\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: frontend\n    ports:\n    - protocol: TCP\n      port: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#deny-all-traffic","title":"Deny All Traffic","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-all\n  namespace: default\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress: []\n  egress: []\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#allow-from-namespace","title":"Allow from Namespace","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-from-namespace\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: database\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: frontend\n    ports:\n    - protocol: TCP\n      port: 3306\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#allow-specific-ip-ranges","title":"Allow Specific IP Ranges","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-ip-range\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: api\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - ipBlock:\n        cidr: 10.0.0.0/24\n        except:\n        - 10.0.0.1\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#egress-policy","title":"Egress Policy","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: restrict-egress\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: restricted\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector: {}\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n  - to:\n    - ipBlock:\n        cidr: 0.0.0.0/0\n    ports:\n    - protocol: TCP\n      port: 443\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#basic-commands","title":"Basic Commands","text":"<pre><code># Create Network Policy\nkubectl apply -f network-policy.yaml\n\n# List Network Policies\nkubectl get networkpolicies\nkubectl get netpol\n\n# Check Network Policy status\nkubectl describe networkpolicy &lt;policy-name&gt;\n\n# Delete Network Policy\nkubectl delete networkpolicy &lt;policy-name&gt;\n\n# Check Network Policy YAML\nkubectl get networkpolicy &lt;policy-name&gt; -o yaml\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/network-policy/#database-access-control","title":"Database Access Control","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: database-access\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: database\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: web\n    ports:\n    - protocol: TCP\n      port: 3306\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#api-gateway-policy","title":"API Gateway Policy","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: api-gateway\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: api-gateway\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: frontend\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-policy/#references","title":"References","text":"<ul> <li>Kubernetes Network Policies</li> <li>GitHub - Aytitech K8sFundamentals - NetworkPolicy</li> </ul>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/","title":"Kubernetes Objects - Network Structure, Service","text":""},{"location":"kubernetes/kubernetes-objects/network-structure-service/#overview","title":"Overview","text":"<p>Kubernetes provides a sophisticated networking infrastructure that enables seamless communication between Pods and external services. This document covers the fundamental networking concepts and Service objects that facilitate this communication.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#network-architecture","title":"Network Architecture","text":""},{"location":"kubernetes/kubernetes-objects/network-structure-service/#core-principles","title":"Core Principles","text":"<p>Kubernetes network architecture operates under three fundamental rules:</p> <ol> <li>An IP address range (<code>--pod-network-cidr</code>) is defined during Kubernetes installation for Pod IP allocation</li> <li>In Kubernetes, each Pod receives a unique IP address assigned from this CIDR block</li> <li>Pods within the same cluster can communicate with each other by default without restrictions and without NAT (    Network Address Translation)</li> </ol>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#communication-patterns","title":"Communication Patterns","text":"<p>Containers within Kubernetes are exposed to three types of communication:</p> <ol> <li>External communication: A container communicates with IP addresses outside the Kubernetes cluster</li> <li>Intra-node communication: A container communicates with another container on the same node</li> <li>Inter-node communication: A container communicates with a container on a different node</li> </ol> <p>The first two scenarios work without issues, but the third scenario presents NAT-related challenges. To address this, Kubernetes has implemented the Container Network Interface (CNI) project to enable inter-container communication.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#cni-implementation","title":"CNI Implementation","text":"<p>CNI is responsible for container network connectivity and resource cleanup when containers are deleted.</p> <p>Kubernetes has adopted CNI standards for network communication and allows users to choose from various CNI plugins. Organizations can select the most suitable CNI plugin from the following resources:</p> <p>CNI GitHub Repository</p> <p>Kubernetes Official Documentation - Cluster Networking</p> <p>Container Communication: We've covered container communication with the \"Outside World.\" Now, how will the \"Outside World\" communicate with Containers?</p> <p>Answer: Through the Service object.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#service-objects","title":"Service Objects","text":""},{"location":"kubernetes/kubernetes-objects/network-structure-service/#purpose","title":"Purpose","text":"<p>The Service object handles the networking aspects of Kubernetes, providing a stable endpoint for accessing Pods and enabling load balancing.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#use-cases","title":"Use Cases","text":"<p>Consider a system with 1 Frontend (React) and 1 Backend (Go):</p> <ul> <li>Organizations create one deployment each for both applications, ensuring 3 Pods each are defined</li> <li>How will external access be provided to the 3 Frontend Pods?</li> <li>Requests from the Frontend need to be processed by the Backend. This communication is straightforward since each Pod   has an IP address, and all Pods in Kubernetes can communicate with each other using these IP addresses</li> <li>To enable this communication, Frontend Pods need to know the IP addresses of Backend Pods. One solution is to   hardcode all Backend Pod IP addresses in the Frontend deployment. However, Pods can be updated, changed, and during   these updates, they may receive new IP addresses, requiring manual updates to the Frontend deployment</li> </ul> <p>This is why Service objects are created to solve all these scenarios. Kubernetes provides Pods with their own IP addresses and a single DNS name for a set of Pods, along with load balancing between them.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#service-types","title":"Service Types","text":""},{"location":"kubernetes/kubernetes-objects/network-structure-service/#clusterip","title":"ClusterIP","text":"<p>Purpose: Inter-container communication within the cluster</p> <p>Organizations can create a ClusterIP service and associate it with Pods through labels. When this object is created, it receives a unique DNS address that all Pods in the cluster can resolve. Additionally, every Kubernetes installation has a virtual IP range (e.g., 10.0.100.0/16).</p> <p>When a ClusterIP service object is created, an IP address is assigned to this object from the IP range, and this IP address is registered with the cluster's DNS mechanism using its name. This IP address is a Virtual IP address.</p> <p>This IP address is added to the IP tables on all nodes by Kube-proxy. All traffic directed to this IP address is distributed to Pods using the Round Robin algorithm. This solution addresses two main problems:</p> <ol> <li>Organizations can define this IP address in Frontend nodes (and if named <code>backend</code>), they can specify to use this IP    address when accessing the Backend. (Selector = app:backend) Organizations no longer need to manually add Backend    Pod IP addresses to Frontend Pods every time!</li> </ol> <p>In summary: ClusterIP Service solves inter-container communication by handling Service Discovery and Load Balancing tasks!</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#nodeport","title":"NodePort","text":"<p>Purpose: External access to cluster services</p> <p>This service type is used to handle connections originating from outside the cluster. The <code>NodePort</code> key is used to configure this service type.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#loadbalancer","title":"LoadBalancer","text":"<p>Purpose: Cloud service integration</p> <p>This service type is only available in cloud-managed Kubernetes services like Azure Kubernetes Service, Google Kubernetes Engine.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#externalname","title":"ExternalName","text":"<p>Purpose: DNS resolution (Not currently necessary for most deployments)</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#service-configuration","title":"Service Configuration","text":""},{"location":"kubernetes/kubernetes-objects/network-structure-service/#clusterip-example","title":"ClusterIP Example","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: backend # Service name\nspec:\n  type: ClusterIP # Service type\n  selector:\n    app: backend # Which Pods to match (same as the label in the Pod)\n  ports:\n    - protocol: TCP\n      port: 5000\n      targetPort: 5000\n</code></pre> <p>Any object within the cluster will receive a response when sending requests to <code>clusterIP:5000</code>.</p> <p>Important Note: Service names follow this format when created: <code>serviceName.namespaceName.svc.cluster.domain</code></p> <p>If another object in the same namespace wants to access this service, it can write <code>backend</code> directly thanks to core DNS resolution. Objects from other namespaces must access this service using the full name above.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#nodeport-example","title":"NodePort Example","text":"<p>Note: All created NodePort services also have ClusterIP functionality. Therefore, this service can be accessed internally using the ClusterIP.</p> <p>Minikube Integration: When using minikube, organizations can open a tunnel with * <code>minikube service --url &lt;serviceName&gt;</code>* because they normally cannot access the worker node from outside. This is specific to minikube.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  type: NodePort\n  selector:\n    app: frontend\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#loadbalancer-example","title":"LoadBalancer Example","text":"<p>This service type works on clusters created on cloud services like Google Cloud Service and Azure.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: frontendlb\nspec:\n  type: LoadBalancer\n  selector:\n    app: frontend\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#service-management","title":"Service Management","text":""},{"location":"kubernetes/kubernetes-objects/network-structure-service/#imperative-creation","title":"Imperative Creation","text":"<pre><code>kubectl delete service &lt;serviceName&gt;\n\n# Creating ClusterIP Service\nkubectl expose deployment backend --type=ClusterIP --name=backend\n\nkubectl expose deployment backend --type=NodePort --name=backend\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#endpoints","title":"Endpoints","text":"<p>Purpose: Endpoints determine where requests to Services will be directed</p> <p>Just as deployments create ReplicaSets, Service objects also create Endpoints in the background. Endpoints determine where requests to our Services will be directed.</p> <pre><code>kubectl get endpoints\n</code></pre> <p>When a Pod is deleted, a new endpoint is created for the new Pod that will be created.</p>"},{"location":"kubernetes/kubernetes-objects/network-structure-service/#references","title":"References","text":"<ul> <li>Kubernetes Official Service Overview</li> <li>GitHub - Aytitech K8sFundamentals - Network Policy</li> <li>GitHub - Aytitech K8sFundamentals - Service</li> </ul>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/","title":"Kubernetes Objects - PersistentVolume &amp; PersistentVolumeClaim","text":""},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#overview","title":"Overview","text":"<p>PersistentVolumes (PVs) and PersistentVolumeClaims (PVCs) provide a way for users to request and consume storage resources without knowing the details of the underlying storage infrastructure.</p>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#persistentvolume-pv","title":"PersistentVolume (PV)","text":""},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#purpose","title":"Purpose","text":"<p>PersistentVolumes are used for:</p> <ul> <li>Storage Abstraction: Providing a unified interface for different storage backends</li> <li>Storage Management: Centralized management of storage resources</li> <li>Storage Provisioning: Dynamic and static storage allocation</li> </ul>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#basic-pv-example","title":"Basic PV Example","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n   name: mysqlpv\n   labels:\n     app: mysql\nspec:\n  capacity:\n    storage: 5Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Recycle\n  nfs:\n    path: /\n    server: 10.255.255.10\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#persistentvolumeclaim-pvc","title":"PersistentVolumeClaim (PVC)","text":""},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#purpose_1","title":"Purpose","text":"<p>PersistentVolumeClaims are used for:</p> <ul> <li>Storage Requests: Users requesting specific storage resources</li> <li>Storage Consumption: Applications consuming allocated storage</li> <li>Storage Binding: Dynamic binding to available PVs</li> </ul>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#basic-pvc-example","title":"Basic PVC Example","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysqlclaim\nspec:\n  accessModes:\n    - ReadWriteOnce\n  volumeMode: Filesystem\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: \"\"\n  selector:\n    matchLabels:\n      app: mysql\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#storage-backends","title":"Storage Backends","text":""},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#nfs-storage","title":"NFS Storage","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: nfs-pv\n  labels:\n    app: nfs-storage\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteMany\n  persistentVolumeReclaimPolicy: Retain\n  nfs:\n    path: /data\n    server: nfs-server.example.com\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#local-storage","title":"Local Storage","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: local-pv\n  labels:\n    app: local-storage\nspec:\n  capacity:\n    storage: 5Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  local:\n    path: /mnt/data\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - node-1\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#access-modes","title":"Access Modes","text":""},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#readwriteonce-rwo","title":"ReadWriteOnce (RWO)","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: rwo-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce  # Single node can mount as read-write\n  persistentVolumeReclaimPolicy: Retain\n  hostPath:\n    path: /data\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#readwritemany-rwx","title":"ReadWriteMany (RWX)","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: rwx-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteMany  # Multiple nodes can mount as read-write\n  persistentVolumeReclaimPolicy: Retain\n  nfs:\n    path: /shared-data\n    server: nfs-server.example.com\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#reclaim-policies","title":"Reclaim Policies","text":""},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#retain-policy","title":"Retain Policy","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: retain-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain  # Manual cleanup required\n  hostPath:\n    path: /data\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#delete-policy","title":"Delete Policy","text":"<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: delete-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Delete  # Automatic cleanup\n  awsElasticBlockStore:\n    volumeID: vol-12345678\n    fsType: ext4\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#using-pvpvc-with-deployments","title":"Using PV/PVC with Deployments","text":""},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#mysql-with-persistent-storage","title":"MySQL with Persistent Storage","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: mysqlsecret\ntype: Opaque\nstringData:\n  password: P@ssw0rd!\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n   name: mysqlpv\n   labels:\n     app: mysql\nspec:\n  capacity:\n    storage: 5Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Recycle\n  nfs:\n    path: /\n    server: 10.255.255.10\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysqlclaim\nspec:\n  accessModes:\n    - ReadWriteOnce\n  volumeMode: Filesystem\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: \"\"\n  selector:\n    matchLabels:\n      app: mysql\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysqldeployment\n  labels:\n    app: mysql\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n        - name: mysql\n          image: mysql\n          ports:\n            - containerPort: 3306\n          volumeMounts:\n            - mountPath: \"/var/lib/mysql\"\n              name: mysqlvolume\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: mysqlsecret\n                  key: password\n      volumes:\n        - name: mysqlvolume\n          persistentVolumeClaim:\n            claimName: mysqlclaim\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#basic-commands","title":"Basic Commands","text":"<pre><code># List PersistentVolumes\nkubectl get pv\nkubectl get persistentvolume\n\n# List PersistentVolumeClaims\nkubectl get pvc\nkubectl get persistentvolumeclaim\n\n# Check PV status\nkubectl describe pv &lt;pv-name&gt;\n\n# Check PVC status\nkubectl describe pvc &lt;pvc-name&gt;\n\n# Delete PV\nkubectl delete pv &lt;pv-name&gt;\n\n# Delete PVC\nkubectl delete pvc &lt;pvc-name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/persistent-volume-claim/#references","title":"References","text":"<ul> <li>Kubernetes PersistentVolumes</li> <li>Kubernetes PersistentVolumeClaims</li> <li>GitHub - Aytitech K8sFundamentals - PV/PVC</li> </ul>"},{"location":"kubernetes/kubernetes-objects/pod/","title":"Kubernetes Objects - Pod","text":""},{"location":"kubernetes/kubernetes-objects/pod/#overview","title":"Overview","text":"<p>Kubernetes Objects are the fundamental entities deployed, executed, and managed within Kubernetes clusters. The * Pod* represents the most basic Kubernetes object and serves as the smallest deployable unit in the Kubernetes ecosystem.</p> <p>Unlike traditional container management where direct Docker container manipulation occurs, Kubernetes operates at the Pod level - the atomic unit for creating and managing workloads.</p>"},{"location":"kubernetes/kubernetes-objects/pod/#pod-architecture","title":"Pod Architecture","text":"<p>Pods can contain one or more containers, though best practice recommends one container per Pod for optimal resource management, scalability, and operational efficiency.</p> <p>Each Pod receives a unique identifier (UID) and a unique IP address. The API server records this information in etcd. The Scheduler identifies unassigned Pods and selects appropriate worker nodes for execution, updating the Pod definition accordingly. The kubelet service running on the worker node then creates and manages the specified containers.</p> <p>Containers within the same Pod run on the same node and communicate through localhost interfaces. Pods are created using the <code>kubectl run</code> command.</p>"},{"location":"kubernetes/kubernetes-objects/pod/#pod-operations","title":"Pod Operations","text":""},{"location":"kubernetes/kubernetes-objects/pod/#creation","title":"Creation","text":"<pre><code>kubectl run firstpod --image=nginx --restart=Never --port=80 --labels=\"app=frontend\" \n\n# Output: pod/firstpod created\n</code></pre> <p>The <code>--restart</code> parameter with <code>Never</code> ensures that if the container stops for any reason, it will not be automatically restarted.</p>"},{"location":"kubernetes/kubernetes-objects/pod/#listing-and-inspection","title":"Listing and Inspection","text":"<pre><code>kubectl get pods -o wide\n\n# -o wide provides an extended table display with additional details\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#detailed-pod-information","title":"Detailed Pod Information","text":"<pre><code>kubectl describe &lt;object&gt; &lt;objectName&gt;\n\nkubectl describe pods first-pod\n</code></pre> <p>This command retrieves comprehensive information about the specified Pod. Pay particular attention to the Events section, which provides a chronological history of Pod lifecycle events:</p> <ul> <li>Initial node assignment by the Scheduler</li> <li>Container image pulling by kubelet</li> <li>Pod creation and startup processes</li> </ul>"},{"location":"kubernetes/kubernetes-objects/pod/#log-access","title":"Log Access","text":"<pre><code>kubectl logs &lt;podName&gt;\n\nkubectl logs first-pod\n</code></pre> <p>Real-time Log Monitoring</p> <pre><code>kubectl logs -f &lt;podName&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#command-execution","title":"Command Execution","text":"<pre><code>kubectl exec &lt;podName&gt; -- &lt;command&gt;\n\nkubectl exec first-pod -- ls /\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#interactive-access","title":"Interactive Access","text":"<pre><code>kubectl exec -it &lt;podName&gt; -- &lt;shellName&gt;\n\nkubectl exec -it first-pod -- /bin/sh\n</code></pre> <p>Multi-container Pod Access</p> <pre><code>kubectl exec -it &lt;podName&gt; -c &lt;containerName&gt; -- &lt;bash|/bin/sh&gt;\n</code></pre> <p>Useful Commands After Connection:</p> <pre><code>hostname    # Displays the Pod name\nprintenv    # Shows Pod environment variables\n</code></pre> <p>Connecting to Specific Containers in Multi-container Pods:</p> <pre><code>kubectl exec -it &lt;podName&gt; -c &lt;containerName&gt; -- /bin/sh\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#deletion","title":"Deletion","text":"<pre><code>kubectl delete pods &lt;podName&gt;\n</code></pre> <p>\u26a0\ufe0f Warning: This command executes immediately without confirmation. Exercise extreme caution, especially in production environments!</p>"},{"location":"kubernetes/kubernetes-objects/pod/#yaml-configuration","title":"YAML Configuration","text":"<p>Kubernetes supports both YAML and JSON as declarative configuration methods. Multiple objects can be defined in a single YAML file by separating them with <code>---</code> (three dashes).</p> <pre><code>apiVersion:\nkind:\nmetadata:\nspec:\n</code></pre> <p>When creating any Kubernetes object, apiVersion, kind, and metadata are mandatory fields:</p> <ul> <li><code>kind</code> specifies the type of object to create (e.g., <code>Pod</code>)</li> <li><code>apiVersion</code> indicates which API endpoint serves the object type</li> <li><code>metadata</code> contains unique identifying information about the object (e.g., <code>namespace</code>, <code>annotations</code>)</li> <li><code>spec</code> defines the object's properties and configuration. Content varies by object type and can be referenced from   official documentation</li> </ul>"},{"location":"kubernetes/kubernetes-objects/pod/#determining-apiversion","title":"Determining apiVersion","text":"<ol> <li>Documentation Reference: Consult official Kubernetes documentation</li> <li>Kubectl Explain: Use the following command:</li> </ol> <pre><code>kubectl explain pods\n</code></pre> <p>This command displays Pod properties and shows the appropriate <code>apiVersion</code> under the <code>Versions</code> field.</p>"},{"location":"kubernetes/kubernetes-objects/pod/#configuration-example","title":"Configuration Example","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: first-pod    # Pod identifier\n  labels: # Optional label assignments\n    app: front-end   # Creates app=front-end label\nspec:\n  containers: # Container definitions\n    - name: nginx            # Container name\n      image: nginx:latest    # Container image\n      ports:\n        - containerPort: 80  # External access port\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#applying-configuration","title":"Applying Configuration","text":"<pre><code>kubectl apply -f pod1.yaml\n</code></pre> <p>This command creates the object defined in the YAML file. All Pod properties can be verified using <code>kubectl describe pods firstpod</code>. YAML configuration is ideal for CI/CD pipeline integration.</p> <p>Declarative Method Advantage: Unlike imperative commands that may return \"Already exists\" errors during updates, YAML modifications with <code>kubectl apply</code> provide \"pod configured\" success messages.</p>"},{"location":"kubernetes/kubernetes-objects/pod/#removing-resources","title":"Removing Resources","text":"<pre><code>kubectl delete -f pod1.yaml\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#direct-editing","title":"Direct Editing","text":"<pre><code>kubectl edit pods &lt;podName&gt;\n</code></pre> <p>This command allows direct modification of Pod properties. Press <code>i</code> to enter <code>INSERT</code> mode for editing. Exit with <code>Ctrl+C</code> and save with <code>:wq</code> in Vim. A confirmation message indicates successful Pod modification.</p> <p>Note: This method is not recommended; prefer YAML configuration with <code>kubectl apply</code>.</p>"},{"location":"kubernetes/kubernetes-objects/pod/#pod-lifecycle","title":"Pod Lifecycle","text":""},{"location":"kubernetes/kubernetes-objects/pod/#lifecycle-states","title":"Lifecycle States","text":"<ul> <li>Pending \u2192 When a YAML file is submitted, the configuration merges with defaults and is recorded in etcd</li> <li>Creating \u2192 The kube-scheduler continuously monitors etcd for unassigned Pods and selects suitable nodes for   execution. If this stage persists, it indicates that no suitable node can be found<ul> <li>The kubelet continuously monitors etcd for Pods assigned to its node and downloads required container images. If   image retrieval fails, the Pod enters ImagePullBackOff state</li> <li>Upon successful image retrieval and container creation, the Pod transitions to Running state</li> </ul> </li> <li>Succeeded \u2192 Pods that complete successfully enter this state</li> <li>Failed \u2192 Pods that fail to complete enter this state</li> <li>Completed \u2192 Pods that run successfully and exit without errors enter this state</li> <li>\u26a0\ufe0f CrashLoopBackOff \u2192 When a Pod frequently crashes and restarts due to RestartPolicy, Kubernetes detects this   pattern and places the Pod in this state. Pods in this state require investigation</li> </ul>"},{"location":"kubernetes/kubernetes-objects/pod/#container-operation-logic","title":"Container Operation Logic","text":"<p>Container images contain applications designed for continuous operation. Applications terminate in three scenarios:</p> <ol> <li>Normal completion: The application finishes all tasks and exits without errors</li> <li>Graceful shutdown: User or system sends a shutdown signal, and the application exits cleanly</li> <li>Error termination: The application encounters an error, crashes, and exits</li> </ol>"},{"location":"kubernetes/kubernetes-objects/pod/#restart-policies","title":"Restart Policies","text":"<p>When container applications stop, a RestartPolicy defined in the Pod determines the response, with three possible values:</p> <ul> <li><code>Always</code> \u2192 Kubelet automatically restarts the container</li> <li><code>Never</code> \u2192 Kubelet does not restart the container</li> <li><code>OnFailure</code> \u2192 Kubelet only restarts the container when errors occur</li> </ul>"},{"location":"kubernetes/kubernetes-objects/pod/#multi-container-pods","title":"Multi-container Pods","text":""},{"location":"kubernetes/kubernetes-objects/pod/#design-principles","title":"Design Principles","text":"<p>Why Not Place Multiple Applications in the Same Container?</p> <p>Answer: Isolation. Multiple applications should operate independently. Without proper isolation, horizontal scaling becomes problematic. When scaling requires duplication, having multiple applications in the same container results in multiple instances of each application (e.g., 2 MySQL instances, 2 WordPress instances), which is not optimal.</p> <p>\u2705 Therefore, the recommended pattern is 1 Pod = 1 Container = 1 Application. Alternative approaches become * anti-patterns*.</p>"},{"location":"kubernetes/kubernetes-objects/pod/#use-cases-for-multi-container-pods","title":"Use Cases for Multi-container Pods","text":"<p>Why Do Pods Support Multiple Containers?</p> <p>Answer: Some applications require tight integration and dependency management. When the main application starts or stops, dependent containers should follow the same lifecycle. In such cases, multiple containers can be placed in a single Pod.</p> <p>Note: Containers within the same Pod communicate through localhost without requiring network configuration.</p> <p>Accessing Specific Containers in Multi-container Pods:</p> <pre><code>kubectl exec -it &lt;podName&gt; -c &lt;containerName&gt; -- /bin/sh\n</code></pre> podmulticontainer.yaml <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: multicontainer\nspec:\n  containers:\n    - name: webcontainer\n      image: nginx\n      ports:\n        - containerPort: 80\n      volumeMounts:\n        - name: sharedvolume\n          mountPath: /usr/share/nginx/html\n    - name: sidecarcontainer\n      image: busybox\n      command: [ \"/bin/sh\" ]\n      args: [ \"-c\", \"while true; do wget -O /var/log/index.html https://raw.githubusercontent.com/ozlmulg/my-dev-notes/refs/heads/master/docs/kubernetes/assets/index.html; sleep 15; done\" ]\n      volumeMounts:\n        - name: sharedvolume\n          mountPath: /var/log\n  volumes:\n    - name: sharedvolume\n      emptyDir: { }\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#init-containers","title":"Init Containers","text":"<p>Init containers function similarly to the <code>init()</code> function in Go - they execute first before the main application container. For example, if an application requires configuration files before startup, this operation can be performed in the init container.</p> <p>Init Container Workflow:</p> <ol> <li>Init Container Execution: Before the application container starts, the Init Container runs first</li> <li>Task Completion: The Init Container performs its required tasks and terminates</li> <li>Application Startup: The application container starts only after the Init Container completes successfully. The    application container will not start until the Init Container finishes</li> </ol> podinitcontainer.yaml <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: initcontainerpod\nspec:\n  containers:\n    - name: appcontainer\n      image: busybox\n      command: [ 'sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600' ]\n  initContainers:\n    - name: initcontainer\n      image: busybox\n      command: [ 'sh', '-c', \"until nslookup myservice; do echo waiting for myservice; sleep 2; done\" ]\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/pod/#references","title":"References","text":"<ul> <li>Kubernetes Official Pods Overview</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/","title":"Kubernetes Objects - Probes, Resource Limits, Environment Variables","text":""},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#overview","title":"Overview","text":"<p>Kubernetes provides comprehensive mechanisms for monitoring application health, managing resource consumption, and configuring runtime environments. This document covers the essential components for ensuring application reliability and performance.</p>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#liveness-probes","title":"Liveness Probes","text":""},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#purpose","title":"Purpose","text":"<p>Applications running inside containers may not function correctly despite appearing operational. If a running application hasn't crashed or shut down but isn't performing its intended function, kubelet cannot detect this issue automatically.</p> <p>Liveness probes enable organizations to determine whether containers are functioning correctly by sending HTTP requests, establishing TCP connections, or executing commands within containers.</p>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#implementation-methods","title":"Implementation Methods","text":"liveness_probe.yaml <pre><code># HTTP GET request example\n# If it returns 200 or above, it's successful!\n# If not, kubelet will restart the container\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n    - name: liveness\n      image: k8s.gcr.io/liveness\n      args:\n        - /server\n      livenessProbe:\n        httpGet: # We're sending a GET request\n          path: /healthz # Path definition\n          port: 8080 # Port definition\n          httpHeaders: # Optional headers for the GET request\n            - name: Custom-Header\n              value: Awesome\n        initialDelaySeconds: 3 # The application may not start immediately,\n        # send the request after x seconds of running\n        periodSeconds: 3 # How frequently this request will be sent\n        # (health check is performed continuously)\n---\n# Command execution example\n# If exit code -1 is received, the container is restarted\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-exec\nspec:\n  containers:\n    - name: liveness\n      image: k8s.gcr.io/busybox\n      args:\n        - /bin/sh\n        - -c\n        - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600\n      livenessProbe:\n        exec: # Command is executed\n          command:\n            - cat\n            - /tmp/healthy\n        initialDelaySeconds: 5\n        periodSeconds: 5\n---\n# TCP connection example\n# If successful, it continues; otherwise, the container is restarted\napiVersion: v1\nkind: Pod\nmetadata:\n  name: goproxy\n  labels:\n    app: goproxy\nspec:\n  containers:\n    - name: goproxy\n      image: k8s.gcr.io/goproxy:0.1\n      ports:\n        - containerPort: 8080\n      livenessProbe: # TCP connection is created\n        tcpSocket:\n          port: 8080\n        initialDelaySeconds: 15\n        periodSeconds: 20\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#readiness-probes","title":"Readiness Probes","text":""},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#deployment-update-process","title":"Deployment Update Process","text":"<p>When a deployment is updated (e.g., with a new image version), Kubernetes follows this sequence:</p> <ol> <li>Deployment Update: The deployment is updated with the new image (e.g., \"v2\")</li> <li>New Pod Creation: A new Pod with the updated image (v2) is created</li> <li>Pod Startup: The new Pod (v2) starts running</li> <li>Readiness Probe Activation: The readiness check mechanism begins after the <code>initialDelaySeconds</code> period</li> <li>First Health Check: The readiness probe performs its first check</li> <li>Service Integration: Once the check passes, the new Pod (v2) is added to the service</li> <li>Traffic Switch: At this point, the old Pod (v1) is removed from the service, but it's not terminated yet</li> <li>Graceful Shutdown: The old Pod (v1) continues processing any existing requests</li> <li>Termination Signal: Kubernetes sends a SIGTERM signal to allow the Pod to shut down gracefully</li> <li>Pod Termination: After completing its processes, the old Pod (v1) terminates itself</li> </ol>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#use-case","title":"Use Case","text":"<p>Consider a system with 3 Pods and 1 LoadBalancer service. After making an update with a new image, old Pods are removed from service and new ones are added. From the moment new Pods are integrated, the LoadBalancer starts directing incoming traffic. However, applications may need to connect to external services, pull data, process it, and then become operational when they first start. During this initialization period, incoming requests won't be answered correctly. In essence, the application is running but not ready to provide service.</p> <p>Solution: Kubelet uses Readiness Probes to determine when a container is ready to accept traffic (initial status). If all containers in a Pod pass the Readiness Probes check, the Service is added behind the Pod.</p>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#operational-behavior","title":"Operational Behavior","text":"<p>In the example above, when new images are created, old Pods are not immediately terminated. This is because there may be previously received requests and ongoing processes. For this reason, Kubernetes first severs the Pod's relationship with the service, preventing it from receiving new requests, and waits for existing internal requests to complete.</p> <p><code>terminationGracePeriodSeconds: 30</code> \u2192 Existing processes complete, wait 30 seconds, then close. (30 seconds is the default setting and is generally sufficient.)</p> <p>Key Difference: Readiness probes focus on the initial operational moment, while Liveness probes continuously check whether the application is functioning properly.</p> <p>Example: Consider a Backend application that needs time to connect to MongoDB when it first starts. It makes sense for the Service to be added behind the Pod only after the MongoDB connection is established. For this reason, readiness probes are used in this scenario.</p>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#configuration","title":"Configuration","text":"<p>Readiness probes support three different methods, similar to Liveness probes:</p> <ul> <li>HTTP GET requests, TCP connections, and command execution</li> </ul> readiness_probe.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: frontend\n  labels:\n    team: development\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: frontend\n  template:\n    metadata:\n      labels:\n        app: frontend\n    spec:\n      containers:\n        - name: frontend\n          image: ozlmulg/k8s:blue\n          ports:\n            - containerPort: 80\n          livenessProbe:\n            httpGet:\n              path: /healthcheck\n              port: 80\n            initialDelaySeconds: 5\n            periodSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /ready    # A request is sent to this endpoint; if it returns OK, the application is ready\n              port: 80\n            initialDelaySeconds: 20 # First check is made after 20 seconds delay from startup\n            periodSeconds: 3 # Continues trying every 3 seconds\n            terminationGracePeriodSeconds: 50 # Explanation provided above\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: frontend\nspec:\n  selector:\n    app: frontend\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#resource-limits","title":"Resource Limits","text":""},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#purpose_1","title":"Purpose","text":"<p>Resource limits allow organizations to manage CPU and Memory restrictions for Pods. Unless specified otherwise, Pods can utilize 100% of the CPU and Memory of the machine they run on in Kubernetes. This situation can create resource contention issues. For this reason, organizations can specify how much CPU and Memory Pods will use.</p>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#cpu-configuration","title":"CPU Configuration","text":""},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#memory-configuration","title":"Memory Configuration","text":""},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#yaml-configuration","title":"YAML Configuration","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: requestlimit\n  name: requestlimit\nspec:\n  containers:\n    - name: requestlimit\n      image: ozlmulg/stress\n      resources:\n        requests: # Minimum requirements needed for the Pod to function\n          memory: \"64M\"    # This Pod needs at least 64M memory\n          cpu: \"250m\" # = Quarter CPU core = \"0.25\"\n        limits: # Maximum limits for the Pod to function\n          memory: \"256M\"\n          cpu: \"0.5\" # = Half CPU Core = \"500m\"\n</code></pre> <p>Important Notes:</p> <ul> <li>If requirements cannot be met, the container cannot be created</li> <li>Memory behaves differently than CPU. Kubernetes doesn't block when memory requests exceed limits. If memory usage   exceeds limits, the Pod enters \"OOMKilled\" state and is restarted</li> </ul>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#environment-variables","title":"Environment Variables","text":""},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#purpose_2","title":"Purpose","text":"<p>Consider a scenario where a Node.js server is created and database information is stored directly in server files. If the container image created from these server files falls into unauthorized hands, a major security vulnerability occurs. For this reason, Environment Variables must be used.</p>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#configuration_1","title":"Configuration","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: envpod\n  labels:\n    app: frontend\nspec:\n  containers:\n    - name: envpod\n      image: ozlmulg/env:latest\n      ports:\n        - containerPort: 80\n      env:\n        - name: USER   # First we specify the name\n          value: \"TestName\"  # Then we specify the value\n        - name: database\n          value: \"testdb.example.com\"\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#management-operations","title":"Management Operations","text":"<p>Viewing Environment Variables:</p> <pre><code>kubectl exec &lt;podName&gt; -- printenv\n</code></pre> <p>Accessing Applications:</p> <pre><code>kubectl port-forward pod/envpod 8080:80\n</code></pre> <p>Then open <code>localhost:8080</code> in your browser.</p>"},{"location":"kubernetes/kubernetes-objects/probes-resource-limits-env-variables/#references","title":"References","text":"<ul> <li>Kubernetes Official Liveness Readiness Probes Overview</li> <li>GitHub - Aytitech K8sFundamentals - Liveness Readiness Probes</li> <li>GitHub - Aytitech K8sFundamentals - Request Limit</li> </ul>"},{"location":"kubernetes/kubernetes-objects/rbac/","title":"Kubernetes Objects - RBAC","text":""},{"location":"kubernetes/kubernetes-objects/rbac/#overview","title":"Overview","text":"<p>Role-Based Access Control (RBAC) in Kubernetes provides fine-grained access control for users and applications. It allows you to define who can access what resources and perform what actions.</p>"},{"location":"kubernetes/kubernetes-objects/rbac/#purpose","title":"Purpose","text":"<p>RBAC is used for:</p> <ul> <li>Access Control: Control who can access cluster resources</li> <li>Security: Implement least privilege access principles</li> <li>Multi-tenancy: Separate access between different teams</li> <li>Compliance: Meet security and audit requirements</li> </ul>"},{"location":"kubernetes/kubernetes-objects/rbac/#rbac-components","title":"RBAC Components","text":""},{"location":"kubernetes/kubernetes-objects/rbac/#role","title":"Role","text":"<p>A Role defines permissions within a namespace.</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: default\n  name: pod-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#clusterrole","title":"ClusterRole","text":"<p>A ClusterRole defines permissions across the entire cluster.</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: secret-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#rolebinding","title":"RoleBinding","text":"<p>A RoleBinding grants a Role to users or groups within a namespace.</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: read-pods\n  namespace: default\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#clusterrolebinding","title":"ClusterRoleBinding","text":"<p>A ClusterRoleBinding grants a ClusterRole to users or groups across the cluster.</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: read-secrets-global\nsubjects:\n- kind: User\n  name: admin\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: secret-reader\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#common-rbac-patterns","title":"Common RBAC Patterns","text":""},{"location":"kubernetes/kubernetes-objects/rbac/#developer-access","title":"Developer Access","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: development\n  name: developer\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: developer-binding\n  namespace: development\nsubjects:\n- kind: User\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#read-only-access","title":"Read-Only Access","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: production\n  name: viewer\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#admin-access","title":"Admin Access","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: cluster-admin\nrules:\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-binding\nsubjects:\n- kind: User\n  name: admin\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#testing-permissions","title":"Testing Permissions","text":""},{"location":"kubernetes/kubernetes-objects/rbac/#check-user-permissions","title":"Check User Permissions","text":"<pre><code># Test if user can perform action\nkubectl auth can-i create pods\nkubectl auth can-i delete pods --namespace=default\nkubectl auth can-i get secrets --as=jane --as-group=developers\n\n# Examples:\nkubectl auth can-i create pods\nkubectl auth can-i delete pods --namespace=production\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#check-specific-resources","title":"Check Specific Resources","text":"<pre><code># Test permissions for specific resource\nkubectl auth can-i get pods --subresource=log\nkubectl auth can-i create deployments --namespace=development\n\n# Examples:\nkubectl auth can-i get pods --subresource=log\nkubectl auth can-i create deployments --namespace=development\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#basic-commands","title":"Basic Commands","text":"<pre><code># Create Role\nkubectl create role &lt;role-name&gt; --verb=get,list,watch --resource=pods,services\n\n# Create ClusterRole\nkubectl create clusterrole &lt;clusterrole-name&gt; --verb=get,list,watch --resource=pods,services\n\n# Create RoleBinding\nkubectl create rolebinding &lt;rolebinding-name&gt; --role=&lt;role-name&gt; --user=&lt;user-name&gt;\n\n# Create ClusterRoleBinding\nkubectl create clusterrolebinding &lt;clusterrolebinding-name&gt; --clusterrole=&lt;clusterrole-name&gt; --user=&lt;user-name&gt;\n\n# Check permissions\nkubectl auth can-i &lt;verb&gt; &lt;resource&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rbac/#references","title":"References","text":"<ul> <li>Kubernetes RBAC</li> <li>GitHub - Aytitech K8sFundamentals - RBAC</li> </ul>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/","title":"Kubernetes Objects - Rollout and Rollback","text":""},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#overview","title":"Overview","text":"<p>Rollout and Rollback concepts become relevant and meaningful during deployment updates. When defining deployments with YAML, two strategy types can be selected to control how updates are applied.</p>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#deployment-strategies","title":"Deployment Strategies","text":""},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#recreate-strategy","title":"Recreate Strategy","text":"<p>The Recreate strategy completely replaces all existing Pods with new ones during updates.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rcdeployment\n  labels:\n    team: development\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: recreate \n  strategy:\n    type: Recreate # Recreate strategy\n... \n</code></pre> <p>Behavior: \"If I make a change in this deployment, first delete all existing pods, then create new ones.\" This method is primarily used when hard migration is required.</p> <p>Use Case: This strategy is chosen when it is risky for the new version of an application to coexist with the old version.</p> <p>Example: RabbitMQ consumer applications. In such scenarios, having old and new versions running simultaneously is generally not preferred. Therefore, <code>Recreate</code> should be selected as the strategy.</p>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#rollingupdate-strategy","title":"RollingUpdate Strategy","text":"<p>The RollingUpdate strategy gradually replaces Pods while maintaining service availability.</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: rolldeployment\n  labels:\n    team: development\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: rolling\n  strategy:\n    type: RollingUpdate # Rolling update strategy\n    rollingUpdate:\n      maxUnavailable: 2 # Maximum pods deleted simultaneously during update\n      maxSurge: 2       # Maximum total active pod count during update\n  template:\n  ...\n</code></pre> <p>Default Behavior: If no strategy is specified in the YAML file, RollingUpdate is automatically selected. The * maxUnavailable and maxSurge values default to 25%.*</p> <p>Behavior: RollingUpdate is the opposite of Recreate. \"When making changes, don't delete all pods at once and * create* new ones.\" This strategy includes two important parameters:</p> <ul> <li><code>maxUnavailable</code> \u2192 Maximum number of pods that can be deleted during an update. (Can also be specified as a   percentage, e.g., 20%.)</li> <li><code>maxSurge</code> \u2192 Maximum number of active pods that should exist in the system during the update transition.</li> </ul>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#update-operations","title":"Update Operations","text":""},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#image-updates","title":"Image Updates","text":"<p>Consider a deployment with image = nginx. To update the existing deployment with the following command, replacing nginx with httpd-alpine:</p> <pre><code>kubectl set image deployment rolldeployment nginx=httpd-alpine --record=true\n</code></pre> <p>The <code>--record=true</code> parameter records all update stages for future reference. This is particularly useful when rollback to previous states is needed.</p>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#deployment-history","title":"Deployment History","text":"<pre><code># rolldeployment = deploymentName\n# Lists all changes made to the deployment\nkubectl rollout history deployment rolldeployment \n\n# To see specific changes for a particular revision:\nkubectl rollout history deployment rolldeployment --revision=2\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#rollback-operations","title":"Rollback Operations","text":"<pre><code># rolldeployment = deploymentName\n# To revert to the previous state:\nkubectl rollout undo deployment rolldeployment\n\n# To revert to a specific revision:\nkubectl rollout undo deployment rolldeployment --to-revision=1\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#monitoring-and-control","title":"Monitoring and Control","text":"<p>Real-time Status Monitoring</p> <pre><code># rolldeployment = deploymentName\nkubectl rollout status deployment rolldeployment -w \n</code></pre> <p>Pausing Updates</p> <p>This feature is used when problems occur during updates and you want to investigate the issue without rolling back.</p> <pre><code># rolldeployment = deploymentName\nkubectl rollout pause deployment rolldeployment\n</code></pre> <p>Resuming Updates</p> <pre><code>kubectl rollout resume deployment rolldeployment\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/rollout-rollback/#references","title":"References","text":"<ul> <li>Kubernetes Official Rolling Update</li> <li>Kubernetes Official Kubectl Rollout</li> <li>GitHub - Aytitech K8sFundamentals - Deployment</li> </ul>"},{"location":"kubernetes/kubernetes-objects/service-account/","title":"Kubernetes Objects - Service Account","text":""},{"location":"kubernetes/kubernetes-objects/service-account/#overview","title":"Overview","text":"<p>Service Accounts in Kubernetes provide an identity for Pods and other workloads to authenticate with the Kubernetes API. They are used to control what resources and operations a Pod can access.</p>"},{"location":"kubernetes/kubernetes-objects/service-account/#purpose","title":"Purpose","text":"<p>Service Accounts are used for:</p> <ul> <li>Pod Identity: Give Pods an identity for API access</li> <li>RBAC Integration: Control Pod permissions through RBAC</li> <li>Security: Implement least privilege access for applications</li> <li>Automation: Enable automated operations by Pods</li> </ul>"},{"location":"kubernetes/kubernetes-objects/service-account/#basic-service-account","title":"Basic Service Account","text":"<pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: app-service-account\n  namespace: default\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#service-account-with-image-pull-secrets","title":"Service Account with Image Pull Secrets","text":"<pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: app-service-account\n  namespace: production\nimagePullSecrets:\n- name: production-registry-secret\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#using-service-account-in-pod","title":"Using Service Account in Pod","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: app-pod\nspec:\n  serviceAccountName: app-service-account\n  containers:\n  - name: app\n    image: nginx\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#using-service-account-in-deployment","title":"Using Service Account in Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      serviceAccountName: app-service-account\n      containers:\n      - name: app\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#service-account-with-rbac","title":"Service Account with RBAC","text":"<pre><code># Service Account\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: monitoring-sa\n  namespace: monitoring\n---\n# Role for monitoring\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: monitoring\n  name: monitoring-role\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\n# RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: monitoring-binding\n  namespace: monitoring\nsubjects:\n- kind: ServiceAccount\n  name: monitoring-sa\n  namespace: monitoring\nroleRef:\n  kind: Role\n  name: monitoring-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#default-service-account","title":"Default Service Account","text":"<p>Every namespace has a default service account:</p> <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: default\n  namespace: default\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#basic-commands","title":"Basic Commands","text":"<pre><code># Create Service Account\nkubectl create serviceaccount &lt;serviceaccount-name&gt;\n\n# List Service Accounts\nkubectl get serviceaccount\nkubectl get sa\n\n# Check Service Account details\nkubectl describe serviceaccount &lt;serviceaccount-name&gt;\n\n# Delete Service Account\nkubectl delete serviceaccount &lt;serviceaccount-name&gt;\n\n# Create token for Service Account\nkubectl create token &lt;serviceaccount-name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/service-account/#application-service-account","title":"Application Service Account","text":"<pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: web-app-sa\n  namespace: web\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\n  namespace: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      serviceAccountName: web-app-sa\n      containers:\n      - name: web-app\n        image: nginx:latest\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#monitoring-service-account","title":"Monitoring Service Account","text":"<pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: prometheus-sa\n  namespace: monitoring\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: prometheus\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prometheus\n  template:\n    metadata:\n      labels:\n        app: prometheus\n    spec:\n      serviceAccountName: prometheus-sa\n      containers:\n      - name: prometheus\n        image: prom/prometheus:latest\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/service-account/#references","title":"References","text":"<ul> <li>Kubernetes Service Accounts</li> <li>GitHub - Aytitech K8sFundamentals - ServiceAccount</li> </ul>"},{"location":"kubernetes/kubernetes-objects/statefulset/","title":"Kubernetes Objects - StatefulSet","text":""},{"location":"kubernetes/kubernetes-objects/statefulset/#overview","title":"Overview","text":"<p>StatefulSets in Kubernetes manage stateful applications that require stable network identities, stable persistent storage, and ordered deployment and scaling.</p>"},{"location":"kubernetes/kubernetes-objects/statefulset/#purpose","title":"Purpose","text":"<p>StatefulSets are used for:</p> <ul> <li>Stateful Applications: Databases, message queues, key-value stores</li> <li>Stable Network Identity: Each Pod gets a predictable hostname</li> <li>Ordered Deployment: Pods are created and scaled in order</li> <li>Persistent Storage: Each Pod gets its own persistent storage</li> </ul>"},{"location":"kubernetes/kubernetes-objects/statefulset/#basic-statefulset","title":"Basic StatefulSet","text":"<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: \"nginx\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/statefulset/#statefulset-with-headless-service","title":"StatefulSet with Headless Service","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  ports:\n  - port: 80\n    name: web\n  clusterIP: None\n  selector:\n    app: nginx\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: \"nginx\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/statefulset/#statefulset-with-update-strategy","title":"StatefulSet with Update Strategy","text":"<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: \"nginx\"\n  replicas: 3\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      partition: 0\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/statefulset/#statefulset-with-scaling","title":"StatefulSet with Scaling","text":"<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: \"nginx\"\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.19\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/statefulset/#basic-commands","title":"Basic Commands","text":"<pre><code># Create StatefulSet\nkubectl apply -f statefulset.yaml\n\n# List StatefulSets\nkubectl get statefulset\nkubectl get sts\n\n# Check StatefulSet status\nkubectl describe statefulset &lt;statefulset-name&gt;\n\n# Scale StatefulSet\nkubectl scale statefulset &lt;statefulset-name&gt; --replicas=5\n\n# Update StatefulSet image\nkubectl set image statefulset/&lt;statefulset-name&gt; &lt;container-name&gt;=&lt;new-image&gt;\n\n# Delete StatefulSet\nkubectl delete statefulset &lt;statefulset-name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/statefulset/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/statefulset/#database-statefulset","title":"Database StatefulSet","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  ports:\n  - port: 3306\n    name: mysql\n  clusterIP: None\n  selector:\n    app: mysql\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  serviceName: \"mysql\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: mysql\n        image: mysql:8.0\n        ports:\n        - containerPort: 3306\n          name: mysql\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: \"password\"\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 10Gi\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/statefulset/#redis-statefulset","title":"Redis StatefulSet","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: redis\n  labels:\n    app: redis\nspec:\n  ports:\n  - port: 6379\n    name: redis\n  clusterIP: None\n  selector:\n    app: redis\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis\nspec:\n  serviceName: \"redis\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: redis\n  template:\n    metadata:\n      labels:\n        app: redis\n    spec:\n      containers:\n      - name: redis\n        image: redis:6-alpine\n        ports:\n        - containerPort: 6379\n          name: redis\n        volumeMounts:\n        - name: data\n          mountPath: /data\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 5Gi\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/statefulset/#references","title":"References","text":"<ul> <li>Kubernetes StatefulSets</li> <li>GitHub - Aytitech K8sFundamentals - StatefulSet</li> </ul>"},{"location":"kubernetes/kubernetes-objects/storage-class/","title":"Kubernetes Objects - Storage Class","text":""},{"location":"kubernetes/kubernetes-objects/storage-class/#overview","title":"Overview","text":"<p>StorageClass provides a way for administrators to describe the \"classes\" of storage they offer. Different classes might map to quality-of-service levels, or to backup policies, or to arbitrary policies determined by the cluster administrators.</p>"},{"location":"kubernetes/kubernetes-objects/storage-class/#purpose","title":"Purpose","text":"<p>StorageClasses are used for:</p> <ul> <li>Storage Provisioning: Automatically provision storage when PVCs are created</li> <li>Storage Policies: Define different storage types with specific characteristics</li> <li>Quality of Service: Provide different performance and reliability levels</li> <li>Cost Optimization: Offer various storage options at different price points</li> </ul>"},{"location":"kubernetes/kubernetes-objects/storage-class/#basic-storageclass","title":"Basic StorageClass","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: standarddisk\nparameters:\n  cachingmode: ReadOnly\n  kind: Managed\n  storageaccounttype: StandardSSD_LRS\nprovisioner: kubernetes.io/azure-disk\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#cloud-provider-storageclasses","title":"Cloud Provider StorageClasses","text":""},{"location":"kubernetes/kubernetes-objects/storage-class/#azure-disk-storageclass","title":"Azure Disk StorageClass","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: azure-ssd\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"true\"\nprovisioner: kubernetes.io/azure-disk\nparameters:\n  storageaccounttype: Premium_LRS\n  kind: Managed\n  cachingmode: ReadWrite\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#aws-ebs-storageclass","title":"AWS EBS StorageClass","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: aws-gp3\nprovisioner: ebs.csi.aws.com\nparameters:\n  type: gp3\n  iops: \"3000\"\n  throughput: \"125\"\n  encrypted: \"true\"\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#gcp-persistent-disk-storageclass","title":"GCP Persistent Disk StorageClass","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: gcp-ssd\nprovisioner: pd.csi.storage.gke.io\nparameters:\n  type: pd-ssd\n  replication-type: regional-pd\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#on-premises-storageclasses","title":"On-Premises StorageClasses","text":""},{"location":"kubernetes/kubernetes-objects/storage-class/#nfs-storageclass","title":"NFS StorageClass","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: nfs-storage\nprovisioner: example.com/nfs\nparameters:\n  server: nfs-server.example.com\n  path: /exports\n  mountOptions: \"nfsvers=4\"\nreclaimPolicy: Retain\nvolumeBindingMode: Immediate\nallowVolumeExpansion: false\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#local-storage-storageclass","title":"Local Storage StorageClass","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer\nreclaimPolicy: Retain\nallowVolumeExpansion: false\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#volume-binding-modes","title":"Volume Binding Modes","text":""},{"location":"kubernetes/kubernetes-objects/storage-class/#immediate-binding","title":"Immediate Binding","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: immediate-binding\nprovisioner: kubernetes.io/azure-disk\nparameters:\n  storageaccounttype: Standard_LRS\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate  # Volume is bound immediately when PVC is created\nallowVolumeExpansion: false\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#waitforfirstconsumer-binding","title":"WaitForFirstConsumer Binding","text":"<pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: wait-for-consumer\nprovisioner: kubernetes.io/azure-disk\nparameters:\n  storageaccounttype: Standard_LRS\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer  # Volume is bound when Pod is scheduled\nallowVolumeExpansion: false\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#using-storageclasses-with-pvcs","title":"Using StorageClasses with PVCs","text":""},{"location":"kubernetes/kubernetes-objects/storage-class/#pvc-with-specific-storageclass","title":"PVC with Specific StorageClass","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysqlclaim\nspec:\n  accessModes:\n    - ReadWriteOnce\n  volumeMode: Filesystem\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: \"standarddisk\"  # Use specific StorageClass\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#pvc-with-default-storageclass","title":"PVC with Default StorageClass","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: default-storage-claim\nspec:\n  accessModes:\n    - ReadWriteOnce\n  volumeMode: Filesystem\n  resources:\n    requests:\n      storage: 10Gi\n  # No storageClassName specified - uses default StorageClass\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#basic-commands","title":"Basic Commands","text":"<pre><code># List StorageClasses\nkubectl get storageclass\nkubectl get sc\n\n# Check StorageClass details\nkubectl describe storageclass &lt;storageclass-name&gt;\n\n# Get StorageClass YAML\nkubectl get storageclass &lt;storageclass-name&gt; -o yaml\n\n# Delete StorageClass\nkubectl delete storageclass &lt;storageclass-name&gt;\n\n# Set default StorageClass\nkubectl patch storageclass &lt;storageclass-name&gt; -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#common-use-cases","title":"Common Use Cases","text":""},{"location":"kubernetes/kubernetes-objects/storage-class/#multi-tier-storage-strategy","title":"Multi-tier Storage Strategy","text":"<pre><code># Fast SSD StorageClass for databases\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: kubernetes.io/azure-disk\nparameters:\n  storageaccounttype: Premium_LRS\n  kind: Managed\n  cachingmode: ReadWrite\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n---\n# Standard HDD StorageClass for logs\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: standard-hdd\nprovisioner: kubernetes.io/azure-disk\nparameters:\n  storageaccounttype: Standard_LRS\n  kind: Managed\n  cachingmode: ReadOnly\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#database-deployment-with-storageclass","title":"Database Deployment with StorageClass","text":"<pre><code># StorageClass for database\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: db-storage\nprovisioner: kubernetes.io/azure-disk\nparameters:\n  storageaccounttype: Premium_LRS\n  kind: Managed\n  cachingmode: ReadWrite\nreclaimPolicy: Delete\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n---\n# PVC using the StorageClass\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysql-storage\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n  storageClassName: db-storage\n---\n# Deployment using the PVC\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-deployment\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n        - name: mysql\n          image: mysql:8.0\n          ports:\n            - containerPort: 3306\n          volumeMounts:\n            - mountPath: \"/var/lib/mysql\"\n              name: mysql-storage\n      volumes:\n        - name: mysql-storage\n          persistentVolumeClaim:\n            claimName: mysql-storage\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/storage-class/#references","title":"References","text":"<ul> <li>Kubernetes StorageClasses</li> <li>GitHub - Aytitech K8sFundamentals - StorageClass</li> </ul>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/","title":"Kubernetes Objects - Volume, Secret, ConfigMap","text":""},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#overview","title":"Overview","text":"<p>Kubernetes provides comprehensive storage solutions for managing data persistence, sensitive information, and configuration management. This document covers the essential components for data management within Kubernetes clusters.</p>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#volume-management","title":"Volume Management","text":""},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#purpose","title":"Purpose","text":"<p>Container files are ephemeral and exist only while the container is running. When containers are deleted, these files are also removed. Each time a new container is created, container-specific files are recreated from scratch. (This represents the stateless concept)</p> <p>In certain scenarios, these files need to persist beyond container lifecycle. This is where Ephemeral (Temporary) Volume concepts become relevant. (This represents the stateful concept) For example, to prevent data loss in database containers, volume structures should be implemented.</p> <p>Ephemeral Volumes can be mounted to all containers within the same Pod simultaneously. Another purpose is to create shared storage areas that multiple containers in the same Pod can utilize collaboratively.</p> <p>Important Note: In Ephemeral Volumes, if the Pod is deleted, all data is lost. However, if only the container is deleted and recreated, data persists as long as the Pod remains intact.</p>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#volume-types","title":"Volume Types","text":"<p>There are two types of Ephemeral Volumes:</p>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#emptydir-volume","title":"emptyDir Volume","text":"<p>Sample YAML file to create an emptyDir volume:</p> emptydir.yaml <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: emptydir\nspec:\n  containers:\n    - name: frontend\n      image: ozlmulg/k8s:blue\n      ports:\n        - containerPort: 80\n      livenessProbe:\n        httpGet:\n          path: /healthcheck\n          port: 80\n        initialDelaySeconds: 5\n        periodSeconds: 5\n      volumeMounts:\n        - name: cache-vol # Provides connection with volume\n          mountPath: /cache # Mount point within the container\n    - name: sidecar\n      image: busybox\n      command: [ \"/bin/sh\" ]\n      args: [ \"-c\", \"sleep 3600\" ]\n      volumeMounts:\n        - name: cache-vol\n          mountPath: /tmp/log # Mount point within the container\n  volumes:\n    - name: cache-vol # First we create the volume, then we mount it to containers\n      emptyDir: { }\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#hostpath-volume","title":"hostPath Volume","text":"<p>Usage Warning: This volume type is rarely used and requires careful consideration when implemented.</p> <p>While emptyDir creates volume folders within the Pod, hostPath creates volume folders on the worker node itself. Three different types are supported:</p> <ul> <li>Directory \u2192 Used for folders that already exist on the worker node</li> <li>DirectoryOrCreate \u2192 Used for existing folders or to create the folder if it doesn't exist</li> <li>FileOrCreate \u2192 Not a folder! Used for single files. If the file doesn't exist, it's created</li> </ul> <p></p> <p>Sample YAML file to create a hostPath volume:</p> hostpath.yaml <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: hostpath\nspec:\n  containers:\n    - name: hostpathcontainer\n      image: ozlmulg/k8s:blue\n      ports:\n        - containerPort: 80\n      livenessProbe:\n        httpGet:\n          path: /healthcheck\n          port: 80\n        initialDelaySeconds: 5\n        periodSeconds: 5\n      volumeMounts:\n        - name: directory-vol\n          mountPath: /dir1\n        - name: dircreate-vol\n          mountPath: /cache\n        - name: file-vol\n          mountPath: /cache/config.json\n  volumes:\n    - name: directory-vol\n      hostPath:\n        path: /tmp\n        type: Directory\n    - name: dircreate-vol\n      hostPath:\n        path: /cache\n        type: DirectoryOrCreate\n    - name: file-vol\n      hostPath:\n        path: /cache/config.json\n        type: FileOrCreate\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#secret-management","title":"Secret Management","text":""},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#purpose_1","title":"Purpose","text":"<p>Although sensitive information (database credentials, etc.) can be stored in Environment Variables, this approach may not be ideal for security and management purposes.</p> <p>The Secret object allows organizations to separate sensitive information from application object definitions in YAML files and manage them independently. It's always safer and more flexible to store sensitive data such as tokens, usernames, and passwords in Secret objects.</p>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#creation-methods","title":"Creation Methods","text":""},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#declarative-creation","title":"Declarative Creation","text":"<p>Important: The Secret and the Pods it will be assigned to must be in the same namespace.</p> <p>Eight different types of secrets can be created. <code>Opaque</code> is a generic type that can store almost all sensitive data.</p> <p>Example secret.yaml file:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: mysecret\ntype: Opaque\nstringData: # Sensitive data is written under stringData\n  db_server: db.example.com\n  db_username: admin\n  db_password: P@ssw0rd!\n</code></pre> <p>To view the data in the secret:</p> <pre><code>kubectl describe secrets &lt;secretName&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#imperative-creation","title":"Imperative Creation","text":"<pre><code>kubectl create secret generic &lt;secretName&gt; --from-literal=db_server=db.example.com --from-literal=db_username=admin\n</code></pre> <p>\u26a0\ufe0f Note: <code>generic</code> here corresponds to <code>Opaque</code> type specified in YAML.</p> <p>Alternative Approach: If organizations prefer not to enter sensitive data via CLI, they can store each piece of data in separate <code>.txt</code> files and use the <code>--from-file=db_server=server.txt</code> command. They can also use <code>.json</code> files instead of <code>.txt</code> files by specifying <code>--from-file=config.json</code>.</p> <p>JSON example:</p> <pre><code>{\n  \"apiKey\": \"9bxa108d4b2212f2c30c71dfa279e1f77cc5c3b1\"\n}\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#integration-with-pods","title":"Integration with Pods","text":"<p>There are two methods to transfer created Secrets to Pods:</p> <p>Method 1: Volume Mount and Method 2: Environment Variables</p> <p>Both methods are demonstrated in the YAML file below:</p> secretpodvolume.yaml <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: secretpodvolume\nspec:\n  containers:\n    - name: secretcontainer\n      image: ozlmulg/k8s:blue\n      volumeMounts: # 2) We include the created secret volume in the pod\n        - name: secret-vol\n          mountPath: /secret # 3) The /secret folder in the application is mounted to the volume\n          # Now we can access this file from within the application and read the values\n  volumes: # 1) First we create the volume and include the secret in the volume\n    - name: secret-vol\n      secret:\n        secretName: mysecret3\n        # When we enter this pod with exec, we will see a secret folder under root. The file names here are \"KEYs\", the values inside are \"VALUEs\"\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: secretpodenv\nspec:\n  containers:\n    - name: secretcontainer\n      image: ozlmulg/k8s:blue\n      env: # We can define all secrets as environment variables in the pod\n        # In this method, we defined all secrets and their values individually\n        - name: username\n          valueFrom:\n            secretKeyRef:\n              name: mysecret3 # Take the value with \"db_username\" key from the secret named mysecret3\n              key: db_username\n        - name: password\n          valueFrom:\n            secretKeyRef:\n              name: mysecret3\n              key: db_password\n        - name: server\n          valueFrom:\n            secretKeyRef:\n              name: mysecret3\n              key: db_server\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: secretpodenvall\nspec:\n  containers:\n    - name: secretcontainer\n      image: ozlmulg/k8s:blue\n      envFrom: # Same as method 2, only difference is we define all secrets at once\n        - secretRef:\n            name: mysecret3\n</code></pre> <p>Viewing All Environment Variables in Pods</p> <pre><code>kubectl exec &lt;podName&gt; -- printenv\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#configmap-management","title":"ConfigMap Management","text":""},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#purpose_2","title":"Purpose","text":"<p>ConfigMaps operate using exactly the same logic as Secret objects. The key difference is that Secrets are stored encrypted in etcd using base64 encoding, while ConfigMaps are not encrypted and therefore should not contain sensitive data.</p> <p>ConfigMaps can be defined as Volumes or Environment Variables in Pods. Since creation methods are identical to Secrets, the commands above remain valid.</p>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#configuration","title":"Configuration","text":"configmap.yaml <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: myconfigmap\ndata: # Should be entered in Key-Value format\n  db_server: \"db.example.com\"\n  database: \"mydatabase\"\n  site.settings: | # \"|\" is used for multi-line writing\n    color=blue\n    padding:25px\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: configmappod\nspec:\n  containers:\n    - name: configmapcontainer\n      image: ozlmulg/k8s:blue\n      env:\n        - name: DB_SERVER\n          valueFrom:\n            configMapKeyRef:\n              name: myconfigmap\n              key: db_server\n        - name: DATABASE\n          valueFrom:\n            configMapKeyRef:\n              name: myconfigmap\n              key: database\n      volumeMounts:\n        - name: config-vol\n          mountPath: \"/config\"\n          readOnly: true\n  volumes:\n    - name: config-vol\n      configMap:\n        name: myconfigmap\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#file-based-creation","title":"File-based Creation","text":"<p>Consider scenarios where organizations have <code>config.qa.yaml</code> or <code>config.prod.json</code> files for different environments (QA, SIT, and PROD) to be used in applications. How can ConfigMaps be created from the appropriate configuration file based on these environments in CI/CD?</p> config.json <pre><code>{\n  \"name\": \"TestName\",\n  \"surName\": \"TestSurname\",\n  \"email\": \"test@testmail.com\",\n  \"apiKey\": \"9bxa108d4b2212f2c30c71dfa279e1f77cc5c3b1\",\n  \"text\": [\n    \"test\",\n    \"example\",\n    \"one\",\n    \"two\",\n    3,\n    true\n  ]\n}\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#creation-process","title":"Creation Process","text":"<p>Creating a ConfigMap from config.json file via Kubectl:</p> <p>If running in CI/CD and want to track logs:</p> <pre><code># --dry-run is normally deprecated, but still used in older versions\nkubectl create configmap xyzconfig --from-file ${configFile} -o yaml --dry-run | kubectl apply -f -\n\n# New version --dry-run=\"client\"\nkubectl create configmap testconfig --from-file config.json -o yaml --dry-run=\"client\" | kubectl apply -f -\n\n# The \"-\" (dash) at the end takes the output from the first part of the pipe\n</code></pre> <p>When running the command above, kubectl takes the config.json file, creates ConfigMap YAML content that can be used with the <code>kubectl apply</code> command, and prints this content to the screen as output due to the <code>--dry-run</code> option.</p> <p>Organizations capture the incoming output (using bash \"pipe | \") and send it to their cluster with the <code>kubectl apply</code> command to create the ConfigMap.</p> <p>If organizations want to create a ConfigMap directly from the config.json file without reading logs:</p> <pre><code># Organizations can use many format files instead of config.json: e.g., yaml\nkubectl create configmap &lt;configName&gt; --from-file config.json\n</code></pre> <ol> <li> <p>Pod Integration: When creating the Pod, organizations need to transfer the values in ConfigMaps to files in    folders inside Pods and store them as files using \"volume\" logic.</p> </li> <li> <p>Define volumes and configMaps in the \"volumes\" section</p> </li> <li>In the \"volumeMounts\" section inside the Pod, introduce this volume to the pod<ul> <li>In the <code>mountPath</code> section, specify under which folder the file in the configMap will be copied inside the Pod   and what its new name will be</li> <li>With <code>subPath</code>, provide the name of the file in the configMap (e.g., <code>config.json</code>). Thus, when the Pod is   created, specify \"This file's name will change\"</li> </ul> </li> </ol> configmappod4.yaml <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: configmappod4\nspec:\n  containers:\n    - name: configmapcontainer\n      image: ozlmulg/k8s:blue\n      volumeMounts:\n        - name: config-vol\n          mountPath: \"/config/newconfig.json\"\n          subPath: \"config.json\"\n          readOnly: true\n  volumes:\n    - name: config-vol\n      configMap:\n        name: test-config # This ConfigMap contains the config.json file\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#alternative-volume-definition-syntax","title":"Alternative Volume Definition Syntax","text":"<p>Organizations can also write the volumes section in a different way:</p> configmappod.yaml <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: configmappod\nspec:\n  containers:\n    - name: configmapcontainer\n      image: ozlmulg/k8s:blue\n      volumeMounts:\n        - name: config-vol\n          mountPath: \"/config/newconfig.json\"\n          subPath: \"config.json\"\n          readOnly: true\n  volumes:\n    - name: config-vol\n      projected:\n        sources:\n          - configMap:\n              name: test-config\n              items:\n                - key: config.json\n                  path: config.json\n</code></pre>"},{"location":"kubernetes/kubernetes-objects/volume-secret-configmap/#references","title":"References","text":"<ul> <li>Kubernetes Official Volume Overview</li> <li>Kubernetes Official Secrets Overview</li> <li>Kubernetes Official Configmaps Overview</li> <li>GitHub - Aytitech K8sFundamentals - Volume</li> <li>GitHub - Aytitech K8sFundamentals - Secret/Configmap</li> </ul>"},{"location":"kubernetes/kubernetes-tools/dashboards/","title":"Kubernetes Dashboards","text":"<p>This guide provides an overview and installation instructions for three popular Kubernetes dashboard tools:</p> <ul> <li>Kubernetes Dashboard</li> <li>Lens</li> <li>Headlamp</li> </ul> <p>These tools make it easier to visualize, manage, and troubleshoot Kubernetes clusters.</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#1-kubernetes-dashboard","title":"1. Kubernetes Dashboard","text":""},{"location":"kubernetes/kubernetes-tools/dashboards/#overview","title":"Overview","text":"<p>The Kubernetes Dashboard is a web-based UI that allows you to manage applications, monitor cluster resources, and troubleshoot workloads within your cluster.</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#installation","title":"Installation","text":"<p>Deploy the dashboard with the following command:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/dashboards/#accessing-the-dashboard","title":"Accessing the Dashboard","text":"<p>Create a Service Account and ClusterRoleBinding:</p> <pre><code>kubectl create serviceaccount dashboard-admin-sa -n kubernetes-dashboard\nkubectl create clusterrolebinding dashboard-admin-sa   --clusterrole=cluster-admin   --serviceaccount=kubernetes-dashboard:dashboard-admin-sa\n</code></pre> <p>Get the authentication token:</p> <pre><code>kubectl -n kubernetes-dashboard create token dashboard-admin-sa\n</code></pre> <p>Start the proxy:</p> <pre><code>kubectl proxy\n</code></pre> <p>Access the dashboard at: http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#using-kubernetes-dashboard-with-minikube","title":"Using Kubernetes Dashboard with Minikube","text":"<p>If you are running Kubernetes with Minikube, enabling the dashboard is even easier.</p> <p>Enable the Dashboard Addon:</p> <pre><code>minikube addons enable dashboard\n</code></pre> <p>Start the Dashboard:</p> <pre><code>minikube dashboard\n</code></pre> <p>This command will automatically open the Dashboard in your default web browser.</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#2-lens","title":"2. Lens","text":""},{"location":"kubernetes/kubernetes-tools/dashboards/#overview_1","title":"Overview","text":"<p>Lens is a popular desktop application for Kubernetes cluster management. It provides an intuitive interface for monitoring workloads, nodes, logs, and cluster health.</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#installation_1","title":"Installation","text":"<ul> <li>macOS (Homebrew):</li> </ul> <pre><code>brew install --cask lens\n</code></pre> <ul> <li>Windows (Chocolatey):</li> </ul> <pre><code>choco install lens\n</code></pre> <ul> <li> <p>Linux (AppImage):   Download the latest <code>.AppImage</code> from the Lens GitHub releases.</p> </li> <li> <p>Or directly download Lens from the Lens Official Website.</p> </li> </ul>"},{"location":"kubernetes/kubernetes-tools/dashboards/#usage","title":"Usage","text":"<ul> <li>Start Lens and add your cluster via <code>~/.kube/config</code>.</li> <li>Explore resources such as pods, deployments, and services.</li> <li>Use built-in terminal and monitoring features for troubleshooting.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/dashboards/#3-headlamp","title":"3. Headlamp","text":""},{"location":"kubernetes/kubernetes-tools/dashboards/#overview_2","title":"Overview","text":"<p>Headlamp is an open-source, web-based Kubernetes UI. Unlike Lens, it runs as a web app and supports plugins for customization.</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#installation_2","title":"Installation","text":"<p>You can run Headlamp as a desktop app or deploy it into a cluster.</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#option-1-desktop-app","title":"Option 1: Desktop App","text":"<ul> <li>macOS (Homebrew):</li> </ul> <pre><code>brew install headlamp\n</code></pre> <ul> <li>Linux &amp; Windows:   Download binaries from the Headlamp releases.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/dashboards/#option-2-deploy-in-cluster","title":"Option 2: Deploy in Cluster","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/headlamp-k8s/headlamp/main/kubernetes-headlamp.yaml\n</code></pre> <p>Expose the service (e.g., via <code>kubectl port-forward</code> or Ingress).</p>"},{"location":"kubernetes/kubernetes-tools/dashboards/#usage_1","title":"Usage","text":"<ul> <li>Log in with your kubeconfig file or token.</li> <li>Navigate through workloads, namespaces, and nodes.</li> <li>Extend functionality using available plugins.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/dashboards/#comparison","title":"Comparison","text":"Feature Kubernetes Dashboard Lens (Desktop) Headlamp (Web/Desktop) Interface Web UI Desktop app Web &amp; Desktop app Installation In-cluster YAML Binary/AppImage In-cluster or Desktop Authentication Token kubeconfig kubeconfig / token Extensibility Limited No plugins Plugin system <p>\u2705 You can choose the tool that best fits your needs:</p> <ul> <li>Kubernetes Dashboard \u2192 Official and lightweight.</li> <li>Lens \u2192 Powerful desktop client.</li> <li>Headlamp \u2192 Flexible, extensible, and web-based.  </li> </ul>"},{"location":"kubernetes/kubernetes-tools/helm/","title":"Helm","text":""},{"location":"kubernetes/kubernetes-tools/helm/#overview","title":"Overview","text":"<p>Helm is the package manager for Kubernetes. It simplifies the deployment and management of Kubernetes applications by packaging them into charts - a collection of files that describe a related set of Kubernetes resources.</p>"},{"location":"kubernetes/kubernetes-tools/helm/#installation","title":"Installation","text":""},{"location":"kubernetes/kubernetes-tools/helm/#macos-homebrew","title":"macOS (Homebrew)","text":"<pre><code>brew install helm\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#linux","title":"Linux","text":"<pre><code>curl https://get.helm.sh/helm-v3.12.0-linux-amd64.tar.gz | tar xz\nsudo mv linux-amd64/helm /usr/local/bin/helm\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#windows","title":"Windows","text":"<pre><code># Using Chocolatey\nchoco install kubernetes-helm\n\n# Using Scoop\nscoop install helm\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#verify-installation","title":"Verify Installation","text":"<pre><code>helm version\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#basic-concepts","title":"Basic Concepts","text":"<ul> <li>Chart: A Helm package containing all resource definitions necessary to run an application</li> <li>Repository: A collection of charts that can be shared</li> <li>Release: An instance of a chart running in a Kubernetes cluster</li> <li>Values: Configuration parameters that customize the chart</li> </ul>"},{"location":"kubernetes/kubernetes-tools/helm/#repository-management","title":"Repository Management","text":""},{"location":"kubernetes/kubernetes-tools/helm/#add-official-helm-repository","title":"Add Official Helm Repository","text":"<pre><code>helm repo add stable https://charts.helm.sh/stable\nhelm repo add bitnami https://charts.bitnami.com/bitnami\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#update-repository","title":"Update Repository","text":"<pre><code>helm repo update\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#list-repositories","title":"List Repositories","text":"<pre><code>helm repo list\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#chart-operations","title":"Chart Operations","text":""},{"location":"kubernetes/kubernetes-tools/helm/#search-charts","title":"Search Charts","text":"<pre><code>helm search repo nginx\nhelm search repo stable/nginx\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#install-chart","title":"Install Chart","text":"<pre><code># Install with default values\nhelm install my-release stable/nginx\n\n# Install with custom values file\nhelm install my-release stable/nginx -f values.yaml\n\n# Install with specific values\nhelm install my-release stable/nginx --set replicaCount=3\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#list-releases","title":"List Releases","text":"<pre><code>helm list\nhelm list -n &lt;namespace&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#upgrade-release","title":"Upgrade Release","text":"<pre><code>helm upgrade my-release stable/nginx\nhelm upgrade my-release stable/nginx --set replicaCount=5\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#rollback-release","title":"Rollback Release","text":"<pre><code>helm rollback my-release 1\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#uninstall-release","title":"Uninstall Release","text":"<pre><code>helm uninstall my-release\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#creating-custom-charts","title":"Creating Custom Charts","text":""},{"location":"kubernetes/kubernetes-tools/helm/#create-new-chart","title":"Create New Chart","text":"<pre><code>helm create my-chart\n</code></pre> <p>This creates a directory structure:</p> <pre><code>my-chart/\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 values.yaml\n\u251c\u2500\u2500 charts/\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 _helpers.tpl\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2514\u2500\u2500 NOTES.txt\n\u2514\u2500\u2500 .helmignore\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#chartyaml-example","title":"Chart.yaml Example","text":"<pre><code>apiVersion: v2\nname: my-application\ndescription: A Helm chart for my application\ntype: application\nversion: 0.1.0\nappVersion: \"1.0.0\"\nkeywords:\n  - web\n  - application\nhome: https://github.com/my-org/my-application\nsources:\n  - https://github.com/my-org/my-application\nmaintainers:\n  - name: Your Name\n    email: your.email@example.com\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#valuesyaml-example","title":"values.yaml Example","text":"values.yaml <pre><code># Default values for my-application\nreplicaCount: 1\n\nimage:\n  repository: nginx\n  pullPolicy: IfNotPresent\n  tag: \"1.19\"\n\nimagePullSecrets: [ ]\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nserviceAccount:\n  create: true\n  annotations: { }\n  name: \"\"\n\npodAnnotations: { }\n\npodSecurityContext: { }\n\nsecurityContext: { }\n\nservice:\n  type: ClusterIP\n  port: 80\n\ningress:\n  enabled: false\n  className: \"\"\n  annotations: { }\n  hosts:\n    - host: chart-example.local\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n  tls: [ ]\n\nresources:\n  limits:\n    cpu: 100m\n    memory: 128Mi\n  requests:\n    cpu: 100m\n    memory: 128Mi\n\nautoscaling:\n  enabled: false\n  minReplicas: 1\n  maxReplicas: 100\n  targetCPUUtilizationPercentage: 80\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#template-example-templatesdeploymentyaml","title":"Template Example (templates/deployment.yaml)","text":"deployment.yaml <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: { { include \"my-application.fullname\" . } }\n  labels:\n    { { - include \"my-application.labels\" . | nindent 4 } }\nspec:\n  { { - if not .Values.autoscaling.enabled } }\n  replicas: { { .Values.replicaCount } }\n  { { - end } }\n  selector:\n    matchLabels:\n      { { - include \"my-application.selectorLabels\" . | nindent 6 } }\n  template:\n    metadata:\n      { { - with .Values.podAnnotations } }\n      annotations:\n        { { - toYaml . | nindent 8 } }\n      { { - end } }\n      labels:\n        { { - include \"my-application.selectorLabels\" . | nindent 8 } }\n    spec:\n      { { - with .Values.imagePullSecrets } }\n      imagePullSecrets:\n        { { - toYaml . | nindent 8 } }\n      { { - end } }\n      serviceAccountName: { { include \"my-application.serviceAccountName\" . } }\n      securityContext:\n        { { - toYaml .Values.podSecurityContext | nindent 8 } }\n      containers:\n        - name: { { .Chart.Name } }\n          securityContext:\n            { { - toYaml .Values.securityContext | nindent 12 } }\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\"\n          imagePullPolicy: { { .Values.image.pullPolicy } }\n          ports:\n            - name: http\n              containerPort: 80\n              protocol: TCP\n          livenessProbe:\n            httpGet:\n              path: /\n              port: http\n          readinessProbe:\n            httpGet:\n              path: /\n              port: http\n          resources:\n            { { - toYaml .Values.resources | nindent 12 } }\n      { { - with .Values.nodeSelector } }\n      nodeSelector:\n        { { - toYaml . | nindent 8 } }\n      { { - end } }\n      { { - with .Values.affinity } }\n      affinity:\n        { { - toYaml . | nindent 8 } }\n      { { - end } }\n      { { - with .Values.tolerations } }\n      tolerations:\n        { { - toYaml . | nindent 8 } }\n      { { - end } }\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#advanced-usage","title":"Advanced Usage","text":""},{"location":"kubernetes/kubernetes-tools/helm/#using-values-files","title":"Using Values Files","text":"<p>Create a custom values file (<code>custom-values.yaml</code>):</p> custom-values.yaml <pre><code>replicaCount: 3\nimage:\n  repository: my-registry/my-app\n  tag: \"2.0.0\"\nservice:\n  type: LoadBalancer\n  port: 8080\nresources:\n  limits:\n    cpu: 500m\n    memory: 512Mi\n  requests:\n    cpu: 250m\n    memory: 256Mi\n</code></pre> <p>Install with custom values:</p> <pre><code>helm install my-release ./my-chart -f custom-values.yaml\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#override-values","title":"Override Values","text":"<pre><code>helm install my-release ./my-chart \\\n  --set replicaCount=5 \\\n  --set image.tag=latest \\\n  --set service.type=NodePort\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#template-rendering","title":"Template Rendering","text":"<p>Preview the rendered templates without installing:</p> <pre><code>helm template my-release ./my-chart\nhelm template my-release ./my-chart -f values.yaml\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#package-chart","title":"Package Chart","text":"<pre><code>helm package ./my-chart\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#install-from-package","title":"Install from Package","text":"<pre><code>helm install my-release my-application-0.1.0.tgz\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#best-practices","title":"Best Practices","text":""},{"location":"kubernetes/kubernetes-tools/helm/#chart-structure","title":"Chart Structure","text":"<ul> <li>Use meaningful names for charts and releases</li> <li>Include comprehensive documentation in README.md</li> <li>Use semantic versioning for chart versions</li> <li>Provide sensible defaults in values.yaml</li> <li>Use templates for reusable components</li> </ul>"},{"location":"kubernetes/kubernetes-tools/helm/#security","title":"Security","text":"<ul> <li>Avoid hardcoding secrets in templates</li> <li>Use Kubernetes secrets for sensitive data</li> <li>Implement proper RBAC configurations</li> <li>Use security contexts in pod specifications</li> </ul>"},{"location":"kubernetes/kubernetes-tools/helm/#testing","title":"Testing","text":"<pre><code># Lint chart\nhelm lint ./my-chart\n\n# Test chart installation\nhelm test my-release\n\n# Validate chart dependencies\nhelm dependency build ./my-chart\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#dependencies","title":"Dependencies","text":"<p>Add dependencies to <code>Chart.yaml</code>:</p> <pre><code>dependencies:\n  - name: postgresql\n    version: 12.1.2\n    repository: https://charts.bitnami.com/bitnami\n    condition: postgresql.enabled\n</code></pre> <p>Install dependencies:</p> <pre><code>helm dependency update ./my-chart\nhelm dependency build ./my-chart\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#common-commands-reference","title":"Common Commands Reference","text":"<pre><code># Chart management\nhelm create &lt;chart-name&gt;\nhelm package &lt;chart-directory&gt;\nhelm lint &lt;chart-directory&gt;\n\n# Repository management\nhelm repo add &lt;name&gt; &lt;url&gt;\nhelm repo update\nhelm repo list\nhelm repo remove &lt;name&gt;\n\n# Release management\nhelm install &lt;release-name&gt; &lt;chart&gt;\nhelm upgrade &lt;release-name&gt; &lt;chart&gt;\nhelm rollback &lt;release-name&gt; &lt;revision&gt;\nhelm uninstall &lt;release-name&gt;\nhelm list\nhelm status &lt;release-name&gt;\n\n# Values and configuration\nhelm get values &lt;release-name&gt;\nhelm get manifest &lt;release-name&gt;\nhelm get hooks &lt;release-name&gt;\n\n# Template operations\nhelm template &lt;release-name&gt; &lt;chart&gt;\nhelm show values &lt;chart&gt;\nhelm show chart &lt;chart&gt;\nhelm show readme &lt;chart&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/helm/#references","title":"References","text":"<ul> <li>Helm Official Documentation</li> <li>Helm Charts Repository</li> <li>Helm Hub</li> <li>Best Practices Guide</li> </ul>"},{"location":"kubernetes/kubernetes-tools/kubeadm/","title":"Kubeadm","text":"<p>You can find the kubernetes documentation here.</p>"},{"location":"kubernetes/kubernetes-tools/kubeadm/#1-create-virtual-machines","title":"1. Create virtual machines","text":"<pre><code>$ multipass launch --name master -c 2 -m 2G -d 10G\n$ multipass launch --name node1 -c 2 -m 2G -d 10G\n</code></pre> <ul> <li>Connect to the master node and run <code>sudo hostnamectl set-hostname master</code>.   Connect to node1 and run <code>sudo hostnamectl set-hostname node1</code>.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/kubeadm/#2-activate-kernel-modules-and-disable-swap","title":"2. Activate kernel modules and disable swap","text":"<pre><code>$ sudo modprobe overlay\n$ sudo modprobe br_netfilter\n</code></pre> <pre><code>$ cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf\noverlay\nbr_netfilter\nEOF\n</code></pre> <pre><code>$ cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-iptables  = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.ipv4.ip_forward                 = 1\nEOF\n</code></pre> <pre><code>$ sudo sysctl --system\n</code></pre> <pre><code>$ sudo swapoff -a\n$ free -m\n$ sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubeadm/#3-install-containerd","title":"3. Install containerd","text":"<pre><code>$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker.gpg\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n$ sudo apt update\n$ sudo apt install containerd.io\n$ sudo systemctl daemon-reload\n$ sudo systemctl enable --now containerd\n$ sudo systemctl start containerd\n$ sudo mkdir -p /etc/containerd\n$ sudo su -\n$ containerd config default | tee /etc/containerd/config.toml\n$ exit\n$ sudo sed -i 's/            SystemdCgroup = false/            SystemdCgroup = true/' /etc/containerd/config.toml\n$ sudo systemctl restart containerd\n\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubeadm/#4-install-kubeadm","title":"4. Install kubeadm","text":"<pre><code>$ sudo ufw allow 6443/tcp\n$ sudo ufw allow 2379:2380/tcp\n$ sudo ufw allow 10250/tcp\n$ sudo ufw allow 10259/tcp\n$ sudo ufw allow 10257/tcp\n$ sudo apt-get update\n$ sudo apt-get install -y apt-transport-https ca-certificates curl\n$ sudo mkdir -p -m 755 /etc/apt/keyrings\n### If you want to install a Kubernetes version other than 1.31, update the v1.31 parts in the two commands below.\n$ curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n$ echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list\n$ sudo apt-get update\n$ sudo apt-get install -y kubelet kubeadm kubectl\n$ sudo apt-mark hold kubelet kubeadm kubectl\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubeadm/#5-kubernetes-cluster-setup","title":"5. Kubernetes cluster setup","text":"<pre><code>$ sudo kubeadm config images pull\n\n$ sudo kubeadm init --pod-network-cidr=192.168.0.0/16 --apiserver-advertise-address=&lt;ip&gt; --control-plane-endpoint=&lt;ip&gt;\n</code></pre> <pre><code>$ mkdir -p $HOME/.kube\n$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n$ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre> <pre><code>$ kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/tigera-operator.yaml\n$ kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/custom-resources.yaml\n</code></pre> <pre><code>kubectl taint nodes --all node-role.kubernetes.io/control-plane-\nkubectl taint nodes --all node-role.kubernetes.io/master-\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubeadm/#references","title":"References","text":"<ul> <li>Kubernetes Official Kubeadm Installation</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-tools/kubectl/","title":"Kubectl","text":""},{"location":"kubernetes/kubernetes-tools/kubectl/#overview","title":"Overview","text":"<ul> <li>kubectl is the command-line interface for interacting with a Kubernetes cluster.</li> <li>kubectl reads connection details from a kubeconfig file. By default, this is <code>~/.kube/config</code>. You can override the   path with the <code>KUBECONFIG</code> environment variable.</li> <li>A kubeconfig contains definitions for clusters, users, and contexts. A context combines a cluster, a user, and   optionally a namespace, and represents \u201cconnect to this cluster as this user (and namespace).\u201d</li> <li>Tools like Minikube or managed Kubernetes providers typically generate kubeconfig entries automatically.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/kubectl/#installation","title":"Installation","text":"<ul> <li>On Linux/macOS with Homebrew:</li> </ul> <pre><code>brew install kubectl\n</code></pre> <ul> <li>Verify the client (and server, if reachable):</li> </ul> <pre><code>kubectl version\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#kubeconfig-and-contexts","title":"Kubeconfig and Contexts","text":"<ul> <li>View the current kubeconfig:</li> </ul> <pre><code>kubectl config view\n</code></pre> <ul> <li>Show contexts defined in the current kubeconfig:</li> </ul> <pre><code>kubectl config get-contexts\n</code></pre> <ul> <li>Show the current context:</li> </ul> <pre><code>kubectl config current-context\n</code></pre> <ul> <li>Switch the current context:</li> </ul> <pre><code>kubectl config use-context &lt;context-name&gt;\n</code></pre> <p>Notes:</p> <ul> <li>In <code>kubectl config get-contexts</code>, a star (*) marks the currently active context.</li> <li>You can open and inspect your kubeconfig directly, for example with an editor: <code>subl ~/.kube/config</code>.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/kubectl/#command-structure-and-namespaces","title":"Command Structure and Namespaces","text":"<p>kubectl commands generally follow:</p> <pre><code>kubectl &lt;verb&gt; &lt;resource&gt; [name] [flags]\n# &lt;verb&gt; examples: get, describe, logs, exec, apply, delete, scale, rollout\n# &lt;resource&gt; examples: pods, services, deployments, nodes, namespaces\n</code></pre> <ul> <li>Unless overridden with <code>-n/--namespace</code>, commands operate in the namespace from the current context. If none is   specified, the <code>default</code> namespace is used.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/kubectl/#cluster-and-resource-discovery","title":"Cluster and Resource Discovery","text":"<ul> <li>Cluster information:</li> </ul> <pre><code>kubectl cluster-info\n</code></pre> <ul> <li>To filter out the debug message:</li> </ul> <pre><code> kubectl cluster-info | grep -v \"To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\"\n</code></pre> <ul> <li>List common resources:</li> </ul> <pre><code>kubectl get &lt;object-type&gt;\n\nkubectl get pods\nkubectl get services\nkubectl get deployments\nkubectl get nodes\nkubectl get namespaces\n</code></pre> <ul> <li>List a single object in the current namespace:</li> </ul> <pre><code>kubectl get &lt;object-type&gt; &lt;object-name&gt;\n\nkubectl get pods testpod\n</code></pre> <ul> <li>List resources in another namespace:</li> </ul> <pre><code>kubectl get &lt;object-type&gt; -n &lt;namespace-name&gt;\n\nkubectl get pods -n testnamespace\n</code></pre> <ul> <li>List across all namespaces:</li> </ul> <pre><code>kubectl get &lt;object-type&gt; --all-namespaces\nkubectl get all -A               # status of many core objects cluster-wide\n\nkubectl get pods --all-namespaces\nkubectl get pods -A\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#output-formatting","title":"Output Formatting","text":"<p>kubectl defaults to a concise, plain-text output. Use <code>-o</code> to change the output format:</p> <ul> <li><code>-o yaml</code> \u2014 output as YAML</li> <li><code>-o json</code> \u2014 output as JSON</li> <li><code>-o wide</code> \u2014 plain text with additional columns</li> <li><code>-o name</code> \u2014 print only resource names</li> <li><code>-o jsonpath=&lt;template&gt;</code> \u2014 select fields using a JSONPath template</li> <li><code>-o custom-columns=&lt;spec&gt;</code> \u2014 comma-separated column definitions for tabular output</li> </ul> <p>Examples:</p> <pre><code>kubectl get &lt;object-type&gt; -o &lt;wide|yaml|json&gt;\n\nkubectl get pods -o wide\nkubectl get pods -A -o json | jq -r '.items[].spec.containers[].name'\n</code></pre> <p>Note: If using <code>-o json</code> with <code>jq</code>, you may need to install <code>jq</code> first:</p> <pre><code># jq -&gt; install json query plugin.\n# brew install jq\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#explaining-api-resources","title":"Explaining API Resources","text":"<p>Use <code>explain</code> to view schema and documentation for resources and fields:</p> <pre><code>kubectl explain &lt;object-type&gt;\n\nkubectl explain pod\nkubectl explain deployment.spec.template.spec.containers\n</code></pre> <p>In the output, we can understand which namespace it belongs to with Version.</p>"},{"location":"kubernetes/kubernetes-tools/kubectl/#help-and-documentation","title":"Help and Documentation","text":"<p>Use <code>-h/--help</code> to get help on any command:</p> <pre><code>kubectl &lt;verb&gt; --help # or -h\n\nkubectl --help\nkubectl apply --help\n</code></pre> kubectl --help <pre><code>kubectl controls the Kubernetes cluster manager.\n\n Find more information at: https://kubernetes.io/docs/reference/kubectl/\n\nBasic Commands (Beginner):\n  create          Create a resource from a file or from stdin\n  expose          Take a replication controller, service, deployment or pod and\nexpose it as a new Kubernetes service\n  run             Run a particular image on the cluster\n  set             Set specific features on objects\n\nBasic Commands (Intermediate):\n  explain         Get documentation for a resource\n  get             Display one or many resources\n  edit            Edit a resource on the server\n  delete          Delete resources by file names, stdin, resources and names, or\nby resources and label selector\n\nDeploy Commands:\n  rollout         Manage the rollout of a resource\n  scale           Set a new size for a deployment, replica set, or replication\ncontroller\n  autoscale       Auto-scale a deployment, replica set, stateful set, or\nreplication controller\n\nCluster Management Commands:\n  certificate     Modify certificate resources\n  cluster-info    Display cluster information\n  top             Display resource (CPU/memory) usage\n  cordon          Mark node as unschedulable\n  uncordon        Mark node as schedulable\n  drain           Drain node in preparation for maintenance\n  taint           Update the taints on one or more nodes\n\nTroubleshooting and Debugging Commands:\n  describe        Show details of a specific resource or group of resources\n  logs            Print the logs for a container in a pod\n  attach          Attach to a running container\n  exec            Execute a command in a container\n  port-forward    Forward one or more local ports to a pod\n  proxy           Run a proxy to the Kubernetes API server\n  cp              Copy files and directories to and from containers\n  auth            Inspect authorization\n  debug           Create debugging sessions for troubleshooting workloads and\nnodes\n  events          List events\n\nAdvanced Commands:\n  diff            Diff the live version against a would-be applied version\n  apply           Apply a configuration to a resource by file name or stdin\n  patch           Update fields of a resource\n  replace         Replace a resource by file name or stdin\n  wait            Experimental: Wait for a specific condition on one or many\nresources\n  kustomize       Build a kustomization target from a directory or URL\n\nSettings Commands:\n  label           Update the labels on a resource\n  annotate        Update the annotations on a resource\n  completion      Output shell completion code for the specified shell (bash,\nzsh, fish, or powershell)\n\nSubcommands provided by plugins:\n\nOther Commands:\n  api-resources   Print the supported API resources on the server\n  api-versions    Print the supported API versions on the server, in the form of\n\"group/version\"\n  config          Modify kubeconfig files\n  plugin          Provides utilities for interacting with plugins\n  version         Print the client and server version information\n\nUsage:\n  kubectl [flags] [options]\n\nUse \"kubectl &lt;command&gt; --help\" for more information about a given command.\nUse \"kubectl options\" for a list of global command-line options (applies to all\ncommands).\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#watching-changes","title":"Watching Changes","text":"<p>Stream updates to resources with <code>-w/--watch</code>:</p> <pre><code>kubectl get pods -w # or --watch\nwatch kubectl get pods\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#describe-logs-and-exec","title":"Describe, Logs, and Exec","text":"<pre><code>kubectl describe pod &lt;pod-name&gt;\nkubectl describe node &lt;node-name&gt;\nkubectl describe deployment &lt;deployment-name&gt;\n\nkubectl logs &lt;pod-name&gt;\nkubectl exec -it &lt;pod-name&gt; -- /bin/bash\nkubectl exec -it &lt;pod-name&gt; -c &lt;container-name&gt; -- /bin/bash\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#apply-delete-scale-and-rollouts","title":"Apply, Delete, Scale, and Rollouts","text":"<pre><code>kubectl apply -f &lt;file.yaml&gt;\nkubectl delete -f &lt;file.yaml&gt;\n\nkubectl scale deployment &lt;name&gt; --replicas=&lt;num&gt;\nkubectl rollout status deployment/&lt;name&gt;\nkubectl rollout undo deployment/&lt;name&gt;\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#port-forward-local-pod","title":"Port-Forward (Local -&gt; Pod)","text":"<p>\u2013&gt; We can open port-forward to directly reach objects within the k8s cluster we want from our own local servers. This is one of the best methods to test this object.</p> <pre><code>kubectl port-forward &lt;objectType&gt;/&lt;podName&gt; &lt;localMachinePort&gt;:&lt;podPort&gt;\n\nkubectl port-forward pod/testpod 8080:80\n# Send all requests coming to port 8080 on my device to port 80 of this pod.\n\ncurl 127.0.0.1:8080\n# You can write for testing.\n</code></pre> <p>Then open <code>localhost:8080</code> in the browser. Port-forwarding ends when CMD + C is done.</p>"},{"location":"kubernetes/kubernetes-tools/kubectl/#metrics","title":"Metrics","text":"<p>Requires Metrics Server installed in the cluster:</p> <pre><code>kubectl top pod\nkubectl top node\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#quick-kubeconfig-context-switch-script-optional","title":"Quick kubeconfig Context Switch Script (optional)","text":"<p>If you keep multiple kubeconfig files like <code>~/.kube/config-minikube</code>, you can use a helper script to copy one into place as the active <code>~/.kube/config</code>:</p> change-kube-config.sh <pre><code>#! /bin/bash\n\nCLUSTER=$1\n\nif [ -z \"$1\" ]\n  then\n    echo -e \"\\n##### No argument supplied. Please select one of these configs. #####\"\n    ls  ~/.kube |grep config- | cut -d \"-\" -f 2\n    echo -e \"######################################################################\\n\"\n    #array=($(ls -d * |grep config_))\n    read -p 'Please set config file: ' config\n    cp -r ~/.kube/config_$config ~/.kube/config\n    echo -e '\\n'\n    kubectl cluster-info |grep -v \"To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\"\n    kubectl config get-contexts\n    kubectl get node -o wide |head -n 4\nelse\n  cp -r ~/.kube/config-$CLUSTER ~/.kube/config\n  if [ $? -ne 0 ];\n  then\n  exit 1\n  fi\n  echo -e '\\n'\n#  kubectl cluster-info | grep -v \"To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\"\n  kubectl config get-contexts\n  echo -e '\\n'\n  kubectl get node -o wide |head -n 4\n  echo -e '\\n'\nfi\n</code></pre> <p>Usage:</p> <pre><code>./change-kube-config.sh &lt;config-name&gt;\n# e.g.\n./change-kube-config.sh minikube\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#makefile-commands-for-aws-eks-setup-optional","title":"Makefile Commands for AWS EKS Setup (optional)","text":"<p>Make Command:</p> <pre><code>aws-config-set: ## AWS configs for to up Preview env on your local machine\n    @source \".make/scripts/aws-config-set.sh\"\n</code></pre> aws-config-set.sh <pre><code>#!/bin/bash\n\n# ======================================================================================================================\n# This script performs the following tasks:\n# 1. Asks to the user to select aws profile.\n# 2. Removes ~/.aws/sso/cache, ~/.aws/cli/cache and ~/.kube/cache folders.\n# 3. Configures aws sso start url, sso region, sso account id, sso role name, region and output.\n# 4. Runs aws eks command.\n# ======================================================================================================================\n\nAWS_PROFILE_1=\"default\"\nAWS_PROFILE_2=\"test-dev\"\n\necho \"Which AWS profile would you like to log in to?\"\necho \"1) $AWS_PROFILE_1\"\necho \"2) $AWS_PROFILE_2\"\nread -p \"Make your choice (1 or 2): \" profile_choice\n\nif [[ $profile_choice -eq 1 ]]; then\n  SSO_ACCOUNT_ID=\"123456789123\"\n  ROLE_ARN=\"arn:aws:iam::123456789123:role/EKSDevV1TesterRole\"\nelif [[ $profile_choice -eq 2 ]]; then\n  SSO_ACCOUNT_ID=\"987654321123\"\n  ROLE_ARN=\"arn:aws:iam::987654321123:role/EKSDevV1TesterRole\"\nelse\n  echo \"Invalid choice. Exiting.\"\n  exit 1\nfi\n\n# PARAMETERS\nAWS_SSO_SESSION_NAME=\"\"\nSSO_START_URL=\"https://d-123407a8b9.awsapps.com/start#/\"\nSSO_REGION=\"eu-west-1\"\nSSO_ACCOUNT_ID=\"$SSO_ACCOUNT_ID\"\nSSO_ROLE_NAME=\"aws_developer\"\nCLI_PROFILE_NAME=\"default\"\nCLI_DEFAULT_REGION=\"eu-west-1\"\nCLI_DEFAULT_OUTPUT_FORMAT=\"json\"\nROLE_ARN=\"$ROLE_ARN\"\n\n# Delete SSO cache\nrm -rf ~/.aws/sso/cache\n\n# Delete AWS CLI cache\nrm -rf ~/.aws/cli/cache\n\n# Delete kube cache\nrm -rf ~/.kube/cache\n\n# Run AWS configure sso command\n{\n  echo \"$AWS_SSO_SESSION_NAME\"\n  echo \"$SSO_START_URL\"\n  echo \"$SSO_REGION\"\n  echo \"$SSO_ACCOUNT_ID\"\n  echo \"$SSO_ROLE_NAME\"\n  echo \"$CLI_DEFAULT_REGION\"\n  echo \"$CLI_DEFAULT_OUTPUT_FORMAT\"\n  echo \"$CLI_PROFILE_NAME\"\n} | aws configure sso --profile \"$CLI_PROFILE_NAME\"\n\n# Set the default CLI profile\naws configure set default.sso_start_url \"$SSO_START_URL\"\naws configure set default.sso_region \"$SSO_REGION\"\naws configure set default.sso_account_id \"$SSO_ACCOUNT_ID\"\naws configure set default.sso_role_name \"$SSO_ROLE_NAME\"\n\n# Set default region\naws configure set default.region \"$CLI_DEFAULT_REGION\"\n\n# Set default output format\naws configure set default.output \"$CLI_DEFAULT_OUTPUT_FORMAT\"\n\n# Run AWS EKS command to update kubeconfig\nif [[ $profile_choice -eq 2 ]]; then\n  aws eks --region \"$CLI_DEFAULT_REGION\" update-kubeconfig --name dev-cluster --role-arn \"$ROLE_ARN\"\nfi\n</code></pre> <p>Usage:</p> <pre><code>make aws-config-set\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/kubectl/#references","title":"References","text":"<ul> <li>Kubernetes Official Kubectl Cheatsheet</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/","title":"Minikube","text":"<p>Minikube is a tool that makes it easy to run Kubernetes locally. Below are some commonly used Minikube commands with brief explanations. It can come with many addons. We can stop and run the cluster with a single command.</p>"},{"location":"kubernetes/kubernetes-tools/minikube/#installing-minikube","title":"Installing Minikube","text":"<pre><code>brew install minikube\n</code></pre> <ul> <li> <p>Installs Minikube using Homebrew.</p> </li> <li> <p>Docker must be installed on the system to use minikube. Because Minikube will use Docker in the background. We can   also use many tools like VirtualBox in the background.</p> </li> <li>For testing <code>minikube status</code>.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/#starting-minikube","title":"Starting Minikube","text":""},{"location":"kubernetes/kubernetes-tools/minikube/#1-start-with-a-docker-driver","title":"1. Start with a Docker driver","text":"<p>By default, it uses Docker in the background.</p> <pre><code>minikube start --driver=docker\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/minikube/#2-start-with-a-virtualbox-driver","title":"2. Start with a VirtualBox driver","text":"<pre><code>minikube start --driver=virtualbox\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/minikube/#3-start-with-multiple-nodes","title":"3. Start with multiple nodes","text":"<pre><code>minikube start --nodes=5 --driver=docker\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/minikube/#4-start-with-a-named-profile","title":"4. Start with a named profile","text":"<pre><code>minikube start -p profileName\n</code></pre> <p>The default profile name is <code>minikube</code>.</p>"},{"location":"kubernetes/kubernetes-tools/minikube/#checking-minikube-status","title":"Checking Minikube Status","text":"<pre><code>minikube status\nkubectl get nodes\n</code></pre> <ul> <li>Shows the current status of the Minikube cluster.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/#stopping-minikube","title":"Stopping Minikube","text":"<pre><code>minikube stop\n</code></pre> <ul> <li>Stops the running Minikube Kubernetes cluster without deleting it.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/#deleting-minikube","title":"Deleting Minikube","text":"<pre><code>minikube delete\n</code></pre> <ul> <li>Deletes the Kubernetes cluster and all its contents (all pods).</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/#creating-a-service-url-in-minikube","title":"Creating a service url in Minikube","text":"<pre><code>minikube service --url &lt;service-name&gt;\n</code></pre> <ul> <li>Starts a service in Minikube and provides the URL to access it. (e.g. http://127.0.0.1:33901)</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/#add-new-node","title":"Add new node","text":"<pre><code>minikube node add\n</code></pre> <ul> <li>Adds a new node to the Minikube cluster.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/#using-addons-in-minikube","title":"Using Addons in Minikube","text":"<p>With Minikube addons, you can quickly enable powerful Kubernetes features such as Ingress, Dashboard, and many others for local testing and learning.</p>"},{"location":"kubernetes/kubernetes-tools/minikube/#1-listing-addons","title":"1. Listing Addons","text":"<p>To see all available addons in Minikube:</p> <pre><code>minikube addons list\n</code></pre> <p>This will show a list of supported addons, their status (enabled/disabled), and descriptions.</p>"},{"location":"kubernetes/kubernetes-tools/minikube/#2-enabling-ingress-addon","title":"2. Enabling Ingress Addon","text":"<p>The Ingress addon provides an NGINX Ingress Controller, useful for routing traffic into your cluster.</p> <p>Enable it with:</p> <pre><code>minikube addons enable ingress\n</code></pre> <p>After enabling, you can use <code>Ingress</code> resources in your cluster to expose services.</p>"},{"location":"kubernetes/kubernetes-tools/minikube/#3-enabling-kubernetes-dashboard-addon","title":"3. Enabling Kubernetes Dashboard Addon","text":"<p>The Dashboard addon provides a web-based UI to manage your Kubernetes cluster.</p> <p>Enable it with:</p> <pre><code>minikube addons enable dashboard\n</code></pre> <p>Start the dashboard with:</p> <pre><code>minikube dashboard\n</code></pre> <p>This command will automatically open the Dashboard in your default web browser.</p>"},{"location":"kubernetes/kubernetes-tools/minikube/#deleting-all-docker-objects-in-minikube","title":"Deleting All Docker Objects in Minikube","text":"<p>Minikube runs its own Docker daemon inside a virtual machine (VM). Because of this, regular Docker commands won\u2019t affect it unless you connect to Minikube\u2019s Docker environment first.</p>"},{"location":"kubernetes/kubernetes-tools/minikube/#1-delete-all-docker-objects-inside-minikube","title":"1. Delete All Docker Objects Inside Minikube","text":"<p>Step 1: Connect your shell to Minikube's Docker environment</p> <pre><code>eval $(minikube docker-env)\n</code></pre> <p>Step 2: Remove all unused containers, images, networks, and volumes</p> <pre><code>docker system prune -a --volumes\n</code></pre> <ul> <li>eval $(minikube docker-env) \u2192 Points your shell to Minikube\u2019s Docker daemon.</li> <li>docker system prune -a --volumes \u2192 Removes all unused containers, images, networks, and volumes.   \u26a0 Warning: This action cannot be undone.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/minikube/#2-completely-reset-the-minikube-environment","title":"2. Completely Reset the Minikube Environment","text":"<p>If you want to remove not just Docker objects, but the entire Minikube Kubernetes environment:</p> <pre><code>minikube delete --all\n</code></pre> <p>Afterward, you can start fresh with:</p> <pre><code>minikube start\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/minikube/#3-delete-all-kubernetes-resources-only","title":"3. Delete All Kubernetes Resources Only","text":"<p>If you only want to remove Kubernetes objects (pods, deployments, services, etc.) without deleting Docker images:</p> <pre><code>kubectl delete all --all -A\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/minikube/#summary","title":"Summary","text":"Command Description <code>brew install minikube</code> Install Minikube <code>minikube start --driver=docker</code> Start Minikube with Docker driver <code>minikube start --nodes=5 --driver=docker</code> Start Minikube with multiple nodes <code>minikube status</code> Check the status of Minikube <code>minikube stop</code> Stop the Minikube cluster <code>minikube delete</code> Delete the Minikube cluster <code>minikube service --url &lt;service-name&gt;</code> Create a service url <code>minikube node add</code> Add new node <code>minikube delete --all</code> Reset the Minikube cluster <code>minikube addons list</code> List addons <code>minikube addons enable dashboard</code> Enable Kubernetes dashboard <code>minikube dashboard</code> Start Kubernetes dashboard"},{"location":"kubernetes/kubernetes-tools/minikube/#references","title":"References","text":"<ul> <li>Minikube Official Website</li> </ul>"},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/","title":"Kubernetes Monitoring - Prometheus, EFK Stack","text":""},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/#prometheus-stack","title":"Prometheus Stack","text":"<p>There are 4 different places we need to monitor in Kubernetes:</p> <ol> <li>How is the K8s Cluster working? What objects are there?</li> <li>What is the current status of objects? EX: Are the replicas we wrote in Deployment really created?</li> <li>We need to monitor Nodes. We run containers on worker nodes. How are the CPU and memory usage, traffic of these    nodes?</li> <li>Logs are generated inside containers. How will we read these logs?</li> </ol>"},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/#without-using-any-monitoring-tool","title":"Without using any monitoring tool;","text":"<p>\u2013&gt; I can learn the status of existing Pods with the <code>kubectl get pods</code> command.</p> <p>\u2013&gt; I can learn the status of all objects in the system with <code>kubectl get all -A</code>.</p> <p>\u2013&gt; For a specific object (EX: a pod), I can learn with <code>kubectl describe podName</code>.</p> <p>\u2013&gt; I can learn what events have occurred in a cluster from the beginning with <code>kubectl get events -A</code>. (<code>-A</code> brings us all namespaces.)</p> <p>\u2013&gt; I can see CPU and Memory usage with <code>kubectl top node</code>. (If I say Pod, we can see the pod's.)</p> <p>\u2013&gt; I can access logs with <code>kubectl logs &lt;podName&gt;</code>.</p> <p>Although we can get what we want manually with such commands, it's easier and more logical to manage this from a central place. When an error occurs, the Alert mechanism should come into play and send me an email. We can manage all of these with Prometheus. (The first 3)</p>"},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/#what-is-prometheus","title":"What is Prometheus?","text":"<p>\u2013&gt; It's a metrics server. It's used almost all over the world. CNCF project (like k8s).</p> <p>\u2013&gt; Pull based operation: You do the installation, Prometheus collects the necessary metrics itself.</p> <p>\u2013&gt; It doesn't only work with k8s, for example you can also use it in Frontend.</p> <ul> <li>Kubernetes Metrics pulls the current status of objects by talking to the k8s API and sends them to Prometheus.</li> <li>Node Exporter pulls the status of Nodes and sends them to Prometheus.</li> <li>Prometheus can talk directly with the Kubernetes API. It can learn the status of the cluster.</li> <li>We can run Query in Prometheus. But I need to visualize this information, I need to create dashboards. We can provide   this with Grafana.</li> <li>Installation and integration of Prometheus and other tools is normally very tedious and complex. For this reason,   prometheus-community created a stack under the name helm-charts that will facilitate this situation. Let's move to   stack installation..</li> </ul>"},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/#installation","title":"Installation","text":"<ul> <li>Let's create a namespace named monitoring:</li> </ul> <pre><code>kubectl create namespace monitoring\n</code></pre> <ul> <li>Let's install kubectl-prometheus-stack:</li> </ul> <pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\nhelm install kubeprostack --namespace monitoring prometheus-community/kube-prometheus-stack\n</code></pre> <ul> <li>Let's make sure it's installed:</li> </ul> <pre><code>kubectl get pods -n monitoring\n\n# Output:\nNAME                                                     READY   STATUS    RESTARTS   AGE\nalertmanager-kubeprostack-kube-promethe-alertmanager-0   2/2     Running   0          15m\nkubeprostack-grafana-5c5d98864b-dn2jz                    3/3     Running   0          15m\nkubeprostack-kube-promethe-operator-5fcb5784fc-57pvs     1/1     Running   0          15m\nkubeprostack-kube-state-metrics-5765b49669-6qqgl         1/1     Running   0          15m\nkubeprostack-prometheus-node-exporter-82mcn              1/1     Running   0          15m\nprometheus-kubeprostack-kube-promethe-prometheus-0       2/2     Running   0          15m\n</code></pre> <ul> <li>Many pods like grafana are exposed in the installation. (Opened to the outside world) However, prometheus is not. For   this, we need to do port-forwarding. Thus, we will be able to connect to prometheus from the web interface.</li> </ul> <pre><code>kubectl --namespace monitoring port-forward svc/kubeprostack-kube-promethe-prometheus 9090\n\n# then we can go to http://localhost:9090.\n</code></pre> <ul> <li>Let's go to the <code>http://localhost:9090</code> Prometheus UI screen and run a few queries:</li> </ul> <pre><code>kube_pod_created # Shows all pods created so far.\n\ncount by (namespace) (kube_pod_created) # Distribution by namespace \n\nsum by (namespace) (kube_pod_info) # Currently running pods\n\nsum by (namespace) (kube_pod_status_ready{condition=\"false\"}) # Pods not in Ready state \"distribution by namespace\"\n</code></pre> <ul> <li>Let's check Grafana:</li> </ul> <pre><code>kubectl --namespace monitoring port-forward svc/kubeprostack-grafana 8080:80\n\n# user: admin\n# pw: prom-operator\n\n# To get Grafana password:\nkubectl get secret kubeprostack-grafana -n monitoring -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n</code></pre> <ul> <li>Let's check Alert Manager:</li> </ul> <pre><code>kubectl --namespace monitoring port-forward svc/kubeprostack-kube-promethe-alertmanager 9093\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/#efk-stack-elasticsearch-fluentd-kibana","title":"EFK Stack (ElasticSearch Fluentd Kibana)","text":"<p>It's the stack used for Logging.</p> <ul> <li>ElasticSearch is where logs are collected and stored.</li> <li>Kibana is used to visualize data taken from ElasticSearch. (Like Grafana in a way.)</li> <li>LogStash (ElasticSearch product) and Fluentd (CNCF project) are tools responsible for collecting logs.</li> <li>FluentD is more performant than LogStash.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/#installation-on-minikube","title":"Installation (on minikube)","text":"<p>The installation here is based on minikube, and yaml files have been prepared to change some settings. Although installation on Cloud is easily done with helm, when we use helm in minikube installation, we encounter some errors.</p> <ul> <li>Let's start minikube and activate the relevant storage addons:</li> </ul> <pre><code>minikube start --cpus 4 --memory 6144\n\nminikube addons enable default-storageclass\nminikube addons enable storage-provisioner\n</code></pre> <ul> <li>Let's create a pod that will continuously generate logs: (<code>testpod.yaml</code>)</li> </ul> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: loggenerator\nspec:\n  containers:\n    - name: loggenerator\n      image: busybox\n      args: [ /bin/sh, -c,'i=0; while true; do echo \"Test Log $i\"; i=$((i+1)); sleep 1; done' ]\n</code></pre> <ul> <li>Let's create a new namespace named efk:</li> </ul> <pre><code>$ kubectl create namespace efk\n</code></pre> <ul> <li>Let's create the ElasticSearch cluster:</li> </ul> elastic.yaml <pre><code>kind: Service\napiVersion: v1\nmetadata:\n  name: elasticsearch\n  namespace: efk\n  labels:\n    app: elasticsearch\nspec:\n  selector:\n    app: elasticsearch\n  clusterIP: None\n  ports:\n    - port: 9200\n      name: rest\n    - port: 9300\n      name: inter-node\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: es-cluster\n  namespace: efk\nspec:\n  serviceName: elasticsearch\n  replicas: 3\n  selector:\n    matchLabels:\n      app: elasticsearch\n  template:\n    metadata:\n      labels:\n        app: elasticsearch\n    spec:\n      containers:\n        - name: elasticsearch\n          image: docker.elastic.co/elasticsearch/elasticsearch:7.16.0\n          resources:\n            limits:\n              cpu: 1000m\n            requests:\n              cpu: 100m\n          ports:\n            - containerPort: 9200\n              name: rest\n              protocol: TCP\n            - containerPort: 9300\n              name: inter-node\n              protocol: TCP\n          volumeMounts:\n            - name: data\n              mountPath: /usr/share/elasticsearch/data\n          env:\n            - name: cluster.name\n              value: k8s-logs\n            - name: node.name\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: discovery.seed_hosts\n              value: \"es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch\"\n            - name: cluster.initial_master_nodes\n              value: \"es-cluster-0,es-cluster-1,es-cluster-2\"\n            - name: ES_JAVA_OPTS\n              value: \"-Xms512m -Xmx512m\"\n      initContainers:\n        - name: fix-permissions\n          image: busybox\n          command: [ \"sh\", \"-c\", \"chown -R 1000:1000 /usr/share/elasticsearch/data\" ]\n          securityContext:\n            privileged: true\n          volumeMounts:\n            - name: data\n              mountPath: /usr/share/elasticsearch/data\n        - name: increase-vm-max-map\n          image: busybox\n          command: [ \"sysctl\", \"-w\", \"vm.max_map_count=262144\" ]\n          securityContext:\n            privileged: true\n        - name: increase-fd-ulimit\n          image: busybox\n          command: [ \"sh\", \"-c\", \"ulimit -n 65536\" ]\n          securityContext:\n            privileged: true\n  volumeClaimTemplates:\n    - metadata:\n        name: data\n        labels:\n          app: elasticsearch\n      spec:\n        accessModes: [ \"ReadWriteOnce\" ]\n        storageClassName: standard\n        resources:\n          requests:\n            storage: 1Gi\n</code></pre> <pre><code>kubectl apply -f elastic.yaml\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/monitoring-prometheus-efk-stack/#references","title":"References","text":"<ul> <li>GitHub - Prometheus Community Helm Charts</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"kubernetes/kubernetes-tools/service-mesh/","title":"Kubernetes Service Mesh","text":""},{"location":"kubernetes/kubernetes-tools/service-mesh/#what-is-a-service-mesh","title":"What Is a Service Mesh?","text":"<p>A Service Mesh is an infrastructure layer that handles service-to-service communication for cloud\u2011native applications. It moves cross\u2011cutting networking concerns (discovery, traffic shaping, retries, timeouts, mutual TLS, telemetry) out of application code into the platform, giving you consistent, policy\u2011driven behavior without changing your services.</p> <p>Key ideas:</p> <ul> <li>Data plane: lightweight proxies that sit next to your services (sidecars) and handle traffic.</li> <li>Control plane: central components that program the proxies with policies, routes, and certificates.</li> </ul> <p>Benefits:</p> <ul> <li>Traffic management (routing, canary, blue/green, A/B, retries, timeouts, circuit breaking)</li> <li>Observability (golden signals, distributed tracing, topology graphs)</li> <li>Security (mTLS, fine\u2011grained authorization, policy)</li> </ul>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#how-it-works-in-kubernetes","title":"How It Works in Kubernetes","text":"<p>In Kubernetes, a Service Mesh typically injects a sidecar proxy into each Pod. The application container talks to the local proxy; the proxy talks to other proxies. The control plane configures these proxies using Kubernetes resources ( CRDs) and watches for changes.</p> <p>Flow:</p> <ol> <li>Sidecar injection (automatic via namespace label or manual via CLI) adds a proxy container to each Pod.</li> <li>Control plane watches the cluster, computes routes/policies, and pushes them to sidecars.</li> <li>All inter\u2011service traffic traverses the sidecars, enabling uniform features without code changes.</li> </ol>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#popular-implementations","title":"Popular Implementations","text":"<ul> <li>Istio (Envoy\u2011based, rich features, broad ecosystem)</li> <li>Linkerd (ultra\u2011light Rust/Go proxies, opinionated, great UX)</li> <li>Consul Service Mesh (HashiCorp ecosystem)</li> <li>Kuma/Envoy (by Kong; CNCF project)</li> </ul> <p>This guide will show minimal quickstarts for Istio and Linkerd so you can choose the right fit.</p>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#the-sidecar-proxy-pattern","title":"The Sidecar Proxy Pattern","text":"<p>Each Pod gets an extra container (the sidecar) that intercepts outbound and inbound traffic:</p> <ul> <li>Outbound: app \u2192 sidecar \u2192 remote sidecar \u2192 remote app</li> <li>Inbound: remote app \u2192 remote sidecar \u2192 local sidecar \u2192 app</li> </ul> <p>Because all traffic flows through proxies, the mesh can enforce mTLS, apply rate limits, inject timeouts, and collect telemetry\u2014without modifying your app.</p>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#quickstart-istio","title":"Quickstart: Istio","text":"<p>Prerequisites:</p> <ul> <li>A Kubernetes cluster</li> <li>kubectl installed and configured</li> <li>istioctl or Helm (we use istioctl for simplicity)</li> </ul>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#1-install-istio-demo-profile","title":"1) Install Istio (demo profile)","text":"<pre><code>istioctl install --set profile=demo -y\n\n# Verify control plane\nkubectl -n istio-system get pods\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#2-enable-automatic-sidecar-injection","title":"2) Enable Automatic Sidecar Injection","text":"<p>Label a namespace to auto\u2011inject the sidecar.</p> <pre><code>kubectl create namespace mesh-demo\nkubectl label namespace mesh-demo istio-injection=enabled\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#3-deploy-a-sample-app-two-versions","title":"3) Deploy a Sample App (two versions)","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-v1\n  namespace: mesh-demo\n  labels:\n    app: web            # app identity used by Service selector\n    version: v1         # version label for routing\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: web\n        version: v1\n    spec:\n      containers:\n        - name: web\n          image: hashicorp/http-echo:1.0\n          args: [ \"-text=Hello from v1\" ]\n          ports:\n            - containerPort: 5678       # app port\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-v2\n  namespace: mesh-demo\n  labels:\n    app: web\n    version: v2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: web\n        version: v2\n    spec:\n      containers:\n        - name: web\n          image: hashicorp/http-echo:1.0\n          args: [ \"-text=Hello from v2\" ]\n          ports:\n            - containerPort: 5678\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: web\n  namespace: mesh-demo\nspec:\n  selector:\n    app: web\n  ports:\n    - name: http\n      port: 80              # cluster-facing port\n      targetPort: 5678      # forwards to containerPort\n</code></pre> <p>Explanation highlights:</p> <ul> <li>labels.app/labels.version: used by Istio routing to target subsets</li> <li>Service targets all versions; routing decides traffic split</li> </ul> <p>Apply:</p> <pre><code>kubectl apply -f web.yaml\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#4-traffic-management-istio","title":"4) Traffic Management (Istio)","text":"<p>Define subsets and a canary split using DestinationRule + VirtualService.</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: web\n  namespace: mesh-demo\nspec:\n  host: web.mesh-demo.svc.cluster.local  # FQDN of the Service\n  trafficPolicy:\n    connectionPool:\n      http:\n        http1MaxPendingRequests: 100     # queueing before 503s\n        maxRequestsPerConnection: 100\n    outlierDetection:\n      consecutive5xxErrors: 5            # circuit breaking trigger\n      interval: 5s\n      baseEjectionTime: 30s\n  subsets:\n    - name: v1\n      labels:\n        version: v1                        # matches Deployment label\n    - name: v2\n      labels:\n        version: v2\n---\napiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: web\n  namespace: mesh-demo\nspec:\n  hosts:\n    - web\n  http:\n    - retries:\n        attempts: 2                         # retry failed requests\n        perTryTimeout: 1s\n      timeout: 3s                            # overall request timeout\n      route:\n        - destination:\n            host: web\n            subset: v1\n          weight: 90\n        - destination:\n            host: web\n            subset: v2\n          weight: 10\n</code></pre> <p>Key fields:</p> <ul> <li>DestinationRule.subsets: group Pods by version for routing</li> <li>trafficPolicy: connection pools, circuit breaking, TLS, etc.</li> <li>VirtualService.http.route: percentage split for canary</li> <li>retries/timeout: app\u2011agnostic resiliency</li> </ul>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#5-mtls-and-authorization-istio","title":"5) mTLS and Authorization (Istio)","text":"<p>Enable mesh\u2011wide mTLS in STRICT mode and allow only in\u2011namespace traffic to the <code>web</code> Service.</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: mesh-demo\nspec:\n  mtls:\n    mode: STRICT        # require mTLS for inbound traffic\n---\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: web-allow-same-namespace\n  namespace: mesh-demo\nspec:\n  selector:\n    matchLabels:\n      app: web\n  rules:\n    - from:\n        - source:\n            namespaces: [ \"mesh-demo\" ]   # only callers in this namespace\n      to:\n        - operation:\n            ports: [ \"80\" ]               # limit allowed ports\n</code></pre> <p>Test calls (from a test Pod):</p> <pre><code>kubectl -n mesh-demo run curl --image=curlimages/curl --restart=Never -it -- /bin/sh\ncurl -s web\n</code></pre> <p>Observability tips:</p> <ul> <li>Istio installs Prometheus/Grafana/Jaeger in some profiles or exposes telemetry via CRDs\u2014check <code>istio-system</code> for   addons.</li> </ul> <p>Uninstall (optional):</p> <pre><code>istioctl uninstall -y\nkubectl delete namespace istio-system\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#quickstart-linkerd","title":"Quickstart: Linkerd","text":"<p>Prerequisites:</p> <ul> <li>A Kubernetes cluster + kubectl</li> <li>Linkerd CLI: <code>curl -sL https://run.linkerd.io/install | sh</code></li> </ul>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#1-install-and-validate","title":"1) Install and Validate","text":"<pre><code>linkerd check --pre\nlinkerd install | kubectl apply -f -\nlinkerd check\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#2-meshed-namespace-and-app","title":"2) Meshed Namespace and App","text":"<pre><code>kubectl create namespace l5d-demo\nkubectl annotate namespace l5d-demo linkerd.io/inject=enabled\n\nkubectl -n l5d-demo apply -f - &lt;&lt;'YAML'\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\n  labels:\n    app: web\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: web\n        image: hashicorp/http-echo:1.0\n        args: [\"-text=Hello from Linkerd\"]\n        ports:\n        - containerPort: 5678\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: web\nspec:\n  selector:\n    app: web\n  ports:\n  - name: http\n    port: 80\n    targetPort: 5678\nYAML\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#3-traffic-split-smi-api","title":"3) Traffic Split (SMI API)","text":"<p>Linkerd supports SMI for progressive delivery. Here\u2019s an example splitting traffic between two backends.</p> <pre><code>apiVersion: split.smi-spec.io/v1alpha2\nkind: TrafficSplit\nmetadata:\n  name: web-split\n  namespace: l5d-demo\nspec:\n  service: web                      # apex Service that clients call\n  backends:\n    - service: web-v1                 # Service pointing to v1 Deployment\n      weight: 90\n    - service: web-v2                 # Service pointing to v2 Deployment\n      weight: 10\n</code></pre> <p>Notes:</p> <ul> <li>You create <code>web-v1</code> and <code>web-v2</code> Services each selecting a distinct version label.</li> <li>Adjust weights to roll traffic gradually.</li> </ul>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#4-observability","title":"4) Observability","text":"<pre><code>linkerd viz install | kubectl apply -f -\nlinkerd viz dashboard\n</code></pre> <p>Linkerd surfaces per\u2011route golden signals (latency, success rate, RPS) with negligible overhead.</p>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#5-mtls-and-policy","title":"5) mTLS and Policy","text":"<p>Linkerd enables mTLS by default. To restrict traffic, use Linkerd Policy resources (Server, ServerAuthorization) or Kubernetes NetworkPolicy for additional control.</p> <p>Uninstall (optional):</p> <pre><code>linkerd viz uninstall | kubectl delete -f -\nlinkerd uninstall | kubectl delete -f -\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#clean-up","title":"Clean Up","text":"<pre><code>kubectl delete namespace mesh-demo || true\nkubectl delete namespace l5d-demo || true\n</code></pre>"},{"location":"kubernetes/kubernetes-tools/service-mesh/#references","title":"References","text":"<ul> <li>Istio Official Website</li> <li>GitHub - Aytitech K8sFundamentals</li> </ul>"},{"location":"maven/maven-wrapper/","title":"Maven Wrapper","text":"<p>The Maven Wrapper has officially been released by the Apache Maven Project!</p>"},{"location":"maven/maven-wrapper/#what-is-maven-wrapper","title":"What is Maven Wrapper?","text":"<p>Maven Wrapper allows you to automatically download and use a specific version of Maven for your project without requiring users to install Maven manually on their machines.</p>"},{"location":"maven/maven-wrapper/#resources","title":"Resources","text":"<ul> <li>GitHub Repository: apache/maven-wrapper</li> <li>Official Site: maven.apache.org/wrapper</li> <li>JIRA Issues: MWRAPPER project issues</li> </ul>"},{"location":"maven/maven-wrapper/#how-to-use","title":"How to Use","text":"<p>Run the following command in the root directory of your Maven project to add the Maven Wrapper scripts:</p> <pre><code>mvn wrapper:wrapper\n</code></pre>"},{"location":"maven/maven-wrapper/#using-a-specific-maven-version","title":"Using a Specific Maven Version","text":"<p>To generate wrapper files for a specific Maven version (e.g., Maven 3.9.5), run:</p> <pre><code>mvn wrapper:wrapper -Dmaven=3.9.5\n</code></pre> <p>This will ensure everyone working on the project uses the specified Maven version.</p>"},{"location":"maven/maven-wrapper/#benefits","title":"Benefits","text":"<ul> <li>No need to install Maven globally</li> <li>Consistent Maven version across all environments</li> <li>Simplifies build setup for new developers</li> </ul> <p>For more details, check the official Maven Wrapper documentation.</p>"},{"location":"mobile/android/android-firebase-integration/","title":"Android Firebase Integration","text":"<p>This document describes the basic configuration required to connect an Android application to Firebase. Completing this integration allows you to use services such as Push Notifications, Crashlytics, and Analytics.</p>"},{"location":"mobile/android/android-firebase-integration/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Description Notes \u2705 Firebase Account Firebase Console Ensure you have access or invitation from an admin. \u2705 Android Studio Development environment where Firebase SDK will be integrated \u2705 Android Project The Android app project to be connected to Firebase"},{"location":"mobile/android/android-firebase-integration/#1-creating-a-firebase-project","title":"\ud83d\udd27 1. Creating a Firebase Project","text":"<ol> <li>Go to Firebase Console.</li> <li>Click Add project.</li> <li>Enter a project name and optionally enable Google Analytics.</li> <li>Complete the project creation process.</li> </ol>"},{"location":"mobile/android/android-firebase-integration/#2-adding-an-android-app-to-firebase","title":"\ud83e\udde9 2. Adding an Android App to Firebase","text":"<ol> <li>Open your Firebase project.</li> <li>Click the Android icon to add an app.</li> <li>Fill in the required info:<ul> <li>Android package name (e.g., <code>com.example.myapp</code>)</li> <li>App nickname (optional) (e.g., <code>MyApp - Android Internal App</code>)</li> <li>Debug signing certificate SHA-1 (optional, can be retrieved via Android Studio)</li> </ul> </li> <li>Click Register app.</li> <li>Download the <code>google-services.json</code> file.</li> </ol>"},{"location":"mobile/android/android-firebase-integration/#3-adding-google-servicesjson-to-your-project","title":"\ud83d\udce5 3. Adding <code>google-services.json</code> to Your Project","text":"<p>Place the downloaded <code>google-services.json</code> file into your Android app folder: <code>YourProject/app/google-services.json</code></p> <p>This file enables the Firebase SDK to configure the app.</p>"},{"location":"mobile/android/android-firebase-integration/#4-firebase-sdk-setup","title":"\u2699\ufe0f 4. Firebase SDK Setup","text":"<ul> <li>In project-level <code>build.gradle</code> (usually <code>build.gradle (Project: your-app)</code>):</li> </ul> <pre><code>buildscript {\n  dependencies {\n    classpath 'com.google.gms:google-services:4.4.0'\n  }\n}\n</code></pre> <ul> <li>In app-level <code>build.gradle</code> (usually <code>build.gradle (Module: app)</code>):</li> </ul> <pre><code>plugins {\n  id 'com.android.application'\n  id 'com.google.gms.google-services' // add at the bottom\n}\n\ndependencies {\n  implementation 'com.google.firebase:firebase-analytics:21.6.1'\n  // Optional Firebase modules:\n  implementation 'com.google.firebase:firebase-messaging:23.4.1' // for push notifications\n}\n</code></pre>"},{"location":"mobile/android/android-firebase-integration/#5-starting-firebase-sdk","title":"\ud83d\ude80 5. Starting Firebase SDK","text":"<p>Firebase initializes automatically with <code>google-services.json</code> and the Google services plugin.</p> <p>If you want manual initialization, do it in your <code>Application</code> subclass:</p> <pre><code>class BaseApplication : Application() {\n  override fun onCreate() {\n    super.onCreate()\n    FirebaseApp.initializeApp(this)\n  }\n}\n</code></pre> <p>And add to your <code>AndroidManifest.xml</code>:</p> <pre><code>\n&lt;application\n    android:name=\".BaseApplication\"\n    ... &gt;\n</code></pre>"},{"location":"mobile/android/android-google-maps-integration/","title":"Android Google Maps Integration","text":"<p>This document provides step-by-step instructions to add Google Maps integration to an Android application.</p>"},{"location":"mobile/android/android-google-maps-integration/#1-google-cloud-console-setup","title":"1. \ud83d\udd11 Google Cloud Console Setup","text":""},{"location":"mobile/android/android-google-maps-integration/#11-create-or-select-project","title":"1.1 Create or Select Project","text":"<ul> <li>Log in to Google Cloud Console.</li> <li>Create a new project or select an existing one.</li> <li>For permissions, coordinate with an authorized team member.</li> </ul>"},{"location":"mobile/android/android-google-maps-integration/#12-enable-apis","title":"1.2 Enable APIs","text":"<p>Enable the following APIs:</p> <ul> <li>\u2705 Maps SDK for Android (for maps)</li> <li>\u2705 Places API (for local search/autocomplete)</li> </ul> <p>Note: Enable any additional APIs your app requires.</p>"},{"location":"mobile/android/android-google-maps-integration/#13-create-api-key","title":"1.3 Create API Key","text":"<ul> <li>Navigate to API &amp; Services &gt; Credentials.</li> <li>Create a new API Key.</li> <li>Name the key appropriately (e.g., \"App Internal - Android Maps Key\").</li> <li> <p>Apply restrictions as follows:</p> <ul> <li> <p>Application Restrictions:</p> <ul> <li>Android apps</li> <li>Package name: <code>com.example.app.internal</code></li> <li>SHA-1 Certificate fingerprint: (from keystore, explained below)</li> </ul> </li> <li> <p>API Restrictions:</p> <ul> <li>Allow access only to:<ul> <li>Maps SDK for Android</li> <li>Places API</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"mobile/android/android-google-maps-integration/#2-obtain-keystore-sha-1-fingerprint","title":"2. \ud83d\udd10 Obtain Keystore SHA-1 Fingerprint","text":"<ul> <li>Follow instructions for Android Keystore Settings for generating a keystore and   obtaining SHA-1 fingerprint in   your Android Studio project.</li> <li>Alternatively, run the following command:</li> </ul> <p><code>./gradlew signingReport</code></p> <ul> <li>Use the SHA-1 value shown under the release or debug variant in Google Cloud Console.</li> <li>It is recommended to register both debug (internal) and release (production) SHA-1 fingerprints.</li> </ul>"},{"location":"mobile/android/android-google-maps-integration/#3-android-studio-configuration","title":"3. \ud83e\udde9 Android Studio Configuration","text":""},{"location":"mobile/android/android-google-maps-integration/#31-buildgradle-setup","title":"3.1 build.gradle Setup","text":"<p>Project-level build.gradle:</p> <pre><code>allprojects {\n    repositories {\n        google()\n        mavenCentral()\n    }\n}\n</code></pre> <p>App-level build.gradle:</p> <pre><code>dependencies {\n    implementation 'com.google.android.gms:play-services-maps:18.2.0'\n    implementation 'com.google.android.libraries.places:places:3.4.0'\n}\n</code></pre>"},{"location":"mobile/android/android-google-maps-integration/#32-androidmanifestxml-setup","title":"3.2 AndroidManifest.xml Setup","text":"<pre><code>&lt;manifest&gt;\n    &lt;application&gt;\n        &lt;meta-data\n            android:name=\"com.google.android.geo.API_KEY\"\n            android:value=\"@string/google_maps_key\" /&gt;\n    &lt;/application&gt;\n\n    &lt;uses-permission android:name=\"android.permission.ACCESS_FINE_LOCATION\" /&gt;\n    &lt;uses-permission android:name=\"android.permission.ACCESS_COARSE_LOCATION\" /&gt;\n&lt;/manifest&gt;\n</code></pre>"},{"location":"mobile/android/android-google-maps-integration/#33-add-api-key","title":"3.3 Add API Key","text":"<p>Add the <code>google_maps_key</code> in your <code>res/values/strings.xml</code> file:</p> <pre><code>&lt;string name=\"google_maps_key\"&gt;YOUR_API_KEY&lt;/string&gt;\n</code></pre> <p>You can define different keys for different build flavors or environments if needed.</p>"},{"location":"mobile/android/android-google-maps-integration/#4-testing-debugging","title":"4. \ud83e\uddea Testing &amp; Debugging","text":"<p>Test the following features inside your app:</p> <ul> <li>Does the map load correctly?</li> <li>Are pins placed correctly on the map?</li> <li>Are location permissions requested and handled properly?</li> <li>Does Places API autocomplete return results as expected?</li> <li>Can addresses be added via the map?</li> </ul> <p>If you encounter errors in Logcat, check:</p> <ul> <li>Is the API key correct?</li> <li>Is the SHA-1 fingerprint registered properly?</li> <li>Are necessary permissions granted?</li> <li>Are APIs enabled in Google Cloud Console?</li> </ul>"},{"location":"mobile/android/android-google-maps-integration/#notes","title":"\ud83d\udcdd Notes","text":"<ul> <li>Google Maps API is paid beyond a free monthly quota ($200).</li> <li>Autocomplete API can be queried frequently; consider throttling if needed.</li> <li>If map does not load in release build, verify the SHA-1 fingerprint matches the release keystore.</li> </ul>"},{"location":"mobile/android/android-keystore-settings/","title":"Android Keystore Settings","text":"<p>This document explains the steps to create, configure, and encrypt sensitive files such as <code>.keystore</code> and <code>release.properties</code> in an Android project.</p>"},{"location":"mobile/android/android-keystore-settings/#1-creating-keystore-files","title":"1. \ud83d\udd10 Creating .keystore Files","text":"<ul> <li>In Android Studio, go to Build &gt; Generate Signed Bundle / APK.</li> <li>Select Android App Bundle \u2192 Click Next.</li> <li>Click Create new....</li> <li>Fill in the fields as follows:</li> </ul> Field Example Value Keystore path <code>.keystore/appinternal.keystore</code> Password <code>123456</code> (example only) Alias <code>appinternalkeystore</code> Key password <code>123456</code> (example only) Validity (years) 25 <ul> <li>Repeat the above process for a production keystore (e.g. <code>.keystore/app.keystore</code>).</li> </ul>"},{"location":"mobile/android/android-keystore-settings/#keystore-folder-structure","title":"Keystore Folder Structure","text":"<p>The <code>.keystore/</code> folder should be placed at the project root and contain the keystore files.</p> Environment File Name Description Debug <code>appinternal.keystore</code> For development signing Release <code>app.keystore</code> For production signing"},{"location":"mobile/android/android-keystore-settings/#2-releaseproperties-file","title":"2. \ud83e\uddfe release.properties File","text":"<p>This file is read by Gradle for signing information and stores keystore properties:</p> <p>Example <code>release.properties</code> content:</p> <pre><code>APP_KEYSTORE_PASSWORD=123456\nAPP_ALIAS_PASSWORD=appinternalkeystore\nAPP_KEY_PASSWORD=123456\n</code></pre> <ul> <li>This file can also be named <code>keystore.properties</code>.</li> <li>Allows managing separate credentials for debug and release builds.</li> <li>Important: This file must be included in <code>.gitignore</code> to avoid committing sensitive data.</li> </ul> <pre><code>release.properties\n</code></pre>"},{"location":"mobile/android/android-keystore-settings/#3-obtaining-keystore-sha-1-fingerprint","title":"3. \ud83d\udd10 Obtaining Keystore SHA-1 Fingerprint","text":"<p>Run this command to get SHA-1, SHA-256, and certificate details:</p> <pre><code>keytool -list -v -keystore .keystore/appinternal.keystore -alias appinternalkeystore\n</code></pre> <ul> <li>Enter the keystore password when prompted (e.g., <code>123456</code>).</li> <li>The output includes certificate fingerprints required for services like Google Cloud Console.</li> </ul>"},{"location":"mobile/android/android-keystore-settings/#4-encrypting-the-properties-file-releasepropertiesgpg","title":"4. \ud83d\udd10 Encrypting the Properties File (<code>release.properties.gpg</code>)","text":"<p>From the project root, run:</p> <pre><code>gpg --symmetric --cipher-algo AES256 release.properties\n</code></pre> <ul> <li>You will be prompted for a passphrase (example: <code>123456</code>).</li> <li>This generates <code>release.properties.gpg</code>.</li> <li>The original <code>release.properties</code> should be deleted or kept in <code>.gitignore</code>.</li> <li>If <code>gpg</code> is not installed, install it via package manager (e.g., <code>brew install gnupg</code> on macOS).</li> </ul>"},{"location":"mobile/android/android-keystore-settings/#5-decrypting-the-encrypted-file","title":"5. \ud83d\udd13 Decrypting the Encrypted File","text":"<p>To decrypt <code>release.properties.gpg</code> on another machine or CI/CD:</p> <pre><code>gpg --output release.properties --decrypt release.properties.gpg\n</code></pre>"},{"location":"mobile/android/android-keystore-settings/#6-gradle-signingconfig-setup","title":"6. \u2705 Gradle SigningConfig Setup","text":"<p>In your app-level <code>build.gradle</code>:</p> <pre><code>    android {\n        signingConfigs {\n            debug {\n                storeFile = rootProject.file(\".keystore/appinternal.keystore\")\n                storePassword = \"123456\"\n                keyAlias = \"appinternalkeystore\"\n                keyPassword = \"123456\"\n            }\n            release {\n                storeFile = rootProject.file(\".keystore/app.keystore\")\n                storePassword = releaseProperties.getProperty(\"APP_KEYSTORE_PASSWORD\")\n                keyAlias = releaseProperties.getProperty(\"APP_ALIAS_PASSWORD\")\n                keyPassword = releaseProperties.getProperty(\"APP_KEY_PASSWORD\")\n            }\n        }\n\n        buildTypes {\n            debug {\n                signingConfig signingConfigs.debug\n            }\n            release {\n                signingConfig signingConfigs.release\n            }\n        }\n    }\n</code></pre> <ul> <li><code>releaseProperties</code> is loaded from the decrypted <code>release.properties</code> file, which is not committed to Git.</li> </ul>"},{"location":"mobile/android/android-keystore-settings/#7-usage-in-cicd-environment","title":"7. \u2705 Usage in CI/CD Environment","text":"<ul> <li>The <code>.gpg</code> encrypted file can be committed to the repository.</li> <li>During the CI/CD pipeline, decrypt it securely.</li> <li>Store the decryption passphrase as an environment secret (e.g., <code>RELEASE_FILE_PASSPHRASE</code>).</li> <li>Avoid hardcoding passwords.</li> <li>Use the same password for keystore and <code>.gpg</code> for simplicity.</li> </ul>"},{"location":"mobile/android/android-keystore-settings/#8-security-notes","title":"8. \ud83d\uded1 Security Notes","text":"<ul> <li>Never commit <code>.properties</code> files containing sensitive data to Git.</li> <li>Encrypted <code>.gpg</code> files can be version controlled but must be protected.</li> <li>On shared machines, delete decrypted files immediately after use.</li> </ul>"},{"location":"mobile/android/android-push-notification-integration/","title":"Android Push Notification Integration","text":"<p>This guide explains how to set up and integrate push notifications into an Android application using Firebase Cloud Messaging (FCM). It covers creating a Firebase project, adding the <code>google-services.json</code> file, configuring Android project files, and testing the notifications.</p> <p>Goal: Enable delivery of push notifications to Android devices via Firebase.</p>"},{"location":"mobile/android/android-push-notification-integration/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Description \u2705 Firebase Project Create one at Firebase Console \u2705 Android App Written in Kotlin or Java, with access to AndroidManifest and build.gradle files \u2705 Physical Device Recommended for push testing (emulators may work but physical devices ensure accuracy)"},{"location":"mobile/android/android-push-notification-integration/#1-firebase-setup","title":"\ud83e\udde9 1. Firebase Setup","text":"<p>Follow the steps in the document below to create a Firebase project and add the <code>google-services.json</code> file to your project:</p> <p>Android Firebase Integration</p>"},{"location":"mobile/android/android-push-notification-integration/#2-firebase-sdk-and-push-notification-setup","title":"\u2699\ufe0f 2. Firebase SDK and Push Notification Setup","text":"<p>\ud83d\udd27 build.gradle (Project-level)</p> <pre><code>buildscript {\n  dependencies {\n    classpath 'com.google.gms:google-services:4.4.0' // Keep the version updated  \n  }\n}\n</code></pre> <p>\ud83d\udd27 build.gradle (App-level)</p> <pre><code>plugins {\n  id 'com.android.application'\n  id 'com.google.gms.google-services' // Make sure this is added at the bottom  \n}\n\ndependencies {\n  implementation platform('com.google.firebase:firebase-bom:32.7.0') // Version BOM  \n  implementation 'com.google.firebase:firebase-messaging'\n}\n</code></pre>"},{"location":"mobile/android/android-push-notification-integration/#3-initializing-firebase-and-retrieving-token","title":"\ud83d\ude80 3. Initializing Firebase and Retrieving Token","text":"<p>\ud83d\udcdd MyFirebaseMessagingService.kt</p> <pre><code>class MyFirebaseMessagingService : FirebaseMessagingService() {\n\n  override fun onNewToken(token: String) {\n    super.onNewToken(token)\n    Log.d(\"FCM\", \"FCM Token: $token\")\n    // TODO: Send token to backend server for push targeting  \n  }\n\n  override fun onMessageReceived(remoteMessage: RemoteMessage) {\n    super.onMessageReceived(remoteMessage)\n\n    val notification = remoteMessage.notification\n    notification?.let {\n      Log.d(\"FCM\", \"Notification: ${it.title} - ${it.body}\")\n    }\n  }\n}\n</code></pre> <p>\ud83d\udcdd AndroidManifest.xml</p> <pre><code>\n&lt;service\n    android:name=\".MyFirebaseMessagingService\"\n    android:exported=\"false\"&gt;\n  &lt;intent-filter&gt;\n    &lt;action android:name=\"com.google.firebase.MESSAGING_EVENT\"/&gt;\n  &lt;/intent-filter&gt;\n&lt;/service&gt;\n\n&lt;uses-permission android:name=\"android.permission.POST_NOTIFICATIONS\"/&gt;  \n</code></pre> <p>\u2705 For Android 13+ devices, runtime permission for notifications must be requested.</p>"},{"location":"mobile/android/android-push-notification-integration/#4-android-13-notification-permission-recommended","title":"\ud83d\udd14 4. Android 13+ Notification Permission (Recommended)","text":"<pre><code>if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.TIRAMISU) {\n  ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.POST_NOTIFICATIONS), 1001)\n}\n</code></pre>"},{"location":"mobile/android/android-push-notification-integration/#5-testing-push-notifications-from-firebase","title":"\ud83d\ude80 5. Testing Push Notifications from Firebase","text":"<ol> <li>Open Firebase Console &gt; Cloud Messaging &gt; Send your first message.</li> <li>Enter a title and message.</li> <li>Click Test on device.</li> <li>Enter the device token (retrieved from app logs).</li> <li>Click Send Test Message.</li> <li>\u2705 The notification should appear on the device.</li> </ol>"},{"location":"mobile/android/android-push-notification-integration/#notes-and-tips","title":"\ud83e\udde0 Notes and Tips","text":"<ul> <li>Do not share your <code>google-services.json</code> file publicly \u2014 it contains sensitive credentials.</li> <li>The app\u2019s package name in Firebase must match your app\u2019s actual package name.</li> <li>If required, add your SHA-1 key to the Firebase project for authentication.</li> <li>To successfully receive push notifications:<ul> <li>The notification permission must be granted.</li> <li>The device must be connected to the internet.</li> <li>The FCM token must be sent to your backend correctly.</li> </ul> </li> </ul>"},{"location":"mobile/ios/ios-firebase-integration/","title":"iOS Firebase Integration","text":"<p>This document outlines the basic setup required to connect an iOS application to Firebase. This integration enables services such as Push Notifications, Crashlytics, and Analytics.</p>"},{"location":"mobile/ios/ios-firebase-integration/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Description \u2705 Firebase Account Create or access via Firebase Console \u2705 iOS App in Xcode An existing iOS project created in Xcode"},{"location":"mobile/ios/ios-firebase-integration/#1-create-a-firebase-project","title":"\ud83d\udd27 1. Create a Firebase Project","text":"<ol> <li>Go to Firebase Console.</li> <li>Click \"Add project\".</li> <li>Enter a project name \u2192 Enable Google Analytics (optional).</li> <li>Complete the project creation process.</li> </ol>"},{"location":"mobile/ios/ios-firebase-integration/#2-add-your-ios-app-to-firebase","title":"\ud83e\udde9 2. Add Your iOS App to Firebase","text":"<ol> <li>Open your Firebase project in the console.</li> <li>In the Project Overview, click the iOS icon.</li> <li>Fill in the following:<ul> <li>iOS Bundle ID: Must exactly match the bundle ID in your Xcode project (e.g., <code>com.example.myapp</code>).</li> <li>App nickname: (Optional) A display name for your app. (e.g., <code>MyApp - iOS Internal App</code>)</li> <li>App Store ID: Leave blank if not applicable.</li> </ul> </li> <li>Click Register app.</li> <li>Download the GoogleService-Info.plist file.</li> </ol>"},{"location":"mobile/ios/ios-firebase-integration/#3-add-googleservice-infoplist-to-your-project","title":"\ud83d\udce5 3. Add <code>GoogleService-Info.plist</code> to Your Project","text":"<ol> <li>Drag the downloaded <code>GoogleService-Info.plist</code> file into your Xcode project.</li> <li>In the popup:<ul> <li>\u2705 Check \"Copy items if needed\".</li> <li>\u2705 Ensure your main app target is selected in Add to targets.</li> </ul> </li> </ol> <p>This file is required for the Firebase SDK to load your app configuration.</p>"},{"location":"mobile/ios/ios-firebase-integration/#4-install-firebase-sdk","title":"\u2699\ufe0f 4. Install Firebase SDK","text":"<p>Using Swift Package Manager (Recommended):</p> <ol> <li>In Xcode, go to File &gt; Add Packages.</li> <li> <p>Enter the URL: https://github.com/firebase/firebase-ios-sdk</p> </li> <li> <p>Select the modules you need:</p> </li> <li> <p><code>FirebaseAnalytics</code></p> </li> <li><code>FirebaseMessaging</code> (for push notifications)</li> <li><code>FirebaseCrashlytics</code>, <code>FirebaseAuth</code>, etc., as needed.</li> </ol>"},{"location":"mobile/ios/ios-firebase-integration/#5-initialize-firebase-sdk","title":"\ud83d\ude80 5. Initialize Firebase SDK","text":"<p>AppDelegate.swift:</p> <pre><code>import Firebase\n\nfunc application(_ application: UIApplication,\n                 didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -&gt; Bool {\n  FirebaseApp.configure()\n  return true\n}\n</code></pre>"},{"location":"mobile/ios/ios-google-maps-integration/","title":"iOS Google Maps Integration","text":"<p>This document explains step-by-step how to integrate Google Maps into an iOS application.</p>"},{"location":"mobile/ios/ios-google-maps-integration/#1-google-cloud-console-setup","title":"1. \ud83d\udd11 Google Cloud Console Setup","text":""},{"location":"mobile/ios/ios-google-maps-integration/#11-create-or-select-project","title":"1.1 Create or Select Project","text":"<ul> <li>Log in to Google Cloud Console.</li> <li>Create a new project or select an existing one.</li> <li>For permissions, coordinate with an authorized team member.</li> </ul>"},{"location":"mobile/ios/ios-google-maps-integration/#12-enable-apis","title":"1.2 Enable APIs","text":"<p>Enable the following APIs for your project:</p> <ul> <li>\u2705 Maps SDK for iOS (for maps)</li> <li>\u2705 Places API (for local search/autocomplete)</li> <li>\u2705 Places SDK for iOS</li> </ul> <p>Note: Enable any additional APIs depending on the services your app uses.</p>"},{"location":"mobile/ios/ios-google-maps-integration/#13-create-api-key","title":"1.3 Create API Key","text":"<ul> <li>Navigate to API &amp; Services &gt; Credentials.</li> <li>Create a new API key.</li> <li>Give it a descriptive name (e.g., <code>MyApp iOS Maps Key</code>).</li> </ul> <p>Apply restrictions:</p> <ul> <li> <p>Application Restrictions:</p> <ul> <li>iOS apps</li> <li>Bundle ID: Your app\u2019s exact bundle ID (e.g., <code>com.example.myapp</code>)</li> </ul> </li> <li> <p>API Restrictions:</p> <ul> <li>Allow access only to:<ul> <li>Maps SDK for iOS</li> <li>Places API</li> <li>Places SDK for iOS</li> </ul> </li> </ul> </li> </ul>"},{"location":"mobile/ios/ios-google-maps-integration/#2-xcode-setup","title":"2. \ud83e\udde9 Xcode Setup","text":""},{"location":"mobile/ios/ios-google-maps-integration/#21-required-sdks","title":"2.1 Required SDKs","text":"<p>Make sure <code>GoogleMaps</code> and <code>GooglePlaces</code> SDKs are installed in your project.</p>"},{"location":"mobile/ios/ios-google-maps-integration/#22-define-api-key","title":"2.2 Define API Key","text":"<p>In your <code>AppDelegate.swift</code>, inside the <code>application(_:didFinishLaunchingWithOptions:)</code> method, add:</p> <pre><code>import GoogleMaps\nimport GooglePlaces\n\nGMSServices.provideAPIKey(\"YOUR_API_KEY\")\nGMSPlacesClient.provideAPIKey(\"YOUR_API_KEY\")\n</code></pre> <p>It\u2019s recommended to fetch the API key from a configuration file or plist instead of hardcoding.</p>"},{"location":"mobile/ios/ios-google-maps-integration/#23-infoplist-settings","title":"2.3 Info.plist Settings","text":"<p>Add the following keys and descriptions if your app uses location services:</p> <pre><code>\n&lt;key&gt;NSLocationWhenInUseUsageDescription&lt;/key&gt;\n&lt;string&gt;Permission required to show your location on the map.&lt;/string&gt;\n&lt;key&gt;NSLocationAlwaysAndWhenInUseUsageDescription&lt;/key&gt;\n&lt;string&gt;Permission required to show your location on the map.&lt;/string&gt;\n&lt;key&gt;io.flutter.embedded_views_preview&lt;/key&gt;\n&lt;true/&gt;\n</code></pre> <p>Location permissions are necessary if your app uses device location features.</p>"},{"location":"mobile/ios/ios-google-maps-integration/#3-in-app-settings","title":"3. In-App Settings","text":"<ul> <li> <p>Ensure your Bundle ID exactly matches the one set in Google Cloud Console.</p> </li> <li> <p>Consider defining the API key in a configuration file (e.g., <code>Config.plist</code> or <code>Environment.swift</code>) for easier   management.</p> </li> <li> <p>Use different API keys for testing and production environments if needed.</p> </li> </ul>"},{"location":"mobile/ios/ios-google-maps-integration/#4-testing-debugging","title":"4. Testing &amp; Debugging","text":"<p>Test the following features inside your app:</p> <ul> <li>Does the map load correctly?</li> <li>Are pins placed correctly on the map?</li> <li>Are location permissions requested and handled properly?</li> <li>Does Places API autocomplete return results as expected?</li> <li>Can addresses be added via the map?</li> </ul> <p>If you encounter errors in Logcat, check:</p> <ul> <li>The API key might be incorrect.</li> <li>Required APIs might not be enabled.</li> <li>iOS location permissions might be missing.</li> <li>Check Xcode Console logs for messages like:</li> </ul> <pre><code>Google Maps SDK for iOS version...\nLoaded GMSCoreResources.bundle\n</code></pre>"},{"location":"mobile/ios/ios-google-maps-integration/#notes","title":"Notes","text":"<ul> <li> <p>Google Maps usage includes a $200 free monthly credit; billing applies if usage exceeds this.</p> </li> <li> <p>Autocomplete queries can be frequent; consider adding throttling or limiting requests.</p> </li> </ul>"},{"location":"mobile/ios/ios-push-notification-integration/","title":"iOS Push Notification Integration","text":"<p>This document provides step-by-step instructions to create an APNs Authentication Key (.p8) from Apple Developer, add the GoogleService-Info.plist file to the project, and configure necessary settings in Firebase Console.</p> <p>The goal is to enable push notification delivery to iOS devices via Firebase.</p>"},{"location":"mobile/ios/ios-push-notification-integration/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Description Notes \u2705 Apple Developer Account Apple Developer account required See iOS TestFlight Integration for details. \u2705 Firebase Project Firebase project must be created See iOS Firebase Integration for details. \u2705 iOS App created with Xcode The app must be registered in Firebase \u2705 Physical iOS device Required for push testing (simulator not supported)"},{"location":"mobile/ios/ios-push-notification-integration/#1-firebase-setup","title":"\ud83e\udde9 1. Firebase Setup","text":"<p>Follow the document for creating a Firebase project and adding the <code>GoogleService-Info.plist</code> file to the project:</p> <p>iOS Firebase Integration</p>"},{"location":"mobile/ios/ios-push-notification-integration/#2-app-store-connect-and-apple-developer-setup","title":"\ud83e\udde9 2. App Store Connect and Apple Developer Setup","text":"<p>Follow the document for Apple Developer account setup and app registration:</p> <p>iOS TestFlight Integration</p>"},{"location":"mobile/ios/ios-push-notification-integration/#3-create-apns-authentication-key-p8","title":"\ud83d\udd11 3. Create APNs Authentication Key (.p8)","text":"<ol> <li>Log in to Apple Developer    at Apple Developer Auth Keys.</li> <li>Click the \"+\" (Create a key) button at the top right.</li> <li>Fill in required information:<ul> <li>Key Name: e.g., <code>FCM APNs Key</code></li> <li>Services: Select Apple Push Notifications service (APNs) \u2705</li> </ul> </li> <li>Click Continue &gt; Register, then download the .p8 file.</li> <li>Note these values:<ul> <li>Key ID (shown on the main page)</li> <li>Team ID (found under Membership)</li> </ul> </li> </ol>"},{"location":"mobile/ios/ios-push-notification-integration/#4-upload-apns-key-to-firebase-console","title":"\u2601\ufe0f 4. Upload APNs Key to Firebase Console","text":"<ol> <li>Go to Firebase Console &gt; Project Settings &gt; Cloud Messaging tab.</li> <li>Scroll down to iOS App Configuration &gt; APNs Authentication Key section.</li> <li>Upload the .p8 file.</li> <li>Fill in Key ID and Team ID fields.</li> <li>Click Save.</li> </ol> <p>\u2705 Firebase is now authorized to connect to APNs!</p>"},{"location":"mobile/ios/ios-push-notification-integration/#5-ios-app-push-notification-setup","title":"\u2699\ufe0f 5. iOS App Push Notification Setup","text":"<p>Ensure <code>FirebaseMessaging</code> SDK is installed.</p> <ul> <li>Add the following code in <code>AppDelegate.swift</code>:</li> </ul> <pre><code>import UIKit\nimport Firebase\nimport UserNotifications\n\n@UIApplicationMain\nclass AppDelegate: UIResponder, UIApplicationDelegate {\n\n  func application(_ application: UIApplication,\n                   didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -&gt; Bool {\n    FirebaseApp.configure()\n\n    UNUserNotificationCenter.current().delegate = self\n    UNUserNotificationCenter.current().requestAuthorization(options: [.alert, .badge, .sound]) { granted, error in\n        print(\"Push permission: \\(granted)\")\n    }\n\n    application.registerForRemoteNotifications()\n    Messaging.messaging().delegate = self\n\n    return true\n  }\n\n  func application(_ application: UIApplication,\n                   didRegisterForRemoteNotificationsWithDeviceToken deviceToken: Data) {\n    Messaging.messaging().apnsToken = deviceToken\n  }\n}\n</code></pre> <ul> <li><code>MessagingDelegate</code> and <code>UNUserNotificationCenterDelegate</code> Extensions:</li> </ul> <pre><code>extension AppDelegate: MessagingDelegate {\n  func messaging(_ messaging: Messaging, didReceiveRegistrationToken fcmToken: String?) {\n    // Send token to backend\n    NotificationServiceV2Helper.shared.saveFCMToken(fcmToken)\n  }\n}\n\nextension AppDelegate: UNUserNotificationCenterDelegate {\n  func userNotificationCenter(_ center: UNUserNotificationCenter,\n                              willPresent notification: UNNotification,\n                              withCompletionHandler completionHandler: @escaping (UNNotificationPresentationOptions) -&gt; Void) {\n    completionHandler([.alert, .badge, .sound])\n  }\n}\n</code></pre>"},{"location":"mobile/ios/ios-push-notification-integration/#6-test-send-push-via-firebase-console","title":"\ud83d\ude80 6. Test: Send Push via Firebase Console","text":"<ol> <li>Go to Firebase Console &gt; Cloud Messaging.</li> <li>Click Send your first message.</li> <li>Enter title and message.</li> <li>Select Test on device.</li> <li>Enter the FCM token retrieved from the iOS device.</li> <li>Click Send Test Message.</li> </ol> <p>\u2705 Push notification should appear on the device.</p>"},{"location":"mobile/ios/ios-push-notification-integration/#notes-tips","title":"\ud83e\udde0 Notes &amp; Tips","text":"<ul> <li>The .p8 APNs key is valid for all your apps (one key for all bundle IDs).</li> <li>Push notifications do not work on the simulator; testing must be on a physical device.</li> <li>If you don't have a physical device, upload your app to TestFlight and ask someone with a real device to test.</li> <li>To receive push notifications:<ul> <li>Notification permission must be granted.</li> <li>Device must have an internet connection.</li> <li>FCM token must be sent correctly to your backend.</li> </ul> </li> </ul>"},{"location":"mobile/ios/ios-push-notification-integration/#faq","title":"\ud83d\udcac FAQ","text":"<p>Q: When I visit https://developer.apple.com/account/resources/, I get this error:</p> <p>Access Unavailable This resource is only for developers enrolled in a developer program or members of an organization's team in a developer program.</p> <p>A: You need to be added to the Apple Developer account by an authorized person. See step 2 for details.</p> <p>Q: When I visit https://developer.apple.com/account/resources/authkeys/list, I get this error:</p> <p>You are not allowed to perform this operation. Please check with one of your Team Admins, or, if you need further assistance, please contact Apple Developer Program Support. https://developer.apple.com/support</p> <p>A: You need to be added to the Apple Developer account by an authorized person. See step 2 for details.</p>"},{"location":"mobile/ios/ios-test-flight-integration/","title":"iOS TestFlight Integration","text":"<p>This document guides you through the steps to enable testing of your local iOS project via TestFlight by other users.</p>"},{"location":"mobile/ios/ios-test-flight-integration/#requirements","title":"Requirements","text":"<ul> <li>Apple Developer account (annual $99 fee)</li> <li>Xcode</li> <li>Valid provisioning profile for your Apple device</li> <li>Access to App Store Connect (same Apple account)</li> <li>App must have a Bundle ID and version number</li> </ul>"},{"location":"mobile/ios/ios-test-flight-integration/#1-app-store-connect-and-apple-developer-setup","title":"1. App Store Connect and Apple Developer Setup","text":"<ul> <li>Have an authorized person invite you to App Store Connect via https://appstoreconnect.apple.com/access/users with Developer role for read access or App Manager role for admin tasks.</li> <li>Accept the invitation email and set your password to activate your developer account.</li> <li>Log in to https://developer.apple.com/account/</li> <li>Create an App ID (Bundle ID) under https://developer.apple.com/account/resources/identifiers/list if you haven\u2019t already. Xcode might create some automatically but you may need to create others manually.</li> <li>In App Store Connect (https://appstoreconnect.apple.com/apps), create a new app:<ul> <li>Platform: iOS</li> <li>Name: (Your app\u2019s internal or public name) (e.g. <code>MyApp Internal</code>)</li> <li>Primary Language: Choose your language</li> <li>Bundle ID: Must exactly match the one in Xcode (e.g. <code>com.example.app.internal</code>)</li> <li>SKU: A unique short identifier (e.g. <code>com.example.app.internal</code>)</li> </ul> </li> </ul>"},{"location":"mobile/ios/ios-test-flight-integration/#2-prepare-your-app-in-xcode","title":"2. Prepare Your App in Xcode","text":"<ul> <li>Open your project in Xcode.</li> <li>Under the General tab:<ul> <li>Verify Version and Build number (e.g. Version = 1.0.0, Build = 1)</li> <li>Manually increment Build number for each archive.</li> </ul> </li> <li>Under Signing &amp; Capabilities, select your Team.</li> <li>Archive your app via Product &gt; Archive.</li> <li>When archive completes, Organizer window opens.</li> <li>Select the new archive, then click Distribute App.</li> <li>Choose App Store Connect &gt; Upload.</li> <li>Follow the steps until you receive the \"Upload succeeded\" message.</li> </ul>"},{"location":"mobile/ios/ios-test-flight-integration/#3-configure-testflight-in-app-store-connect","title":"3. Configure TestFlight in App Store Connect","text":"<ul> <li>Go to App Store Connect &gt; My Apps &gt; Select your app.</li> <li>Open the TestFlight tab.</li> <li>Wait for your uploaded build to appear (may take a few minutes).</li> <li>For internal testing:<ul> <li>Go to Internal Testing &gt; click \"+\" to create a test group.</li> <li>Add testers to the group.</li> <li>Optionally enable automatic assignment of builds to this group.</li> </ul> </li> <li>Approve the build.</li> <li>Invite Internal Testers (team members) or External Testers (outside testers).</li> <li>Note: External testers require a brief Apple review process (usually 1\u20132 days).</li> </ul>"},{"location":"mobile/ios/ios-test-flight-integration/#4-what-testers-receive","title":"4. What Testers Receive","text":"<ul> <li>Testers download the TestFlight app from the App Store.</li> <li>They are invited via their Apple ID email.</li> <li>Invitations contain a message like: \"You\u2019ve been invited to test [App Name].\"</li> <li>After accepting, testers can install and test your app.</li> </ul>"},{"location":"mobile/ios/ios-test-flight-integration/#notes","title":"Notes","text":"<ul> <li>The app does not need to be published on the App Store.</li> <li>TestFlight allows up to 10,000 testers per app.</li> <li>Each build can be tested for up to 90 days.</li> <li>Crash and usage reports are available via TestFlight.</li> </ul>"},{"location":"mobile/ios/ios-test-flight-integration/#faq","title":"FAQ","text":"<p>Q: I get this error while archiving:</p> <ol> <li>No profiles for 'com.example.app.internal.NotificationService' were found      &gt;  Xcode couldn't find any iOS App Store provisioning profiles matching 'com.example.app.internal.NotificationService'.</li> <li>Automatic signing cannot register bundle identifier \"com.example.app.internal.NotificationService\".       &gt;  Automatic signing cannot register bundle identifiers with Apple. Register your bundle identifier on https://developer.apple.com/account and then try again.</li> </ol> <p>A: Your app's bundle ID <code>com.example.app.internal.NotificationService</code> is not registered as an App ID. Register it manually at https://developer.apple.com/account/resources/identifiers/list.</p> <p>Q: I get this validation error when archiving:</p> <p>Validation failed Invalid large app icon. The large app icon in the asset catalog in your app can\u2019t be transparent or contain an alpha channel. For details, visit: https://developer.apple.com/design/human-interface-guidelines/app-icons.</p> <p>A: App Store does not accept app icons with transparency. Remove transparency or corner rounding in your icons (set corner radius to 0 and fill background with a solid color).</p>"},{"location":"nodejs/nvm-npm/","title":"Nvm &amp; Npm - Node Version &amp; Package Manager","text":"<p>nvm (Node Version Manager) allows you to install and switch between multiple Node.js versions easily. npm (Node Package Manager) is used to manage JavaScript packages for Node.js.</p>"},{"location":"nodejs/nvm-npm/#1-installation","title":"1. Installation","text":"<pre><code>brew install nvm\n</code></pre>"},{"location":"nodejs/nvm-npm/#2-configure-nvm","title":"2. Configure NVM","text":"<p>Create a directory for NVM:</p> <pre><code>mkdir ~/.nvm\n</code></pre> <p>Update your shell configuration (<code>~/.bash_profile</code> or <code>~/.zshrc</code>):</p> <pre><code># NVM\nexport NVM_DIR=\"$HOME/.nvm\"\n  [ -s \"$(brew --prefix)/opt/nvm/nvm.sh\" ] &amp;&amp; . \"$(brew --prefix)/opt/nvm/nvm.sh\" # This loads nvm\n  [ -s \"$(brew --prefix)/opt/nvm/etc/bash_completion.d/nvm\" ] &amp;&amp; . \"$(brew --prefix)/opt/nvm/etc/bash_completion.d/nvm\" # This loads nvm\n</code></pre> <p>Reload your shell:</p> <pre><code>source ~/.bash_profile\n</code></pre>"},{"location":"nodejs/nvm-npm/#3-basic-commands","title":"3. Basic Commands","text":"<p>Check nvm version:</p> <pre><code>nvm --version\n</code></pre> <p>Install a specific Node.js version:</p> <pre><code>nvm install 16.20.2\n</code></pre> <p>List installed Node.js versions:</p> <pre><code>nvm list\n</code></pre> <p>List available remote versions:</p> <pre><code>nvm list-remote\n</code></pre> <p>Use a specific version:</p> <pre><code>nvm use 16.20.2\n</code></pre> <p>Set a default version:</p> <pre><code>nvm alias default 16.20.2\n</code></pre>"},{"location":"nodejs/nvm-npm/#4-node-npm-versions","title":"4. Node &amp; NPM Versions","text":"<p>Check versions:</p> <pre><code>node -v # node --version\nnpm -v # npm --version\n</code></pre>"},{"location":"nodejs/nvm-npm/#5-using-nvmrc-and-npmrc","title":"5. Using <code>.nvmrc</code> and <code>.npmrc</code>","text":""},{"location":"nodejs/nvm-npm/#51-nvmrc","title":"5.1 <code>.nvmrc</code>","text":"<p>If your project contains a <code>.nvmrc</code> file:</p> <pre><code>v16.20.2\n</code></pre> <p>You can run:</p> <pre><code>nvm use\n</code></pre> <p>to automatically switch to that version.</p>"},{"location":"nodejs/nvm-npm/#52-npmrc","title":"5.2 <code>.npmrc</code>","text":"<p><code>.npmrc</code> is a configuration file that customizes npm behavior, such as registry URLs and authentication tokens.</p> <p>Example <code>.npmrc</code> for private GitHub packages:</p> <pre><code>@yourorg:registry=https://npm.pkg.github.com\n//npm.pkg.github.com/:_authToken=ghp_your_github_token_here\n</code></pre>"},{"location":"nodejs/nvm-npm/#6-makefile-commands-for-easy-setup","title":"6. Makefile Commands for Easy Setup","text":"<p>Generate <code>.npmrc</code>:</p> <pre><code>init-npmrc: ## Generate npmrc file to access @yourorg npm packages\n    echo -e \"@yourorg:registry=https://npm.pkg.github.com\\n//npm.pkg.github.com/:_authToken=${GITHUB_TOKEN}\" &gt;${MAIN_POM_FOLDER}/app/test-react-client/.npmrc\n</code></pre> <p>Build React Client:</p> <pre><code>react-build: ## Build react client\n    rm -rf ${MAIN_POM_FOLDER}/app/test-react-client/node \\\n           ${MAIN_POM_FOLDER}/app/test-react-client/node_modules\n    make init-npmrc\n    cd ${MAIN_POM_FOLDER}/app/test-react-client &amp;&amp; \\\n    bash -i -c \"nvm use &amp;&amp; npm install\"\n</code></pre> <p>Run React Client:</p> <pre><code>react-run: ## Run react client\n    make init-npmrc\n    cd ${MAIN_POM_FOLDER}/app/test-react-client &amp;&amp; \\\n    bash -i -c \"nvm use &amp;&amp; npm start\"\n</code></pre> <p>Usage:</p> <pre><code>make init-npmrc\nmake react-build\nmake react-run\n</code></pre>"},{"location":"nodejs/nvm-npm/#7-useful-commands","title":"7. Useful Commands","text":"<p>Kill a process on port 3000:</p> <pre><code>lsof -i tcp:3000\nkill -9 &lt;PID&gt;\n</code></pre> <p>Webpack Installation:</p> <pre><code>npm install --save-dev webpack@4\nwebpack --version\nnpm run dev\n</code></pre>"},{"location":"nodejs/nvm-npm/#8-directory-structure","title":"8. Directory Structure","text":"<pre><code>~/.nvm\n   \u2514\u2500 versions\n      \u2514\u2500 node\n         \u251c\u2500 v11.14.0\n         \u2502  \u2514\u2500 lib\n         \u2502     \u2514\u2500 node_modules\n         \u2502        \u2514\u2500 npm\n         \u2514\u2500 v12.4.0\n            \u2514\u2500 lib\n               \u2514\u2500 node_modules\n                  \u2514\u2500 npm\n</code></pre>"},{"location":"nodejs/nvm-npm/#references","title":"References","text":"<ul> <li>NVM GitHub</li> <li>Node.js Website</li> <li>NPM Documentation</li> <li>Homebrew NVM Formula</li> <li>Webpack</li> </ul>"},{"location":"shell/bash-completion/","title":"Bash Completion","text":""},{"location":"shell/bash-completion/#introduction","title":"Introduction","text":"<p>Bash completion is a shell feature that allows you to auto-complete commands, options, and arguments by pressing the Tab key. This is especially useful for CLI tools like <code>git</code>, <code>docker</code>, <code>kubectl</code>, and <code>multipass</code> where you often need to remember many commands and flags.</p> <p>In this guide, we'll:</p> <ul> <li>Install <code>bash-completion</code> using Homebrew.</li> <li>Enable bash completion in your shell.</li> <li>Set up completion for Git, Docker, kubectl, and Multipass.</li> </ul>"},{"location":"shell/bash-completion/#installing-bash-completion","title":"Installing Bash Completion","text":"<p>Bash Completion comes in two major versions, and the right one for you depends on your Bash version.</p> Feature bash-completion v1 bash-completion v2 Compatible Bash versions Bash 3.x and above Bash 4.x and above (including 5.x) Status Legacy, still works for older setups Recommended for modern setups Installation path (Homebrew) <code>/usr/local/etc/bash_completion.d/</code> <code>$(brew --prefix)/etc/profile.d/</code> Feature set More limited Expanded features and modern completion format macOS usage Works with macOS default Bash (3.2) Best used with newer Bash installed via Homebrew <p>When to choose v1:</p> <ul> <li>You are on macOS and using the default Bash (3.2) without upgrading.</li> <li>You need maximum compatibility with older scripts or legacy environments.</li> </ul> <p>When to choose v2:</p> <ul> <li>You have installed a newer Bash (4.x or 5.x) via Homebrew.</li> <li>You want more up-to-date and feature-rich completions.</li> </ul> <p>Installation commands:</p> <ul> <li>v1:</li> </ul> <pre><code>brew install bash-completion\n</code></pre> <ul> <li>v2:</li> </ul> <pre><code>brew install bash-completion@2\n</code></pre>"},{"location":"shell/bash-completion/#enabling-bash-completion","title":"Enabling Bash Completion","text":"<p>To enable bash completion globally, add the following to your <code>~/.bash_profile</code> (or <code>~/.bashrc</code> if you prefer):</p> <ul> <li>If you installed <code>bash-completion</code>:</li> </ul> <pre><code>if [ -f $(brew --prefix)/etc/bash_completion ]; then\n  . $(brew --prefix)/etc/bash_completion\nfi\n</code></pre> <ul> <li>If you installed <code>bash-completion@2</code>:</li> </ul> <pre><code>if [ -f $(brew --prefix)/etc/profile.d/bash_completion.sh ]; then\n    . $(brew --prefix)/etc/profile.d/bash_completion.sh\nfi\n</code></pre> <p>Then reload your profile:</p> <pre><code>source ~/.bash_profile\n</code></pre>"},{"location":"shell/bash-completion/#git-bash-completion","title":"Git Bash Completion","text":"<p>Git also supports bash tab completion to make typing commands and branch names faster.</p> <p>Add alias <code>g</code> for <code>git</code> in your <code>~/.aliases</code> file:</p> <pre><code>alias g=\"git\"\n</code></pre> <p>Source the git-completion script if it exists:</p> <pre><code>if [ -f ~/.git-completion.bash ]; then\n    source ~/.git-completion.bash\nfi\n</code></pre> <p>Set up tab completion for the 'g' alias if bash completion is available:</p> <pre><code>if type _git &amp;&gt; /dev/null &amp;&amp; [ -f /usr/local/etc/bash_completion.d/git-completion.bash ]; then\n  complete -o default -o nospace -F _git g;\nfi;\n</code></pre> <p>Reload your shell:</p> <pre><code>source ~/.aliases\nsource ~/.bash_profile\n</code></pre> <p>You can now type:</p> <pre><code>git &lt;TAB&gt;\ng &lt;TAB&gt;\n</code></pre> <p>and see available commands.</p>"},{"location":"shell/bash-completion/#docker-bash-completion","title":"Docker Bash Completion","text":"<p>Add alias <code>d</code> for <code>docker</code> in your <code>~/.aliases</code> file:</p> <pre><code>alias d=\"docker\"\n</code></pre> <p>Create a dedicated directory for Docker completions and download the script:</p> <pre><code>mkdir -p ~/.docker/completion\ncurl -L https://raw.githubusercontent.com/docker/cli/master/contrib/completion/bash/docker \\\n    -o ~/.docker/completion/docker\n</code></pre> <p>Source the completion script in your <code>~/.bash_profile</code>:</p> <pre><code>echo 'source ~/.docker/completion/docker' &gt;&gt; ~/.bash_profile\necho 'complete -F _docker d' &gt;&gt; ~/.bash_profile # optional alias completion\n</code></pre> <p>or manually add these lines to your <code>~/.bash_profile</code>:</p> <pre><code>source ~/.docker/completion/docker\ncomplete -F _docker d # optional alias completion\n</code></pre> <p>Reload your shell:</p> <pre><code>source ~/.aliases\nsource ~/.bash_profile\n</code></pre> <p>You can now type:</p> <pre><code>docker &lt;TAB&gt;\nd &lt;TAB&gt;\n</code></pre> <p>and see available commands.</p>"},{"location":"shell/bash-completion/#kubectl-bash-completion","title":"kubectl Bash Completion","text":"<p>Add alias <code>k</code> for <code>kubectl</code> in your <code>~/.aliases</code> file:</p> <pre><code>alias k=\"kubectl\"\n</code></pre> <p>Source the completion script in your <code>~/.bash_profile</code>:</p> <pre><code>echo 'source /usr/local/opt/kubernetes-cli/etc/bash_completion.d/kubectl' &gt;&gt; ~/.bash_profile\n#echo 'source &lt;(kubectl completion bash)' &gt;&gt; ~/.bash_profile # optional for dynamic completion\necho 'complete -F __start_kubectl k' &gt;&gt; ~/.bash_profile # optional alias completion\n</code></pre> <p>or manually add these lines to your <code>~/.bash_profile</code>:</p> <pre><code>source /usr/local/opt/kubernetes-cli/etc/bash_completion.d/kubectl\n#source &lt;(kubectl completion bash) # optional for dynamic completion\ncomplete -F __start_kubectl k # optional alias completion\n</code></pre> <p>Reload your shell:</p> <pre><code>source ~/.aliases\nsource ~/.bash_profile\n</code></pre> <p>You can now type:</p> <pre><code>kubectl &lt;TAB&gt;\nk &lt;TAB&gt;\n</code></pre> <p>and see available commands.</p>"},{"location":"shell/bash-completion/#multipass-bash-completion","title":"Multipass Bash Completion","text":"<p>Add alias <code>mp</code> for <code>multipass</code> in your <code>~/.aliases</code> file:</p> <pre><code>alias mp=\"multipass\"\n</code></pre> <p>Source the completion script in your <code>~/.bash_profile</code>:</p> <pre><code>echo 'source \"/Library/Application Support/com.canonical.multipass/Resources/completions/bash/multipass\"' &gt;&gt; ~/.bash_profile\necho 'complete -F _multipass_complete mp' &gt;&gt; ~/.bash_profile # optional alias completion\n</code></pre> <p>or manually add these lines to your <code>~/.bash_profile</code>:</p> <pre><code>if [ -f \"/Library/Application Support/com.canonical.multipass/Resources/completions/bash/multipass\" ]; then\n    source \"/Library/Application Support/com.canonical.multipass/Resources/completions/bash/multipass\"\n    complete -F _multipass_complete mp\nfi\n</code></pre> <p>Reload your shell:</p> <pre><code>source ~/.aliases\nsource ~/.bash_profile\n</code></pre> <p>You can now type:</p> <pre><code>multipass &lt;TAB&gt;\nmp &lt;TAB&gt;\n</code></pre> <p>and see available commands.</p>"},{"location":"shell/bash-completion/#conclusion","title":"Conclusion","text":"<p>Bash completion can dramatically speed up your workflow when working with CLI tools. With these configurations, you now have tab-completion support for:</p> <ul> <li>Git</li> <li>Docker</li> <li>kubectl</li> <li>Multipass</li> </ul> <p>No more typing long command names or guessing available flags\u2014just hit Tab and let bash do the work.</p>"},{"location":"shell/shell-commands/","title":"Shell Commands","text":"<p>This document provides an overview of commonly used shell commands for developers, along with descriptions and practical usage examples.</p>"},{"location":"shell/shell-commands/#watch","title":"watch","text":"<p>Runs a command repeatedly, showing its output and errors. Useful for monitoring changes in real time. If the command is not found, install it by using <code>brew install watch</code>.</p> <p>Usage: <code>watch ls -l</code></p> <p><code>watch -n 5 ls -l</code></p>"},{"location":"shell/shell-commands/#grep","title":"grep","text":"<p>Searches for a pattern within files or input.</p> <p>Usage: <code>grep \"error\" /var/log/syslog</code></p>"},{"location":"shell/shell-commands/#tail","title":"tail","text":"<p>Shows the last part of a file.</p> <p>Usage: <code>tail -f /var/log/syslog</code></p>"},{"location":"shell/shell-commands/#ps","title":"ps","text":"<p>Displays information about running processes.</p> <p>Usage: <code>ps -u $(whoami)</code></p>"},{"location":"shell/shell-commands/#top","title":"top","text":"<p>Interactive process viewer showing system resource usage.</p> <p>Usage: <code>top</code></p>"},{"location":"shell/shell-commands/#htop","title":"htop","text":"<p>An enhanced, interactive process viewer (must be installed separately).</p> <p>Usage: <code>htop</code></p>"},{"location":"shell/shell-commands/#chmod","title":"chmod","text":"<p>Changes file permissions.</p> <p>Usage: <code>chmod +x script.sh</code></p>"},{"location":"shell/shell-commands/#chown","title":"chown","text":"<p>Changes file owner and group.</p> <p>Usage: <code>chown user:group file.txt</code></p>"},{"location":"shell/shell-commands/#ssh","title":"ssh","text":"<p>Secure shell for logging into a remote machine.</p> <p>Usage: <code>ssh user@host</code></p>"},{"location":"shell/shell-commands/#scp","title":"scp","text":"<p>Securely copies files between hosts.</p> <p>Usage: <code>scp file.txt user@remote:/path/to/destination</code></p>"},{"location":"shell/shell-commands/#rsync","title":"rsync","text":"<p>Efficiently syncs files/directories between locations.</p> <p>Usage: <code>rsync -avz /local/dir user@remote:/remote/dir</code></p>"},{"location":"shell/shell-commands/#df","title":"df","text":"<p>Shows disk space usage.</p> <p>Usage: <code>df -h</code></p>"},{"location":"shell/shell-commands/#du","title":"du","text":"<p>Shows disk usage of files and directories.</p> <p>Usage: <code>du -h --max-depth=1</code></p>"},{"location":"shell/shell-commands/#find","title":"find","text":"<p>Searches for files and directories matching criteria.</p> <p>Usage: <code>find . -name \"*.log\"</code></p>"},{"location":"shell/shell-commands/#sed","title":"sed","text":"<p>Stream editor for filtering and transforming text.</p> <p>Usage: <code>sed 's/old/new/g' file.txt</code></p>"},{"location":"shell/shell-commands/#awk","title":"awk","text":"<p>Powerful text processing and pattern scanning language.</p> <p>Usage: <code>awk '{print $1}' file.txt</code></p>"},{"location":"shell/shell-commands/#tar","title":"tar","text":"<p>Archives and extracts files.</p> <p>Usage:</p> <ul> <li>Create archive: <code>tar -cvf archive.tar folder/</code></li> <li>Extract archive: <code>tar -xvf archive.tar</code></li> </ul>"},{"location":"shell/shell-commands/#zip-unzip","title":"zip / unzip","text":"<p>Compress and decompress files.</p> <p>Usage: <code>zip archive.zip file1 file2</code> <code>unzip archive.zip</code></p>"},{"location":"shell/shell-commands/#systemctl","title":"systemctl","text":"<p>Controls systemd system and service manager.</p> <p>Usage: <code>systemctl status nginx</code> <code>systemctl restart nginx</code></p>"},{"location":"shell/shell-commands/#journalctl","title":"journalctl","text":"<p>Views systemd logs.</p> <p>Usage: <code>journalctl -u nginx.service</code></p>"},{"location":"shell/shell-commands/#whoami","title":"whoami","text":"<p>Shows current logged in user.</p> <p>Usage: <code>whoami</code></p>"},{"location":"shell/shell-commands/#history","title":"history","text":"<p>Shows command history.</p> <p>Usage: <code>history</code></p>"},{"location":"shell/shell-commands/#clear","title":"clear","text":"<p>Clears the terminal screen.</p> <p>Usage: <code>clear</code></p>"},{"location":"shell/shell-commands/#env","title":"env","text":"<p>Shows environment variables.</p> <p>Usage: <code>env</code></p>"},{"location":"shell/shell-commands/#export","title":"export","text":"<p>Sets environment variables.</p> <p>Usage: <code>export PATH=$PATH:/new/path</code></p>"},{"location":"shell/shell-commands/#alias","title":"alias","text":"<p>Creates command shortcuts.</p> <p>Usage: <code>alias ll='ls -la'</code></p>"},{"location":"shell/shell-commands/#lsof","title":"lsof","text":"<p><code>lsof</code> (List Open Files) lists information about files opened by processes, useful for finding which process is using a specific file or network port.</p> <p>Usage:</p> <pre><code>lsof -i tcp:3000\nlsof -i :8000\n</code></pre>"},{"location":"shell/shell-commands/#kill","title":"kill","text":"<p>Terminates processes by PID.</p> <p>Usage:</p> <pre><code>kill 1234\nkill -9 &lt;PID&gt; # Force kill\n</code></pre>"},{"location":"shell/shell-commands/#pkill","title":"pkill","text":"<p>Kills processes by name.</p> <p>Usage: <code>pkill nginx</code></p>"},{"location":"shell/shell-commands/#sleep","title":"sleep","text":"<p>Pauses execution for specified seconds.</p> <p>Usage: <code>sleep 5</code></p>"},{"location":"shell/shell-commands/#date","title":"date","text":"<p>Shows or sets the system date/time.</p> <p>Usage: <code>date</code></p>"},{"location":"shell/shell-commands/#printenv","title":"printenv","text":"<p>Displays the current environment variables.</p> <p>Usage: <code>printenv</code></p>"},{"location":"shell/shell-commands/#pwd","title":"pwd","text":"<p><code>pwd</code> (Print Working Directory) displays the current directory you are in within the terminal.</p> <p>Usage: <code>pwd</code></p>"},{"location":"shell/shell-commands/#arch","title":"arch","text":"<p><code>arch</code> prints the architecture of the machine you are currently using.</p> <p>Usage: <code>arch</code></p> <p>Example output: <code>x86_64</code> or <code>arm64</code></p>"},{"location":"shell/shell-commands/#uname","title":"uname","text":"<p>Displays system information.</p> <p>Usage: <code>uname -a</code></p> <p><code>uname -m</code> # Displays machine hardware name like <code>x86_64</code> or <code>arm64</code></p>"},{"location":"shell/shell-commands/#which","title":"which","text":"<p><code>which</code> shows the full path of the executable that would run when you type the command.</p> <p>Usage: <code>which brew</code></p> <p>Example output: <code>/usr/local/bin/brew</code></p>"},{"location":"shell/shell-commands/#notes","title":"Notes","text":"<ul> <li>Most commands support many options and flags; check their man pages (e.g., <code>man grep</code>) for details.</li> <li>Some tools like <code>htop</code> or <code>rsync</code> may require installation depending on your operating system or shell environment.</li> </ul>"},{"location":"shell/shell-network-commands/","title":"Shell Network Commands","text":"<p>This document provides an overview of commonly used shell network commands for developers, along with descriptions and practical usage examples.</p>"},{"location":"shell/shell-network-commands/#hostname","title":"hostname","text":"<p>Shows or sets the system's hostname.</p> <p>Usage: <code>hostname</code></p>"},{"location":"shell/shell-network-commands/#ping","title":"ping","text":"<p>Checks if a hostname resolves to an IP and if the host is reachable. Sends ICMP echo requests to test network connectivity to a host.</p> <p>Usage: <code>ping google.com</code></p> <p>\u27a1\ufe0f Shows whether <code>google.com</code> points to the expected IP.</p>"},{"location":"shell/shell-network-commands/#dig","title":"dig","text":"<p>DNS lookup utility, more flexible than <code>nslookup</code>. Queries DNS resolution for a hostname. This command is very useful for debugging DNS issues and checking DNS propagation.</p> <p>Usage: <code>dig example.com</code></p> <p><code>dig example.com @111.11.11.11</code> # Querying a specific DNS server</p>"},{"location":"shell/shell-network-commands/#nslookup","title":"nslookup","text":"<p>Queries DNS servers to obtain domain name or IP address mapping. Alternative to dig for DNS lookup.</p> <p>Usage: <code>nslookup example.com</code></p>"},{"location":"shell/shell-network-commands/#telnet","title":"telnet","text":"<p>Tests if a specific hostname and port are reachable.</p> <p>Usage: <code>telnet example.com 8080</code></p>"},{"location":"shell/shell-network-commands/#ifconfig","title":"ifconfig","text":"<p>Displays or configures network interfaces (deprecated in favor of <code>ip</code> command).</p> <p>Usage: <code>ifconfig</code></p>"},{"location":"shell/shell-network-commands/#curl","title":"curl","text":"<p>Transfers data from or to a server, supporting multiple protocols.</p> <p>Usage: <code>curl https://example.com</code></p>"},{"location":"shell/shell-network-commands/#wget","title":"wget","text":"<p>Non-interactive network downloader, useful for downloading files from the web.</p> <p>Usage: <code>wget https://example.com/file.zip</code></p>"},{"location":"shell/shell-network-commands/#ip","title":"ip","text":"<p>Modern tool to show/manipulate routing, devices, policy routing, and tunnels.</p> <p>Usage: <code>ip addr show</code></p>"},{"location":"shell/shell-network-commands/#traceroute","title":"traceroute","text":"<p>Shows the path packets take to reach a host.</p> <p>Usage: <code>traceroute google.com</code></p>"},{"location":"shell/shell-network-commands/#netstat","title":"netstat","text":"<p>Displays network connections, routing tables, interface statistics, etc.</p> <p>Usage: <code>netstat -tuln</code></p>"},{"location":"slack/slack-github-workflows/","title":"Slack Notifications via GitHub Actions","text":"<p>This document contains example GitHub Actions workflows that send notifications to Slack channels using <code>slackapi/slack-github-action@v1.27.0</code>.</p>"},{"location":"slack/slack-github-workflows/#1-notify-slack-on-new-discussion","title":"1. Notify Slack on New Discussion","text":"<p>This workflow triggers when a new discussion is created in the repository and sends a formatted message to a Slack channel.</p> discussion-notify.yml <pre><code>name: Notify Slack on New Discussion\n\non:\n  discussion:\n    types: [ created ]\n\njobs:\n  notify:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Send Notification To Slack Channel\n        uses: slackapi/slack-github-action@v1.27.0\n        with:\n          payload: '{\n            \"attachments\": [\n              {\n                \"color\": \"#36C5F0\",\n                \"blocks\": [\n                  {\n                    \"type\": \"section\",\n                    \"text\": {\n                      \"type\": \"mrkdwn\",\n                      \"text\": \":speech_balloon: *New Discussion Created*:\\n*&lt;${{ github.event.discussion.html_url }}|${{ github.event.discussion.title }}&gt;*\"\n                    }\n                  }\n                ]\n              }\n            ]\n          }'\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_DEVELOPERS_WEBHOOK }}\n          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK\n</code></pre>"},{"location":"slack/slack-github-workflows/#2-notify-slack-to-remind-session","title":"2. Notify Slack to Remind Session","text":"<p>This workflow is triggered manually and sends a reminder about an upcoming Engineering Session.</p> session-reminder-notify.yml <pre><code>name: Notify Slack to Remind Session\n\non:\n  workflow_dispatch:\n    inputs:\n      topic:\n        description: 'Topic'\n        required: true\n        type: string\n      meet-link:\n        description: 'Meet Link'\n        required: true\n        type: string\n      date:\n        description: 'Date (e.g. 19.04.2025)'\n        required: false\n      time:\n        description: 'Time (e.g. 14:00 - 15:00)'\n        required: false\n        default: '14:00 - 15:00'\n      session-details-link:\n        description: 'Session details Slack link'\n        required: false\n        type: string\n      test:\n        description: 'Is test notification?'\n        required: true\n        type: boolean\n        default: true\n\njobs:\n  notify:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Set webhook based on test input\n        id: set-webhook\n        run: |\n          if [ \"${{ inputs.test }}\" = \"true\" ]; then\n            echo \"url=${{ secrets.SLACK_PERSONAL_TEST_WEBHOOK }}\" &gt;&gt; $GITHUB_OUTPUT\n          else\n            echo \"url=${{ secrets.SLACK_DEVELOPERS_WEBHOOK }}\" &gt;&gt; $GITHUB_OUTPUT\n          fi\n      - name: Set date\n        id: set-date\n        run: |\n          if [ -z \"${{ inputs.date }}\" ]; then\n            TODAY=$(TZ=Europe/Istanbul date +'%d.%m.%Y')\n            echo \"date=$TODAY\" &gt;&gt; $GITHUB_OUTPUT\n          else\n            echo \"date=${{ inputs.date }}\" &gt;&gt; $GITHUB_OUTPUT\n          fi\n      - name: Prepare session details text\n        id: set-details\n        run: |\n          if [ -n \"${{ inputs.session-details-link }}\" ]; then\n            echo \"details_text=:information_source: *Session Details:* &lt;${{ inputs.session-details-link }}|Click here to view session details&gt;\" &gt;&gt; $GITHUB_OUTPUT\n          else\n            echo \"details_text=\" &gt;&gt; $GITHUB_OUTPUT\n          fi\n      - name: Send Notification To Slack Channel\n        uses: slackapi/slack-github-action@v1.27.0\n        with:\n          payload: '{\n            \"unfurl_links\": false,\n            \"unfurl_media\": false,\n            \"blocks\": [\n                {\n                    \"type\": \"header\",\n                    \"text\": {\n                        \"type\": \"plain_text\",\n                        \"text\": \"\ud83c\udf1f Friendly Reminder: Upcoming Engineering Session :coffee:\",\n                        \"emoji\": true\n                    }\n                },\n                {\n                    \"type\": \"section\",\n                    \"text\": {\n                        \"type\": \"mrkdwn\",\n                        \"text\": \"Hi Friends,\\n\\nJust a quick reminder about our upcoming *Engineering Session*:\\n\\n*\ud83d\udccc Topic:* ${{ inputs.topic }}\\n*\ud83d\uddd3\ufe0f Date:* ${{ steps.set-date.outputs.date }}\\n*\u23f0 Time:* ${{ inputs.time }}\\n*\ud83d\udccd Link:* &lt;${{ inputs.meet-link }}|Click here to join the meeting&gt;\\n\\n${{ steps.set-details.outputs.details_text }}\\n\\nLooking forward to seeing you all there! \ud83d\ude0a\"\n                    }\n                }\n            ]\n        }'\n        env:\n          SLACK_WEBHOOK_URL: ${{ steps.set-webhook.outputs.url }}\n          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK\n</code></pre>"},{"location":"slack/slack-github-workflows/#3-notify-slack-for-kudos-session","title":"3. Notify Slack for Kudos Session","text":"<p>This workflow is triggered manually and sends a message to Slack to celebrate and thank presenters for an Engineering Session.</p> session-kudos-notify.yml <pre><code>name: Notify Slack to Kudos Session\n\non:\n  workflow_dispatch:\n    inputs:\n      topic:\n        description: 'Topic'\n        required: true\n        type: string\n      slack-member-ids:\n        description: 'Slack Member IDs (comma-separated, e.g. U123ABCD,U456DEFG)'\n        required: true\n        type: string\n      session-number:\n        description: 'Session Number (e.g. 15)'\n        required: true\n        type: string\n      test:\n        description: 'Is test notification?'\n        required: true\n        type: boolean\n        default: true\n\njobs:\n  notify:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Set webhook based on test input\n        id: set-webhook\n        run: |\n          if [ \"${{ inputs.test }}\" = \"true\" ]; then\n            echo \"url=${{ secrets.SLACK_PERSONAL_TEST_WEBHOOK }}\" &gt;&gt; $GITHUB_OUTPUT\n          else\n            echo \"url=${{ secrets.SLACK_DEVELOPERS_WEBHOOK }}\" &gt;&gt; $GITHUB_OUTPUT\n          fi\n      - name: Parse speaker list\n        id: parse-speakers\n        run: |\n          speakers=\"${{ inputs.slack-member-ids }}\"\n          IFS=',' read -ra ADDR &lt;&lt;&lt; \"$speakers\"\n          OUTPUT=\"\"\n\n          for id in \"${ADDR[@]}\"; do\n            OUTPUT=\"$OUTPUT\\\\n*\ud83d\udde3\ufe0f &lt;@$id&gt;* :crown:\\n\"\n          done\n\n          echo \"formatted_speakers=$OUTPUT\" &gt;&gt; $GITHUB_OUTPUT\n      - name: Send Notification To Slack Channel\n        uses: slackapi/slack-github-action@v1.27.0\n        with:\n          payload: '{\n          \"unfurl_links\": false,\n          \"unfurl_media\": false,\n          \"blocks\": [\n            {\n              \"type\": \"header\",\n              \"text\": {\n                \"type\": \"plain_text\",\n                \"text\": \"\ud83d\udc4f Great Job, Friends! \ud83c\udf89\",\n                \"emoji\": true\n              }\n            },\n            {\n              \"type\": \"section\",\n              \"text\": {\n                \"type\": \"mrkdwn\",\n                \"text\": \"A huge thank you to everyone for your time and contributions in today\u2019s Engineering Session :coffee:! Special shoutout to the amazing presenter(s) who did an outstanding job:\\n${{ steps.parse-speakers.outputs.formatted_speakers }}\\n\\n for the *${{ inputs.topic }}* presentation \ud83d\udc4f\"\n              }\n            },\n            {\n              \"type\": \"section\",\n              \"text\": {\n                \"type\": \"mrkdwn\",\n                \"text\": \" #\ufe0f\u20e3 Please join the #engineering-sessions channel and give a suggestion for the next topics. Looking forward to the next one! \ud83d\ude80\"\n              }\n            },\n            {\n              \"type\": \"section\",\n              \"text\": {\n                \"type\": \"mrkdwn\",\n                \"text\": \"*\ud83d\udcc2 You can check out all previous session materials right &lt;https://yourorg.atlassian.net/wiki/spaces/EN/pages/123456/Previous+Sessions|here.&gt;*\"\n              }\n            },\n            {\n              \"type\": \"divider\"\n            },\n            {\n              \"type\": \"context\",\n              \"elements\": [\n                {\n                  \"type\": \"plain_text\",\n                  \"text\": \"Thanks again, everyone! This was our ${{ inputs.session-number }}. :coffee: session\u2014keep up the fantastic work! \ud83d\udcaa\",\n                  \"emoji\": true\n                }\n              ]\n            }\n          ]\n        }'\n        env:\n          SLACK_WEBHOOK_URL: ${{ steps.set-webhook.outputs.url }}\n          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK\n</code></pre>"},{"location":"slack/slack-github-workflows/#notes","title":"Notes","text":"<ul> <li>All workflows require a valid Slack Incoming Webhook URL stored in GitHub Secrets.</li> <li>Use test webhooks for development to avoid spamming real channels.</li> <li>Customize the payload structure for your team's formatting preferences.</li> <li>The action version used here is <code>slackapi/slack-github-action@v1.27.0</code>.</li> </ul>"},{"location":"slack/slack-message/","title":"Slack Message","text":"<p>This document provides examples and guidelines for building Slack messages using Block Kit Builder and sending messages via Incoming Webhooks and Slack API.</p>"},{"location":"slack/slack-message/#slack-block-kit-builder","title":"Slack Block Kit Builder","text":"<p>You can use the Slack Block Kit Builder app to visually design and test your Slack message layouts: https://app.slack.com/block-kit-builder</p> <p>Try changing properties like <code>color</code> in attachments or customizing blocks for your needs.</p>"},{"location":"slack/slack-message/#incoming-webhooks","title":"Incoming Webhooks","text":"<p>Slack Incoming Webhooks allow you to send messages to Slack channels via HTTP requests. You need to create an app and enable Incoming Webhooks in your Slack workspace: https://api.slack.com/apps</p> <p>Example Incoming Webhook URL: <code>https://hooks.slack.com/services/XXXXXXXXX/XXXXXXXXX/XXXXXXXXXXXXXXXXXXXX</code></p>"},{"location":"slack/slack-message/#example-slack-messages-using-block-kit-json","title":"Example Slack Messages Using Block Kit JSON","text":""},{"location":"slack/slack-message/#reminder-message-start-of-event","title":"Reminder Message (Start of Event)","text":"<pre><code>{\n  \"blocks\": [\n    {\n      \"type\": \"header\",\n      \"text\": {\n        \"type\": \"plain_text\",\n        \"text\": \"\ud83c\udf1f Friendly Reminder: Upcoming Team Meeting :rocket:\",\n        \"emoji\": true\n      }\n    },\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"Hi Team,\\n\\nJust a quick reminder about our upcoming *Team Meeting*:\\n\\n*\ud83d\udccc Topic:* Efficient Build System Updates\\n*\ud83d\uddd3\ufe0f Date:* 22.11.2024\\n*\u23f0 Time:* 15:00-16:00\\n*\ud83d\udccd Link:* &lt;https://meeting-link.example.com|Click here to join the meeting&gt;\\n\\nLooking forward to seeing you all there! \ud83d\ude0a\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"slack/slack-message/#thank-you-message-end-of-event","title":"Thank You Message (End of Event)","text":"<pre><code>{\n  \"blocks\": [\n    {\n      \"type\": \"header\",\n      \"text\": {\n        \"type\": \"plain_text\",\n        \"text\": \"\ud83d\udc4f Great Job, Team! \ud83c\udf89\",\n        \"emoji\": true\n      }\n    },\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"Thank you everyone for your participation in today\u2019s Team Meeting :rocket:! Special thanks to our presenters for their excellent work:\\n\\n*\ud83d\udde3\ufe0f Presenter 1* - for the *Build System Overview* presentation \ud83d\udc4f\\n*\ud83d\udde3\ufe0f Presenter 2* - for the *Automation Tools* presentation \ud83d\udc4f\\n\\nPlease share your topic ideas in the #team-announcements channel. Looking forward to the next meeting! \ud83d\ude80\"\n      }\n    },\n    {\n      \"type\": \"divider\"\n    },\n    {\n      \"type\": \"context\",\n      \"elements\": [\n        {\n          \"type\": \"plain_text\",\n          \"text\": \"Thanks again, everyone! Keep up the fantastic work! \ud83d\udcaa\ud83c\udffc\",\n          \"emoji\": true\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"slack/slack-message/#example-with-user-mentions","title":"Example with User Mentions","text":"<p>In Slack Block Kit, you can mention users by their Slack User ID:</p> <pre><code>{\n  \"type\": \"section\",\n  \"text\": {\n    \"type\": \"mrkdwn\",\n    \"text\": \"Special shoutout to our presenter &lt;@U12345678&gt; for an amazing presentation! \ud83c\udf89\"\n  }\n}\n</code></pre> <p>Replace <code>U12345678</code> with the actual Slack User ID.</p>"},{"location":"slack/slack-message/#example-user-joining-request-message","title":"Example: User Joining Request Message","text":"<pre><code>{\n  \"blocks\": [\n    {\n      \"type\": \"header\",\n      \"text\": {\n        \"type\": \"plain_text\",\n        \"text\": \"User Request to Join Channel\",\n        \"emoji\": true\n      }\n    },\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"Hello @here, &lt;@U12345678&gt; would like to join this private channel but cannot. Could someone please add them?\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"slack/slack-message/#sending-messages-using-curl-and-incoming-webhooks","title":"Sending Messages Using <code>curl</code> and Incoming Webhooks","text":"<p>Replace <code>YOUR_WEBHOOK_URL</code> with your actual webhook URL.</p>"},{"location":"slack/slack-message/#send-reminder-message","title":"Send Reminder Message","text":"<pre><code>curl -X POST -H 'Content-type: application/json' --data '{\n  \"blocks\": [\n    {\n      \"type\": \"header\",\n      \"text\": {\n        \"type\": \"plain_text\",\n        \"text\": \"\ud83c\udf1f Friendly Reminder: Upcoming Team Meeting :rocket:\",\n        \"emoji\": true\n      }\n    },\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"Hi Team,\\n\\nJust a quick reminder about our upcoming *Team Meeting*:\\n\\n*\ud83d\udccc Topic:* Efficient Build System Updates\\n*\ud83d\uddd3\ufe0f Date:* 22.11.2024\\n*\u23f0 Time:* 15:00-16:00\\n*\ud83d\udccd Link:* &lt;https://meeting-link.example.com|Join here&gt;\\n\\nLooking forward to seeing you all there! \ud83d\ude0a\"\n      }\n    }\n  ]\n}' https://hooks.slack.com/services/YOUR_WEBHOOK_URL\n</code></pre>"},{"location":"slack/slack-message/#send-thank-you-message","title":"Send Thank You Message","text":"<pre><code>curl -X POST -H 'Content-type: application/json' --data '{\n  \"blocks\": [\n    {\n      \"type\": \"header\",\n      \"text\": {\n        \"type\": \"plain_text\",\n        \"text\": \"\ud83d\udc4f Great Job, Team! \ud83c\udf89\",\n        \"emoji\": true\n      }\n    },\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"Thank you everyone for your participation in today\u2019s Team Meeting :rocket:! Special thanks to our presenters for their excellent work:\\n\\n*\ud83d\udde3\ufe0f Presenter 1* - for the *Build System Overview* presentation \ud83d\udc4f\\n*\ud83d\udde3\ufe0f Presenter 2* - for the *Automation Tools* presentation \ud83d\udc4f\\n\\nPlease share your topic ideas in the #team-announcements channel. Looking forward to the next meeting! \ud83d\ude80\"\n      }\n    },\n    {\n      \"type\": \"divider\"\n    },\n    {\n      \"type\": \"context\",\n      \"elements\": [\n        {\n          \"type\": \"plain_text\",\n          \"text\": \"Thanks again, everyone! Keep up the fantastic work! \ud83d\udcaa\ud83c\udffc\",\n          \"emoji\": true\n        }\n      ]\n    }\n  ]\n}' https://hooks.slack.com/services/YOUR_WEBHOOK_URL\n</code></pre>"},{"location":"slack/slack-message/#emoji-customization","title":"Emoji Customization","text":"<p>You can use custom emojis in your messages. Manage your workspace emojis here: <code>https://YOURWORKSPACE.slack.com/customize/emoji</code></p> <p>Use emojis by their shortcodes, for example: <code>:rocket:</code>, <code>:star:</code>, <code>:heart:</code>.</p>"},{"location":"slack/slack-message/#helpful-links","title":"Helpful Links","text":"<ul> <li>Slack Block Kit Builder: Slack Block Kit Builder</li> <li>Slack API Incoming Webhooks: Slack Webhooks</li> <li>Custom Emojis: <code>https://YOURWORKSPACE.slack.com/customize/emoji</code></li> </ul>"},{"location":"slack/slack-reminder/","title":"Slack Reminder","text":"<p>Slack reminders allow you to schedule notifications for yourself, specific channels, or groups at specific times or on a recurring basis. They are useful for meeting reminders, daily check-ins, and recurring tasks.</p>"},{"location":"slack/slack-reminder/#syntax","title":"Syntax","text":"<pre><code>/remind [@someone or #channel] \"[message]\" [time or recurrence]\n</code></pre> <ul> <li><code>@someone</code> \u2192 Sends the reminder to a specific person.</li> <li><code>#channel</code> \u2192 Sends the reminder to an entire channel.</li> <li><code>[message]</code> \u2192 The text to display when the reminder triggers.</li> <li><code>[time or recurrence]</code> \u2192 When the reminder should occur (e.g., \"at 9am\", \"every Monday\", \"tomorrow\", \"in 10 minutes\").</li> </ul>"},{"location":"slack/slack-reminder/#examples","title":"Examples","text":""},{"location":"slack/slack-reminder/#1-remind-yourself-once","title":"1. Remind Yourself Once","text":"<pre><code>/remind me \"Check project status updates\" at 3pm today\n</code></pre>"},{"location":"slack/slack-reminder/#2-remind-a-channel-once","title":"2. Remind a Channel Once","text":"<pre><code>/remind #general \"Team meeting starts in 10 minutes\" at 2:50pm\n</code></pre>"},{"location":"slack/slack-reminder/#3-daily-recurring-reminder","title":"3. Daily Recurring Reminder","text":"<pre><code>/remind me \"Read daily stand-up notes\" every weekday at 9am\n</code></pre>"},{"location":"slack/slack-reminder/#4-weekly-recurring-reminder","title":"4. Weekly Recurring Reminder","text":"<pre><code>/remind #project-team \"Weekly sync meeting starts now\" every Monday at 10am\n</code></pre>"},{"location":"slack/slack-reminder/#5-every-few-weeks","title":"5. Every Few Weeks","text":"<pre><code>/remind #design-team \"Submit design review notes\" every 2 weeks on Monday at 4pm\n</code></pre>"},{"location":"slack/slack-reminder/#6-other-examples","title":"6. Other Examples","text":"<pre><code>-- Weekly team meeting (every 2 weeks)\n/remind #team \"@here Please add your items to the meeting agenda.\" at 9am on Monday, December 2, 2024 every 2 weeks\n\n-- Another meeting time variation\n/remind #team \"@here Don't forget to review the agenda before the meeting.\" at 3pm on Monday, December 2, 2024 every 2 weeks\n\n-- Morning motivational reminder\n/remind @username every weekday at 7:30am \"Read your daily motivation rules before starting the day!\"\n\n-- Early daily start\n/remind @username every weekday at 6:00am \"Good morning! Let's start the day with a positive mindset.\"\n\n-- Pre-event technical check\n/remind @username every Friday at 10:15am \"Check audio and video permissions before the engineering session.\"\n\n-- Event reminder\n/remind @username every Friday at 2:45pm \"Friendly reminder: send Slack notification for the engineering session.\"\n</code></pre>"},{"location":"slack/slack-reminder/#tips","title":"Tips","text":"<ul> <li>Quotes (<code>\" \"</code>) around the reminder message are recommended, especially if it contains spaces.</li> <li>You can use <code>me</code> instead of your username to send reminders to yourself.</li> <li>Use channel names like <code>#general</code> or <code>#team-meeting</code> to notify everyone in that channel.</li> <li>Common recurrence formats:<ul> <li><code>every day at [time]</code></li> <li><code>every weekday at [time]</code></li> <li><code>every [number] weeks on [day] at [time]</code></li> <li><code>tomorrow at [time]</code></li> <li><code>in [number] minutes/hours</code></li> </ul> </li> </ul>"},{"location":"slack/slack-reminder/#managing-reminders","title":"Managing Reminders","text":"<ul> <li>To see your upcoming reminders:</li> </ul> <pre><code>/remind list\n</code></pre> <ul> <li>To delete a reminder:<ul> <li>Use <code>/remind list</code> to find it and then select Delete.</li> </ul> </li> </ul>"},{"location":"slack/slack-reminder/#quick-reference-table","title":"Quick Reference Table","text":"Command Example Description <code>/remind me \"Submit timesheet\" every Friday at 5pm</code> Reminds you every Friday to submit your timesheet <code>/remind #marketing \"Campaign kickoff call\" at 11am tomorrow</code> Notifies the marketing channel about the kickoff <code>/remind me \"Stretch break\" every hour</code> Sends you a stretch reminder every hour <code>/remind #support-team \"Review support tickets\" every weekday at 9:30am</code> Daily ticket review reminder for the support team"},{"location":"slack/slack-user-group-creation/","title":"Slack User Group Creation","text":""},{"location":"slack/slack-user-group-creation/#creating-slack-user-groups-via-api","title":"Creating Slack User Groups via API","text":"<p>You can create user groups in Slack to mention multiple users at once efficiently.</p>"},{"location":"slack/slack-user-group-creation/#example-curl-request-to-create-a-user-group","title":"Example <code>curl</code> request to create a user group","text":"<pre><code>curl -X POST https://slack.com/api/usergroups.create \\\n-H \"Authorization: Bearer xoxb-your-bot-token\" \\\n-H \"Content-Type: application/json; charset=utf-8\" \\\n-d '{\n  \"name\": \"Test User Group\",\n  \"handle\": \"test-user-group\",\n  \"description\": \"Test user group\"\n}'\n</code></pre> <p>Replace <code>xoxb-your-bot-token</code> with your bot user OAuth token with <code>usergroups:write</code> scope.</p>"},{"location":"slack/slack-user-group-creation/#automation-with-makefile-target-and-bash-script","title":"Automation with Makefile target and Bash script","text":"<p>You can automate creating user groups and connecting them to channels using a Makefile target and a shell script.</p> <p>Makefile target example:</p> <pre><code>create-slack-user-groups: ## Create slack user groups and connect to channel\n    @bash .make/scripts/create-slack-user-groups.sh\n</code></pre> <p>Bash script example:</p> .make/scripts/create-slack-user-groups.sh <pre><code>#!/bin/bash\n\n# Slack OAuth Token\nSLACK_TOKEN=\"xoxb-XXXX-XXXX-XXX\"\n\n# User Group and Channel list\ndeclare -A TEAMS\nTEAMS=(\n  [\"team_name_1\"]=\"channel_name_1\"\n  [\"team_name_2\"]=\"channel_name_2\"\n)\n\n# API URLs\nCREATE_USERGROUP_URL=\"https://slack.com/api/usergroups.create\"\nUPDATE_USERGROUP_URL=\"https://slack.com/api/usergroups.update\"\nGET_CHANNELS_URL=\"https://slack.com/api/conversations.list\"\n\n# Function to get channel ID by name\nget_channel_id() {\n  local channel_name=$1\n  local response=$(curl -s -X GET \"$GET_CHANNELS_URL\" \\\n    -H \"Authorization: Bearer $SLACK_TOKEN\" \\\n    -H \"Content-Type: application/json; charset=utf-8\")\n\n  echo \"$response\" | jq -r --arg name \"$channel_name\" '.channels[] | select(.name == $name) | .id'\n}\n\n# Create User Groups and connect to channels\nfor team_name in \"${!TEAMS[@]}\"; do\n  channel_name=${TEAMS[$team_name]}\n\n  # Get channel id\n  channel_id=$(get_channel_id \"$channel_name\")\n  if [[ -z \"$channel_id\" ]]; then\n    echo \"Error: Channel not found -&gt; $channel_name\"\n    continue\n  fi\n\n  # Create User Group\n  create_response=$(curl -s -X POST \"$CREATE_USERGROUP_URL\" \\\n    -H \"Authorization: Bearer $SLACK_TOKEN\" \\\n    -H \"Content-Type: application/json; charset=utf-8\" \\\n    -d '{\n      \"name\": \"'\"$team_name\"'\",\n      \"handle\": \"'\"$team_name\"'\",\n      \"description\": \"Description for '\"$channel_name\"'\"\n    }')\n\n  usergroup_id=$(echo \"$create_response\" | jq -r '.usergroup.id')\n  if [[ \"$usergroup_id\" == \"null\" ]]; then\n    echo \"Error: User group can not be created -&gt; $team_name\"\n    echo \"Error detail: $(echo \"$create_response\" | jq -r '.error')\"\n    continue\n  fi\n\n  # Connect User Group to Channel\n  update_response=$(curl -s -X POST \"$UPDATE_USERGROUP_URL\" \\\n    -H \"Authorization: Bearer $SLACK_TOKEN\" \\\n    -H \"Content-Type: application/json; charset=utf-8\" \\\n    -d '{\n      \"usergroup\": \"'\"$usergroup_id\"'\",\n      \"channels\": \"'\"$channel_id\"'\"\n    }')\n\n  if [[ $(echo \"$update_response\" | jq -r '.ok') == \"true\" ]]; then\n    echo \"Success: $team_name is connected to $channel_name channel.\"\n  else\n    echo \"Error: Connecting user group failed -&gt; $team_name\"\n    echo \"Error detail: $(echo \"$update_response\" | jq -r '.error')\"\n  fi\ndone\n</code></pre>"},{"location":"slack/slack-user-group-creation/#notes","title":"Notes","text":"<ul> <li>Make sure your bot token has the required scopes (<code>usergroups:write</code> and <code>channels:read</code> or <code>conversations:read</code>).</li> <li>This script requires <code>jq</code> installed for JSON parsing.</li> <li>Customize the <code>TEAMS</code> associative array with your user group names and corresponding Slack channel names.</li> </ul>"},{"location":"terraform/terraform-cheatsheet/","title":"Terraform Cheatsheet","text":""},{"location":"terraform/terraform-cheatsheet/#terraform-basics","title":"Terraform Basics","text":"<p>Terraform is an infrastructure-as-code tool that allows you to provision and manage cloud resources declaratively. Key components include:</p> <ul> <li>Providers: Plugins that manage resources (e.g., <code>azurerm</code> for Azure, <code>aws</code> for AWS)</li> <li>Modules: Reusable Terraform configurations</li> <li>State: Maintains the current state of infrastructure</li> <li>Workspaces/Environments: Logical separation for different deployment stages (dev, prod, etc.)</li> </ul>"},{"location":"terraform/terraform-cheatsheet/#moving-or-renaming-terraform-resources","title":"Moving or Renaming Terraform Resources","text":"<p>When you rename a Terraform resource in code, Terraform may try to delete the old resource and create a new one instead of just updating its name. To avoid unnecessary destruction and downtime, you can use the  <code>terraform state mv</code> command.</p> <p>Example:</p> <pre><code># Move a resource in the state file from the old name to the new name\nterraform state mv \\\nmodule.old_module_name.aws_s3_bucket.example \\\nmodule.new_module_name.aws_s3_bucket.example\n</code></pre> <p>When to Use:</p> <ul> <li>Renaming a resource in <code>.tf</code> files.</li> <li>Moving a resource to another module.</li> <li>Refactoring module structures.</li> </ul> <p>Best Practices:</p> <ol> <li>Plan first \u2014 Run <code>terraform plan</code> before and after the move to ensure no unintended changes.</li> <li>Backup your state \u2014 Always back up <code>terraform.tfstate</code> before making state changes.</li> <li>Avoid in production without testing \u2014 Test the move in a non-production environment first.</li> </ol> <p>Reference:</p> <p>For more details, see: Terraform Rename Instead of Delete \u2013 Open Up The Cloud</p>"},{"location":"terraform/terraform-cheatsheet/#terraform-import","title":"Terraform Import","text":"<p>When managing existing infrastructure with Terraform, <code>terraform import</code> allows you to bring existing resources into Terraform's state.</p> <p>Example: Import an Azure Service Bus Subscription Rule</p> <pre><code>- name: \"Terraform Import\"\n  run: terraform import azurerm_servicebus_subscription_rule.example /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/microsoft.servicebus/namespaces/{namespace}/topics/{topic}/subscriptions/{subscription}/rules/{rule}\n  working-directory: ${{ github.workspace }}/terraform/environments/dev\n</code></pre> <p>Sample import commands:</p> <pre><code># List current state resources\nterraform state list\n\n# Remove resource from state if it no longer exists\nterraform state rm module.example.azurerm_dns_a_record.resource_name\n\n# Import an existing Azure DNS A record\nterraform import module.dns.azurerm_dns_a_record.resource_name /subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Network/dnszones/{zoneName}/A/{recordName}\n</code></pre> <p>Sample import file (Terraform DNS Record State Update):</p> Prerequisites  Before running the Terraform import commands, export the required Auth0 credentials in your shell profile (e.g., `~/.bash_profile` or `~/.zshrc`).   <pre><code>export AUTH0_DOMAIN=\"https://&lt;your-auth0-domain&gt;\"\nexport AUTH0_CLIENT_ID=\"&lt;your-client-id&gt;\"\nexport AUTH0_CLIENT_SECRET=\"&lt;your-client-secret&gt;\"\n</code></pre>   After adding these lines, reload your shell configuration:   <pre><code>source ~/.bash_profile\n# or\nsource ~/.zshrc\n</code></pre> import.sh <pre><code># Terraform DNS Record State Update\n\n## 1. View the initial state\n# This lists all resources currently in the Terraform state.\nterraform -chdir=.. state list\n\n## 2. Remove existing DNS record resources from the state\nterraform -chdir=.. state rm module.infrastructure_region.azurerm_dns_a_record.app_record_1\nterraform -chdir=.. state rm module.infrastructure_region.azurerm_dns_a_record.app_record_2\nterraform -chdir=.. state rm module.infrastructure_region.azurerm_dns_a_record.app_record_3\nterraform -chdir=.. state rm module.infrastructure_region.azurerm_dns_a_record.app_record_4\nterraform -chdir=.. state rm module.infrastructure_region.data.azurerm_dns_zone.zone\n\n## 3. Import new DNS record resources into the state\nterraform -chdir=.. import module.dns_region.azurerm_dns_a_record.app_record_1 /subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;dns-resource-group&gt;/providers/Microsoft.Network/dnszones/example.com/A/record-1\nterraform -chdir=.. import module.dns_region.azurerm_dns_a_record.app_record_2 /subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;dns-resource-group&gt;/providers/Microsoft.Network/dnszones/example.com/A/record-2\nterraform -chdir=.. import module.dns_region.azurerm_dns_a_record.app_record_3 /subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;dns-resource-group&gt;/providers/Microsoft.Network/dnszones/example.com/A/record-3\nterraform -chdir=.. import module.dns_region.azurerm_dns_a_record.app_record_4 /subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;dns-resource-group&gt;/providers/Microsoft.Network/dnszones/example.com/A/record-4\n\n## 4. View the final state\nterraform -chdir=.. state list\n</code></pre> <p>Sample import file (Terraform Auth0 Resource Import):</p> import.sh <pre><code># Terraform Auth0 Resource Import\n\n## 1. View the initial state\n# This lists all resources currently in the Terraform state.\nterraform -chdir=.. state list\n\n## 2. Import Auth0 resources\n\n### Servers\nterraform -chdir=.. import module.auth0-example-service.auth0_resource_server.rs[0] &lt;resource-server-id&gt;\n\n### Clients\nterraform -chdir=.. import module.auth0-example-app.auth0_client.application &lt;client-id&gt;\n\n### Client Grants\nterraform -chdir=.. import module.auth0-example-grant.auth0_client_grant.application-grant &lt;client-grant-id&gt;\n\n## 3. View the final state\nterraform -chdir=.. state list\n</code></pre>"},{"location":"terraform/terraform-cheatsheet/#terraform-state-management","title":"Terraform State Management","text":"<p>Managing the Terraform state file is critical for avoiding conflicts and ensuring proper tracking of resources.</p> <ul> <li>To manually edit state:</li> </ul> <pre><code># Pull state locally\nterraform state pull &gt; terraform.tfstate\n\n# Edit terraform.tfstate file carefully\n\n# Push edited state back\nterraform state push terraform.tfstate\n</code></pre> <ul> <li>To list resources in state:</li> </ul> <pre><code>terraform state list\n</code></pre> <ul> <li>To remove resources from state:</li> </ul> <pre><code>terraform state rm &lt;resource_address&gt;\n</code></pre>"},{"location":"terraform/terraform-cheatsheet/#terraform-aliases-and-providers","title":"Terraform Aliases and Providers","text":"<p>Terraform allows configuring multiple provider instances with aliases, useful for managing different subscriptions or environments.</p> <pre><code>provider \"azurerm\" {\n  version         = \"=2.33.0\"\n  alias           = \"development\"\n  subscription_id = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n  features {}\n}\n\ndata \"azurerm_dns_zone\" \"example\" {\n  provider            = azurerm.development\n  name                = \"example.dev\"\n  resource_group_name = \"dns-example-group\"\n}\n</code></pre>"},{"location":"terraform/terraform-cheatsheet/#terraform-console-examples","title":"Terraform Console Examples","text":"<p>Terraform Console is a useful interactive REPL to test expressions:</p> <pre><code>$ echo 'replace(\"example_name\", \"_\", \"-\")' | terraform console\nexample-name\n\n$ echo 'split(\",\", \"foo,bar,baz\")' | terraform console\n[\"foo\", \"bar\", \"baz\"]\n</code></pre>"},{"location":"terraform/terraform-cheatsheet/#flattening-nested-lists-in-terraform","title":"Flattening Nested Lists in Terraform","text":"<p>When working with nested lists or complex data structures in Terraform, you can use the <code>flatten()</code> function to produce a single-level list from multiple nested lists.</p> <p>Example: Flatten Database Roles:</p> <p>Suppose you have a list of databases, each with its own set of roles, and you want to create a flat list of all roles with their corresponding database details.</p> <pre><code>variable \"databases\" {\n  type = list(object({\n    name         = string\n    key_vault_id = string\n    roles = list(object({\n      name       = string\n      privileges = list(string)\n    }))\n  }))\n  description = \"Database settings\"\n  default     = []\n}\n\nlocal all_database_roles = flatten([\n  for database in local.databases : [\n    for role in database.roles : {\n      db_name      = database.name\n      key_vault_id = database.key_vault_id\n      name         = role.name\n      privileges   = role.privileges\n    }\n  ]\n])\n</code></pre> <p>How It Works:</p> <ol> <li>The outer <code>for</code> loop iterates over each database in <code>local.databases</code>.</li> <li>The inner <code>for</code> loop iterates over each role in <code>database.roles</code>.</li> <li>For each role, we construct an object containing some fields from the database and the role itself.</li> <li>The result of each inner loop is a list of role objects per database.</li> <li>The <code>flatten()</code> function merges all these lists into a single list of role objects.</li> </ol> <p>Reference:</p> <p>For more details, see the Terraform <code>flatten()</code> function documentation and  <code>setproduct()</code> function documentation.</p>"},{"location":"terraform/terraform-cheatsheet/#makefile-commands-for-terraform","title":"Makefile Commands for Terraform","text":"<p>Example Makefile snippets to standardize Terraform commands:</p> terraform.make <pre><code>MODULE_TERRAFORM=.\n\n##@ TERRAFORM\n\nterraform-init: ## Init tf, sample usage: make terraform-init env=dev\n    terraform -chdir=terraform/environments/$(env) init -upgrade\n\nterraform-format-check: ## Check formatting of tf files\n    terraform fmt -check -recursive\n\nterraform-format: ## Format tf files\n    terraform fmt -recursive\n\nterraform-validate: ## Validate tf files, sample usage: make terraform-validate env=dev\n    terraform -chdir=terraform/environments/$(env) validate\n\nterraform-state-list: ## List tf state, sample usage: make terraform-state-list env=dev\n    terraform -chdir=terraform/environments/$(env) state list\n\nterraform-plan: ## Plan tf, sample usage: make terraform-plan env=dev\n    terraform -chdir=terraform/environments/$(env) plan -lock=false\n\nterraform-import: ## Run tf import script, sample usage: make terraform-import env=dev\n    (cd terraform/environments/$(env) &amp;&amp; ./imports.sh)\n</code></pre>"},{"location":"terraform/terraform-cheatsheet/#atlantis-integration","title":"Atlantis Integration","text":"<p>Atlantis automates Terraform workflows on GitHub pull requests.</p> <p>Sample commands for Atlantis:</p> <pre><code>atlantis plan -d 'path/to/module' -- -target='module.example'\n\natlantis apply -d 'path/to/module'\n</code></pre> <p>You can specify multiple targets in one command:</p> <pre><code>atlantis plan -d 'path/to/module' -- -target='module.repo1' -target='module.repo2'\n</code></pre>"},{"location":"terraform/terraform-cheatsheet/#using-specific-git-references-for-terraform-modules","title":"Using Specific Git References for Terraform Modules","text":"<p>When sourcing Terraform modules from a Git repository, omitting the <code>ref</code> parameter will default to the repository's <code>master</code> (or <code>main</code>) branch. To ensure reproducibility and stability, it is recommended to use a specific tag, commit, or branch via the <code>ref</code> parameter.</p> <p>Example:</p> <pre><code># Without ref \u2014 defaults to master/main branch\nsource = \"git::ssh://git@github.com/organization/terraform-modules.git//path/to/module\"\n\n# With ref \u2014 pinned to a specific version\nsource = \"git::ssh://git@github.com/organization/terraform-modules.git//path/to/module?ref=v1.2.3\"\n\n# You can also reference a specific branch or commit\nsource = \"git::ssh://git@github.com/organization/terraform-modules.git//path/to/module?ref=feature/my-feature\"\nsource = \"git::ssh://git@github.com/organization/terraform-modules.git//path/to/module?ref=commit-sha\"\n</code></pre> <p>Tip: Using a specific tag or commit hash prevents unexpected changes from upstream that could break your infrastructure.</p>"},{"location":"terraform/terraform-cheatsheet/#terraform-best-practices","title":"Terraform Best Practices","text":"<ul> <li>Use version pinning for providers to avoid unexpected changes.</li> <li>Use modules to structure reusable code.</li> <li>Separate environments using workspaces or directory structure.</li> <li>Manage state securely with remote backends.</li> <li>Use <code>terraform fmt</code> and <code>terraform validate</code> regularly.</li> <li>Plan and apply with targeted resources if needed:</li> </ul> <pre><code>terraform plan -target='module.example.resource'\n\nterraform apply -target='module.example.resource'\n</code></pre> <ul> <li>Use community best practices,   e.g., terraform-aws-lambda.</li> </ul>"},{"location":"terraform/terraform-cheatsheet/#sample-terraform-registries","title":"Sample Terraform Registries","text":"<ul> <li> <p>Refer to   the official Azure PostgreSQL Terraform resource documentation   for managing PostgreSQL databases on Azure.</p> </li> <li> <p>Refer to   the official GitHub Repository Terraform resource documentation   for managing GitHub repositories.</p> </li> </ul>"},{"location":"terraform/terraform-cheatsheet/#references","title":"References","text":"<p>For all official Terraform documentation, including CLI commands, configuration language functions, providers, modules, and other resources, you can refer to the main HashiCorp Terraform documentation site:</p> <ul> <li>Terraform Official Documentation   : https://developer.hashicorp.com/terraform</li> </ul> <p>This site covers:</p> <ul> <li> <p>Terraform CLI:   Covers all CLI commands, flags, environment variables, configuration options, and usage examples.</p> </li> <li> <p>Terraform Language &amp; Functions:   Includes information about Terraform configuration language, expressions, and built-in functions like <code>flatten</code>,   <code>setproduct</code>, <code>lookup</code>, <code>templatefile</code>, and many others.</p> </li> <li> <p>Providers &amp; Modules:   Central resource for providers, modules, and other Terraform resources.</p> </li> <li> <p>State Management:   Guides for managing Terraform state, remote backends, and best practices.</p> </li> <li> <p>Terraform Cloud &amp; Enterprise:   Documentation for Terraform Cloud and Enterprise features like integration guides and workflows.</p> </li> <li> <p>Getting Started Guides:   Step-by-step tutorials to help beginners set up Terraform and learn best practices.</p> </li> </ul> <p>By visiting the link above, you can navigate to all specific areas of Terraform documentation in one place.</p>"},{"location":"terraform/tfenv/","title":"tfenv - Terraform Version Manager","text":"<p>tfenv is a Terraform version manager, similar to tools like <code>jenv</code> for Java or <code>nvm</code> for Node.js. It makes it easy to install, switch, and manage multiple versions of Terraform on your system.</p>"},{"location":"terraform/tfenv/#installation","title":"Installation","text":"<pre><code>brew install tfenv\n</code></pre>"},{"location":"terraform/tfenv/#usage","title":"Usage","text":""},{"location":"terraform/tfenv/#list-available-terraform-versions","title":"List Available Terraform Versions","text":"<pre><code>tfenv list-remote\n</code></pre> <p>Example output:</p> <pre><code>0.12.0\n0.12.0-rc1\n0.12.0-beta2\n0.12.0-beta1\n0.11.14\n...\n</code></pre>"},{"location":"terraform/tfenv/#install-a-specific-version","title":"Install a Specific Version","text":"<pre><code>tfenv install 0.11.14\n</code></pre> <p>Example output:</p> <pre><code>[INFO] Installing Terraform v0.11.14\n[INFO] Downloading release tarball from https://releases.hashicorp.com/terraform/0.11.14/terraform_0.11.14_darwin_amd64.zip\n[INFO] Installation of terraform v0.11.14 successful\n[INFO] Switching to v0.11.14\n[INFO] Switching completed\n</code></pre>"},{"location":"terraform/tfenv/#use-a-specific-version","title":"Use a Specific Version","text":"<pre><code>tfenv use 0.12.0\n</code></pre> <p>Example output:</p> <pre><code>[INFO] Switching to v0.12.0\n[INFO] Switching completed\n</code></pre>"},{"location":"terraform/tfenv/#upgrading-terraform","title":"Upgrading Terraform","text":"<p>For instructions on upgrading Terraform to a specific version, refer to: https://stackoverflow.com/questions/56283424/upgrade-terraform-to-specific-version</p>"},{"location":"terraform/tfenv/#references","title":"References","text":"<p>For more details, check the official repo: https://github.com/tfutils/tfenv</p>"},{"location":"tools/apicurio-via-docker/","title":"Apicurio via Docker","text":"<p>Apicurio Registry is an open-source registry for storing and retrieving API artifacts such as OpenAPI definitions, AsyncAPI definitions, Avro schemas, JSON Schema, and more. This guide explains how to install and run Apicurio (both backend and UI) using Docker.</p>"},{"location":"tools/apicurio-via-docker/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed on your system</li> <li>Ensure that ports 8080 (backend) and 8888 (UI) are free before starting</li> <li>You can check if a port is in use with:</li> </ul> <pre><code>lsof -i:8080  \nlsof -i:8888\n</code></pre>"},{"location":"tools/apicurio-via-docker/#step-1-install-docker-macos-example-with-homebrew","title":"Step 1 \u2014 Install Docker (MacOS example with Homebrew)","text":"<p><code>brew install docker</code></p>"},{"location":"tools/apicurio-via-docker/#step-2-run-the-backend","title":"Step 2 \u2014 Run the Backend","text":"<ol> <li>Pull the Apicurio Registry backend image:</li> </ol> <p><code>docker pull apicurio/apicurio-registry:3.0.6</code></p> <ol> <li>Run the backend container:</li> </ol> <p><code>docker run -it -p 8080:8080 apicurio/apicurio-registry:3.0.6</code></p> <ol> <li>Open your browser and navigate to: <code>http://localhost:8080</code></li> </ol>"},{"location":"tools/apicurio-via-docker/#step-3-run-the-ui","title":"Step 3 \u2014 Run the UI","text":"<ol> <li>Pull the Apicurio Registry UI image:</li> </ol> <p><code>docker pull apicurio/apicurio-registry-ui:3.0.6</code></p> <ol> <li>Run the UI container:</li> </ol> <p><code>docker run -it -p 8888:8080 apicurio/apicurio-registry-ui:3.0.6</code></p> <ol> <li>Open your browser and navigate to: <code>http://localhost:8888</code></li> </ol>"},{"location":"tools/apicurio-via-docker/#step-4-upload-and-validate-api-artifacts","title":"Step 4 \u2014 Upload and Validate API Artifacts","text":"<p>Once the UI is connected to the backend:</p> <ol> <li>Go to the UI (<code>http://localhost:8888</code>)</li> <li>Use the Upload feature to add your API definition file (e.g., OpenAPI, Avro, JSON Schema).</li> <li>Explore detailed documentation, validation results, and example payloads.</li> </ol> <p>Note: Postman does not provide schema-level validation and example previews for these formats \u2014 using Apicurio UI is more powerful for this purpose.</p>"},{"location":"tools/apicurio-via-docker/#step-5-stopping-containers","title":"Step 5 \u2014 Stopping Containers","text":"<p>To stop the backend:</p> <p><code>docker ps</code>  # find the container ID for the backend <code>docker stop &lt;container_id&gt;</code></p> <p>To stop the UI:</p> <p><code>docker ps</code>  # find the container ID for the UI <code>docker stop &lt;container_id&gt;</code></p>"},{"location":"tools/bloomrpc/","title":"BloomRPC","text":"<p>BloomRPC is a GUI client for testing and interacting with gRPC services. It allows developers to quickly test RPC endpoints using <code>.proto</code> files without writing additional client code.</p>"},{"location":"tools/bloomrpc/#installation","title":"Installation","text":"<pre><code>brew install --cask bloomrpc\n</code></pre>"},{"location":"tools/bloomrpc/#running-bloomrpc","title":"Running BloomRPC","text":"<p>After installation, open BloomRPC from the Applications folder or via Spotlight search.</p>"},{"location":"tools/bloomrpc/#loading-and-using-proto-files","title":"Loading and Using <code>.proto</code> Files","text":"<ol> <li>Click on <code>File</code> \u2192 <code>Import Proto</code> or the <code>+</code> button in the left panel to add a <code>.proto</code> file.</li> <li>BloomRPC will parse the services and display all available RPC methods.</li> <li>Select a method to test, fill in the request fields, and click <code>Invoke</code> to send the RPC request.</li> <li>The response will appear in the right panel.</li> </ol>"},{"location":"tools/bloomrpc/#connecting-to-a-grpc-server","title":"Connecting to a gRPC Server","text":"<ol> <li>Enter the server address (e.g., <code>localhost:50051</code>) in the target field.</li> <li>If the server uses TLS, configure the certificate in the <code>Settings</code> panel.</li> <li>Click <code>Connect</code> to establish the connection.</li> </ol>"},{"location":"tools/bloomrpc/#saving-requests","title":"Saving Requests","text":"<p>BloomRPC allows you to save your requests for reuse:</p> <ul> <li>Click <code>Save</code> after creating a request.</li> <li>Saved requests can be organized into collections for easier access.</li> </ul>"},{"location":"tools/bloomrpc/#updating-bloomrpc","title":"Updating BloomRPC","text":"<p>To update BloomRPC:</p> <pre><code>brew upgrade --cask bloomrpc\n</code></pre>"},{"location":"tools/bloomrpc/#uninstalling-bloomrpc","title":"Uninstalling BloomRPC","text":"<p>To uninstall via Homebrew:</p> <pre><code>brew uninstall --cask bloomrpc\n</code></pre>"},{"location":"tools/bloomrpc/#conclusion","title":"Conclusion","text":"<p>BloomRPC simplifies testing gRPC services, allowing you to load <code>.proto</code> files, send requests, and view responses with a simple GUI. It is especially useful for developers working with multiple gRPC endpoints on macOS.</p> <p>For more details, refer to the official GitHub repository: https://github.com/bloomrpc/bloomrpc.</p>"},{"location":"tools/bloomrpc/#note-on-bloomrpc","title":"\u26a0\ufe0f Note on BloomRPC","text":"<p>This project was archived in Jan 2023 and is no longer actively maintained. Its usage is no longer recommended.</p>"},{"location":"tools/bloomrpc/#why-was-it-archived","title":"Why was it archived?","text":"<p>When BloomRPC was first released in Dec 2018, there were very few GUI gRPC tools available, hence the project tagline: \" The missing GUI client for gRPC services\". It served its purpose for a few years. Unfortunately, development stalled and issues accumulated, leaving users frustrated. The maintainers decided that BloomRPC no longer offered a good experience and archived the project.</p>"},{"location":"tools/bloomrpc/#recommended-alternatives","title":"Recommended Alternatives","text":"<p>For actively maintained and feature-rich gRPC GUI clients, check out the list of current tools at Awesome gRPC Tools.</p>"},{"location":"tools/kafkaui-via-docker/","title":"KafkaUI via Docker","text":"<p>This guide explains how to set up and use Kafka UI locally with Docker for debugging and inspecting Kafka topics.</p>"},{"location":"tools/kafkaui-via-docker/#1-list-available-topics","title":"1. List Available Topics","text":"<p>To list the topics in a running Kafka cluster:</p> <pre><code>kafka-topics --bootstrap-server &lt;KAFKA_BOOTSTRAP_SERVER&gt; --list\n</code></pre> <p>Example:</p> <pre><code>kafka-topics --bootstrap-server my-cluster.kafka.local:9094 --list\n</code></pre>"},{"location":"tools/kafkaui-via-docker/#2-get-kafka-cluster-id","title":"2. Get Kafka Cluster ID","text":"<p>To retrieve the cluster ID of your local or remote Kafka cluster:</p> <pre><code>kafka-cluster cluster-id --bootstrap-server &lt;KAFKA_BOOTSTRAP_SERVER&gt;\n</code></pre> <p>Example:</p> <pre><code>kafka-cluster cluster-id --bootstrap-server my-cluster.kafka.local:9094\n</code></pre> <p>You will need this Cluster ID in the next step.</p>"},{"location":"tools/kafkaui-via-docker/#3-run-kafka-ui-with-docker","title":"3. Run Kafka UI with Docker","text":"<p>Run the Kafka UI Docker container, replacing <code>&lt;CLUSTER_ID&gt;</code> and <code>&lt;KAFKA_BOOTSTRAP_SERVER&gt;</code> with your values:</p> <pre><code>docker run -d -p 8080:8080\n-e KAFKA_CLUSTERS_0_NAME=&lt;CLUSTER_ID&gt;\n-e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=&lt;KAFKA_BOOTSTRAP_SERVER&gt;\nprovectuslabs/kafka-ui\n</code></pre> <p>Example:</p> <pre><code>docker run -d -p 8080:8080\n-e KAFKA_CLUSTERS_0_NAME=abcd1234ClusterId\n-e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=my-cluster.kafka.local:9094\nprovectuslabs/kafka-ui\n</code></pre>"},{"location":"tools/kafkaui-via-docker/#4-access-kafka-ui","title":"4. Access Kafka UI","text":"<p>Once the container is running, open your browser and navigate to: <code>http://localhost:8080</code></p> <p>You will see the Kafka UI interface where you can:</p> <ul> <li>Browse topics</li> <li>View messages</li> <li>Manage consumer groups</li> <li>Inspect configurations</li> </ul>"},{"location":"tools/kafkaui-via-docker/#notes","title":"Notes","text":"<ul> <li>Docker must be installed and running on your local machine.</li> <li>Ensure that port 8080 is not already in use. You can check by running: <code>lsof -i:8080</code></li> <li>Replace placeholder values (<code>&lt;CLUSTER_ID&gt;</code> and <code>&lt;KAFKA_BOOTSTRAP_SERVER&gt;</code>) with actual values from your environment.</li> </ul>"},{"location":"tools/multi-gitter/","title":"Multi-Gitter","text":"<p>This document introduces a powerful tool called Multi-Gitter, perfect for people who need to apply changes across many repositories efficiently.</p> <p>Multi-Gitter runs a script on multiple repositories, automatically creating Pull Requests (PRs) with custom titles and bodies. This allows teams to review and merge changes consistently across all relevant repos.</p>"},{"location":"tools/multi-gitter/#why-use-multi-gitter","title":"Why Use Multi-Gitter?","text":"<ul> <li>Automate repetitive changes across multiple repositories.</li> <li>Keep repo configurations consistent.</li> <li>Easily update or remove files (e.g., config files, CODEOWNERS).</li> <li>Facilitate team collaboration with reviewable PRs.</li> </ul>"},{"location":"tools/multi-gitter/#example-use-cases","title":"Example Use Cases","text":"<ul> <li>Removing deprecated config files from workflow directories in multiple repos.</li> <li>Updating CODEOWNERS files to reflect new team ownership.</li> <li>Bulk modifications related to platform migrations or tooling upgrades.</li> </ul>"},{"location":"tools/multi-gitter/#installation","title":"Installation","text":"<p>On macOS, install via Homebrew:</p> <pre><code>brew install lindell/multi-gitter/multi-gitter\n</code></pre> <p>If you encounter errors related to Command Line Tools, run:</p> <pre><code>sudo rm -rf /Library/Developer/CommandLineTools\nsudo xcode-select --install\n</code></pre>"},{"location":"tools/multi-gitter/#prepare-your-scripts","title":"Prepare Your Scripts","text":"<p>Make sure your shell scripts have execute permission:</p> <pre><code>chmod +x ./update_codeowners.sh\n</code></pre>"},{"location":"tools/multi-gitter/#usage-examples","title":"Usage Examples","text":""},{"location":"tools/multi-gitter/#1-delete-config-files-in-multiple-repos","title":"1. Delete Config Files in Multiple Repos","text":"<p>Dry-run to preview:</p> <pre><code>multi-gitter run ./delete_config.sh \\\n--token YOUR_GITHUB_TOKEN \\\n--repo user/repo1,user/repo2,user/repo3 \\\n--branch feature/remove-config \\\n--pr-title \"Remove config.yml from workflows\" \\\n--pr-body \"This PR removes the unnecessary config.yml file from workflow directories.\" \\\n--dry-run\n</code></pre> <p>Execute actual PR creation:</p> <pre><code>multi-gitter run ./delete_config.sh \\\n--token YOUR_GITHUB_TOKEN \\\n--repo user/repo1,user/repo2,user/repo3 \\\n--branch feature/remove-config \\\n--pr-title \"Remove config.yml from workflows\" \\\n--pr-body \"This PR removes the unnecessary config.yml file from workflow directories.\"\n</code></pre>"},{"location":"tools/multi-gitter/#2-update-codeowners-across-multiple-repos","title":"2. Update CODEOWNERS Across Multiple Repos","text":"<p>Dry-run example:</p> <pre><code>multi-gitter run ./update_codeowners.sh \\\n--token YOUR_GITHUB_TOKEN \\\n--repo user/repo1,user/repo2,user/repo3 \\\n--branch feature/update-codeowners \\\n--pr-title \"Update CODEOWNERS\" \\\n--pr-body \"This PR updates the CODEOWNERS file with correct team assignments.\" \\\n--dry-run\n</code></pre>"},{"location":"tools/multi-gitter/#sample-scripts","title":"Sample Scripts","text":"<p>Delete config.yml:</p> delete_config.sh <pre><code>#!/bin/bash\n\n# Check if config.yml exists and remove it\nif [ -f \".github/config.yml\" ]; then\n  echo \"Found config.yml. Removing...\"\n  git rm .github/config.yml\nelse\n  echo \"config.yml not found, skipping...\"\nfi\n</code></pre> <p>Update codeowners:</p> update_codeowners.sh <pre><code>#!/bin/bash\n\nrepo_name=$REPOSITORY\n\nORG_NAME=\"your-org\"\nCODEOWNERS_FILE=\".github/CODEOWNERS\"\n\n# Example: Clear CODEOWNERS for a specific repo\nif [[ \"$repo_name\" == \"your-org/special-repo\" ]]; then\n  echo \"Clearing CODEOWNERS for $repo_name...\"\n  &gt; $CODEOWNERS_FILE\n  git add $CODEOWNERS_FILE\n  exit 0\nfi\n\n# Assign teams based on repo name\nif [[ \"$repo_name\" == \"your-org/repo1\" ]]; then\n  team=\"@${ORG_NAME}/team1\"\nelif [[ \"$repo_name\" == \"your-org/repo2\" ]]; then\n  team=\"@${ORG_NAME}/team2\"\nelif [[ \"$repo_name\" == \"your-org/repo3\" ]]; then\n  team=\"@${ORG_NAME}/team3\"\nelse\n  echo \"No team assignment found for $repo_name, skipping...\"\n  exit 0\nfi\n\necho \"Updating CODEOWNERS for $repo_name with team $team...\"\n\necho \"* $team\" &gt; $CODEOWNERS_FILE\n\ngit add $CODEOWNERS_FILE\n</code></pre>"},{"location":"tools/multipass/","title":"Multipass","text":"<p>Multipass is a lightweight VM manager developed by Canonical that allows you to run Ubuntu virtual machines quickly and easily on macOS, Linux, and Windows. It is ideal for developers who want a clean Ubuntu environment for testing or development.</p>"},{"location":"tools/multipass/#what-is-multipass","title":"What is Multipass?","text":"<p>Multipass is a tool for launching and managing lightweight Ubuntu virtual machines. It provides:</p> <ul> <li>Quick VM provisioning</li> <li>Minimal setup</li> <li>Cross-platform support (Mac, Linux, Windows)</li> <li>CLI commands for VM management</li> </ul> <p>It is perfect for testing, development, and experimenting without affecting your host system.</p>"},{"location":"tools/multipass/#why-use-multipass","title":"Why Use Multipass?","text":"<ul> <li>Quickly spin up Ubuntu environments</li> <li>Isolate development environments</li> <li>Test applications in a clean OS</li> <li>Easily create, delete, and manage multiple VMs</li> </ul>"},{"location":"tools/multipass/#how-multipass-works","title":"How Multipass Works","text":"<p>Multipass does not use Docker containers. Instead, it launches full Ubuntu virtual machines using the host system's hypervisor:</p> <ul> <li>macOS: HyperKit</li> <li>Linux: KVM (Kernel-based Virtual Machine)</li> <li>Windows: Hyper-V</li> </ul> <p>This provides a fully isolated operating system, unlike Docker, which uses container-based virtualization.</p>"},{"location":"tools/multipass/#installation","title":"Installation","text":""},{"location":"tools/multipass/#mac","title":"Mac","text":"<p>The recommended way to install Multipass on macOS is via Homebrew:</p> <pre><code>brew install --cask multipass\n</code></pre> <p>After installation, verify it with:</p> <pre><code>multipass version\n</code></pre> <p>You can also download the official <code>.dmg</code> file from the Multipass website.</p> <p>And you can use the Multipass GUI app for managing your VMs visually:</p> <p></p>"},{"location":"tools/multipass/#linux","title":"Linux","text":"<p>Multipass is available for Linux distributions like Ubuntu, Debian, Fedora, and CentOS. The easiest way is to use the official snap package:</p> <pre><code>sudo snap install multipass\n</code></pre> <p>Verify installation:</p> <pre><code>multipass version\n</code></pre>"},{"location":"tools/multipass/#basic-usage","title":"Basic Usage","text":""},{"location":"tools/multipass/#help","title":"Help","text":"<pre><code>multipass help\n</code></pre>"},{"location":"tools/multipass/#launch-a-new-vm","title":"Launch a New VM","text":"<pre><code>multipass launch --name my-ubuntu-vm\n</code></pre> <p>This will download the latest Ubuntu image and start a VM named <code>my-ubuntu-vm</code>.</p>"},{"location":"tools/multipass/#list-running-vms","title":"List Running VMs","text":"<pre><code>multipass list\n</code></pre>"},{"location":"tools/multipass/#access-a-vm","title":"Access a VM","text":"<pre><code>multipass shell my-ubuntu-vm\n</code></pre>"},{"location":"tools/multipass/#stop-a-vm","title":"Stop a VM","text":"<pre><code>multipass stop my-ubuntu-vm\nmultipass stop --all\n</code></pre>"},{"location":"tools/multipass/#delete-a-vm","title":"Delete a VM","text":"<pre><code>multipass delete my-ubuntu-vm\nmultipass purge\n</code></pre>"},{"location":"tools/multipass/#advanced-features","title":"Advanced Features","text":"<ul> <li>Mount Local Folders: Access local files from your VM:</li> </ul> <pre><code>multipass mount /path/to/local my-ubuntu-vm:/home/ubuntu/mounted\n</code></pre> <ul> <li>Execute Commands:</li> </ul> <pre><code>multipass exec my-ubuntu-vm -- ls /home/ubuntu\n</code></pre> <ul> <li>Specify Ubuntu Version:</li> </ul> <pre><code>multipass launch 22.04 --name ubuntu22\n</code></pre> <ul> <li>Set Resources (CPU, RAM, Disk):</li> </ul> <pre><code>multipass launch --name big-vm --cpus 4 --mem 4G --disk 20G\n</code></pre>"},{"location":"tools/multipass/#references","title":"References","text":"<ul> <li>Official Multipass Documentation</li> <li>Ubuntu Multipass Documentation</li> <li>Multipass GitHub Repository</li> <li>Ubuntu Official Site</li> <li>Snap Package Info</li> <li>Docker vs Virtual Machines </li> </ul>"},{"location":"tools/overriding-hostnames/","title":"Overriding Hostnames","text":"<p>When testing services on private or temporary servers, there may not be public DNS pointing to the server IPs. You can override hostnames on macOS using the <code>/etc/hosts</code> file or temporarily with <code>curl --resolve</code>.</p>"},{"location":"tools/overriding-hostnames/#1-macos-hosts-file","title":"1. macOS Hosts File","text":"<p>The hosts file is located at:</p> <p><code>/etc/hosts</code></p> <p>You can edit it with sudo privileges:</p> <pre><code>sudo nano /etc/hosts # use nano\n\nsudo subl /etc/hosts # or use your preferred text editor\n</code></pre>"},{"location":"tools/overriding-hostnames/#example-entries","title":"Example Entries","text":"<p>Add your custom overrides (<code>IP -&gt; HOST</code> pairs) inside <code>/etc/hosts</code> file:</p> <pre><code>##\n# Host Database\n#\n# localhost is used to configure the loopback interface\n# when the system is booting.  Do not change this entry.\n##\n127.0.0.1   localhost\n255.255.255.255 broadcasthost\n::1             localhost\n# Added by Docker Desktop\n# To allow the same kube context to work on the host and the container:\n127.0.0.1 kubernetes.docker.internal\n# End of section\n\n# Custom overrides\n192.168.1.100 app.example.com\n192.168.1.100 api.example.com\n192.168.1.100 dashboard.example.com\n</code></pre> <p>Note: Multiple hostnames can point to the same IP. This is useful when a server hosts multiple services.</p> <p>When you ping or accessing <code>app.example.com</code>, it will resolve to <code>192.168.1.100</code>:</p> <pre><code>$ ping app.example.com\nPING app.example.com (192.168.1.100): 56 data bytes\nRequest timeout for icmp_seq 0\n...\n</code></pre>"},{"location":"tools/overriding-hostnames/#2-testing-with-curl","title":"2. Testing with <code>curl</code>","text":"<p>Instead of editing the hosts file, you can temporarily map a hostname to an IP using the <code>--resolve</code> option in <code>curl</code>:</p> <pre><code>curl --resolve app.example.com:443:192.168.1.100 -o /dev/null -v https://app.example.com\n</code></pre> <p>Replace the hostname and IP for the service you want to test.</p>"},{"location":"tools/overriding-hostnames/#3-purpose","title":"3. Purpose","text":"<ul> <li>Resolve hostnames locally without relying on public DNS.</li> <li>Useful for testing, certificate checks, or interacting with services in private or local clusters.</li> <li>Can be done permanently via <code>/etc/hosts</code> or temporarily with <code>curl --resolve</code>.</li> </ul>"},{"location":"tools/overriding-hostnames/#4-flushing-dns-cache","title":"4. Flushing DNS Cache","text":"<p>After editing <code>/etc/hosts</code>, flush the DNS cache to apply changes:</p> <pre><code>sudo dscacheutil -flushcache  \nsudo killall -HUP mDNSResponder\n</code></pre>"},{"location":"tools/windows-on-mac-via-utm/","title":"Windows on Mac via UTM","text":"<p>This guide explains how to set up a Windows ARM virtual machine on macOS using UTM and CrystalFetch ISO Downloader . It covers downloading the ISO, configuring the VM, and optimizing display settings.</p>"},{"location":"tools/windows-on-mac-via-utm/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Mac with Apple Silicon (M1, M2, etc.)</li> <li>UTM installed</li> <li>CrystalFetch ISO Downloader app</li> </ul>"},{"location":"tools/windows-on-mac-via-utm/#step-1-download-the-windows-arm-iso","title":"Step 1: Download the Windows ARM ISO","text":"<ol> <li>Open CrystalFetch ISO Downloader on your Mac.</li> <li>Select the Windows 11 ARM Insider Preview build you want to download.</li> <li>Choose Home + Pro edition (default selection works for most users).</li> <li>Wait until the download is complete. You will have an ISO file ready to use with UTM.</li> </ol>"},{"location":"tools/windows-on-mac-via-utm/#step-2-create-a-new-vm-in-utm","title":"Step 2: Create a New VM in UTM","text":"<ol> <li>Open UTM.</li> <li>Click + to create a new virtual machine.</li> <li>Select Virtualize \u2192 Windows ARM.</li> <li> <p>Configure the following settings:</p> <ul> <li>CPU: 4 cores (recommended)</li> <li>Memory: 4096 MB or more</li> <li>Storage: 64 GB NVMe disk (sparse disk recommended)</li> </ul> </li> <li> <p>Under CD/DVD Drive, select the ISO file you downloaded from CrystalFetch.</p> </li> </ol>"},{"location":"tools/windows-on-mac-via-utm/#step-3-configure-vm-display-and-input","title":"Step 3: Configure VM Display and Input","text":"<ul> <li>Keyboard Layout: Turkish Q (or US if you use an English keyboard)</li> <li>Display Settings:<ul> <li>Enable Retina / scaled display if available</li> <li>Allocate more video memory if the screen appears blurry</li> </ul> </li> <li>UTM Guest Tools: Install after Windows is running for better graphics and input integration</li> </ul>"},{"location":"tools/windows-on-mac-via-utm/#step-4-install-windows-arm","title":"Step 4: Install Windows ARM","text":"<ol> <li>Start the VM. It should boot from the ISO.</li> <li>Follow the Windows installation steps:<ul> <li>Select language, keyboard layout, and time zone.</li> <li>Choose the NVMe virtual disk as the installation target.</li> </ul> </li> <li>Complete the installation. Once finished, remove the ISO from the CD/DVD drive in UTM.</li> <li>Restart the VM. It should boot directly into Windows ARM from the virtual disk.</li> </ol>"},{"location":"tools/windows-on-mac-via-utm/#step-5-post-installation-tips","title":"Step 5: Post-Installation Tips","text":"<ul> <li>Storage: The VM disk will consume space based on what you allocated (e.g., 64 GB) and used by Windows + apps.</li> <li>Display Optimization: Adjust scaling in Windows settings and install UTM Guest Tools to reduce blurriness.</li> <li>Shutting Down: Use \u201cShut Down\u201d instead of \u201cStop\u201d to avoid booting from ISO again.</li> <li>Deleting the VM: Remove the VM in UTM and delete the associated <code>.utm</code> folder from   <code>~/Library/Containers/com.utmapp.UTM/Data/Documents/&lt;UTM_NAME&gt;/</code> to free space.</li> </ul>"},{"location":"tools/windows-on-mac-via-utm/#notes","title":"Notes","text":"<ul> <li>You do not need a license key to run Windows ARM Insider Preview in a virtual machine, but a license is required   for production use or activation.</li> <li>Performance will vary depending on your Mac model and allocated resources.</li> </ul>"}]}